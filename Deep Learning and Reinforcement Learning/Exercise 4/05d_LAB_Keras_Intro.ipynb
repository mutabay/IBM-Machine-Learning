{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "source": [
    "# Machine Learning Foundation\n",
    "\n",
    "## Course 5, Part d: Keras Intro LAB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Keras to Build and Train Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we will use a neural network to predict diabetes using the Pima Diabetes Dataset.  We will start by training a Random Forest to get a performance baseline.  Then we will use the Keras package to quickly build and train a neural network and compare the performance.  We will see how different network structures affect the performance, training time, and level of overfitting (or underfitting).\n",
    "\n",
    "## UCI Pima Diabetes Dataset\n",
    "\n",
    "* UCI ML Repositiory (http://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabetes)\n",
    "\n",
    "\n",
    "### Attributes: (all numeric-valued)\n",
    "   1. Number of times pregnant\n",
    "   2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
    "   3. Diastolic blood pressure (mm Hg)\n",
    "   4. Triceps skin fold thickness (mm)\n",
    "   5. 2-Hour serum insulin (mu U/ml)\n",
    "   6. Body mass index (weight in kg/(height in m)^2)\n",
    "   7. Diabetes pedigree function\n",
    "   8. Age (years)\n",
    "   9. Class variable (0 or 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The UCI Pima Diabetes Dataset which has 8 numerical predictors and a binary outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_auc_score, roc_curve, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "## Import Keras objects for Deep Learning\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "from tensorflow.keras import layers"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load in the data set \n",
    "names = [\"times_pregnant\", \"glucose_tolerance_test\", \"blood_pressure\", \"skin_thickness\", \"insulin\", \n",
    "         \"bmi\", \"pedigree_function\", \"age\", \"has_diabetes\"]\n",
    "diabetes_df = pd.read_csv('diabetes.csv', names=names, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 9)\n"
     ]
    },
    {
     "data": {
      "text/plain": "     times_pregnant  glucose_tolerance_test  blood_pressure  skin_thickness  \\\n678               3                     121              52               0   \n139               5                     105              72              29   \n529               0                     111              65               0   \n189               5                     139              80              35   \n51                1                     101              50              15   \n\n     insulin   bmi  pedigree_function  age  has_diabetes  \n678        0  36.0              0.127   25             1  \n139      325  36.9              0.159   28             0  \n529        0  24.6              0.660   31             0  \n189      160  31.6              0.361   25             1  \n51        36  24.2              0.526   26             0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>times_pregnant</th>\n      <th>glucose_tolerance_test</th>\n      <th>blood_pressure</th>\n      <th>skin_thickness</th>\n      <th>insulin</th>\n      <th>bmi</th>\n      <th>pedigree_function</th>\n      <th>age</th>\n      <th>has_diabetes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>678</th>\n      <td>3</td>\n      <td>121</td>\n      <td>52</td>\n      <td>0</td>\n      <td>0</td>\n      <td>36.0</td>\n      <td>0.127</td>\n      <td>25</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>139</th>\n      <td>5</td>\n      <td>105</td>\n      <td>72</td>\n      <td>29</td>\n      <td>325</td>\n      <td>36.9</td>\n      <td>0.159</td>\n      <td>28</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>529</th>\n      <td>0</td>\n      <td>111</td>\n      <td>65</td>\n      <td>0</td>\n      <td>0</td>\n      <td>24.6</td>\n      <td>0.660</td>\n      <td>31</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>189</th>\n      <td>5</td>\n      <td>139</td>\n      <td>80</td>\n      <td>35</td>\n      <td>160</td>\n      <td>31.6</td>\n      <td>0.361</td>\n      <td>25</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>51</th>\n      <td>1</td>\n      <td>101</td>\n      <td>50</td>\n      <td>15</td>\n      <td>36</td>\n      <td>24.2</td>\n      <td>0.526</td>\n      <td>26</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a peek at the data -- if there are lots of \"NaN\" you may have internet connectivity issues\n",
    "print(diabetes_df.shape)\n",
    "diabetes_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = diabetes_df.iloc[:, :-1].values\n",
    "y = diabetes_df[\"has_diabetes\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data to Train, and Test (75%, 25%)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(0.3489583333333333, 0.6510416666666666)"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y), np.mean(1-y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we see that about 35% of the patients in this dataset have diabetes, while 65% do not.  This means we can get an accuracy of 65% without any model - just declare that no one has diabetes. We will calculate the ROC-AUC score to evaluate performance of our model, and also look at the accuracy as well to see if we improved upon the 65% accuracy.\n",
    "## Exercise 1: Get a baseline performance using Random Forest\n",
    "To begin, and get a baseline for classifier performance:\n",
    "1. Train a Random Forest model with 200 trees on the training data.\n",
    "2. Calculate the accuracy and roc_auc_score of the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "RandomForestClassifier(n_estimators=200)"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### BEGIN SOLUTION\n",
    "## Train the RF Model\n",
    "rf_model = RandomForestClassifier(n_estimators=200)\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.729\n",
      "roc-auc is 0.808\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set - both \"hard\" predictions, and the scores (percent of trees voting yes)\n",
    "y_pred_class_rf = rf_model.predict(X_test)\n",
    "y_pred_prob_rf = rf_model.predict_proba(X_test)\n",
    "\n",
    "\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_rf)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_rf[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 576x576 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_roc(y_test, y_pred, model_name):\n",
    "    fpr, tpr, thr = roc_curve(y_test, y_pred)\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.plot(fpr, tpr, 'b-')\n",
    "    ax.plot([0, 1], [0, 1], 'k--', linewidth=.5)  # roc curve for random model\n",
    "    ax.grid(True)\n",
    "    ax.set(title='ROC Curve for {} on PIMA diabetes problem'.format(model_name),\n",
    "           xlim=[-0.01, 1.01], ylim=[-0.01, 1.01])\n",
    "plot_roc(y_test, y_pred_prob_rf[:, 1], 'RF')\n",
    "### END SOLUTION"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Single Hidden Layer Neural Network\n",
    "\n",
    "We will use the Sequential model to quickly build a neural network.  Our first network will be a single layer network.  We have 8 variables, so we set the input shape to 8.  Let's start by having a single hidden layer with 12 nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "## First let's normalize the data\n",
    "## This aids the training of neural nets by providing numerical stability\n",
    "## Random Forest does not need this as it finds a split only, as opposed to performing matrix multiplications\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_norm = scaler.fit_transform(X_train)\n",
    "X_test_norm = scaler.transform(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "# Define the Model\n",
    "# Input size is 8-dimensional\n",
    "# 1 hidden layer, 12 hidden nodes, sigmoid activation\n",
    "# Final layer has just one node with a sigmoid activation (standard for binary classification)\n",
    "\n",
    "\n",
    "model_1 = Sequential()\n",
    "model_1.add(Dense(12, input_shape= (8,), activation='sigmoid'))\n",
    "model_1.add(Dense(1, activation='sigmoid'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 12)                108       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 121\n",
      "Trainable params: 121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#  This is a nice tool to view the model you have created and count the parameters\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comprehension question:\n",
    "Why do we have 121 parameters?  Does that make sense?\n",
    "\n",
    "Let's fit our model for 200 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.9522 - accuracy: 0.3455 - val_loss: 0.9310 - val_accuracy: 0.3594\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.9175 - accuracy: 0.3455 - val_loss: 0.8986 - val_accuracy: 0.3594\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8857 - accuracy: 0.3455 - val_loss: 0.8690 - val_accuracy: 0.3594\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8566 - accuracy: 0.3455 - val_loss: 0.8420 - val_accuracy: 0.3594\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8300 - accuracy: 0.3455 - val_loss: 0.8174 - val_accuracy: 0.3594\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8059 - accuracy: 0.3455 - val_loss: 0.7951 - val_accuracy: 0.3594\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7840 - accuracy: 0.3507 - val_loss: 0.7749 - val_accuracy: 0.3594\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7641 - accuracy: 0.3524 - val_loss: 0.7566 - val_accuracy: 0.3646\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7462 - accuracy: 0.3559 - val_loss: 0.7401 - val_accuracy: 0.3750\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7299 - accuracy: 0.3715 - val_loss: 0.7253 - val_accuracy: 0.4010\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7153 - accuracy: 0.4010 - val_loss: 0.7119 - val_accuracy: 0.4219\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7020 - accuracy: 0.4358 - val_loss: 0.6999 - val_accuracy: 0.4479\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6901 - accuracy: 0.4670 - val_loss: 0.6890 - val_accuracy: 0.5000\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6793 - accuracy: 0.5122 - val_loss: 0.6793 - val_accuracy: 0.5208\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6697 - accuracy: 0.5625 - val_loss: 0.6706 - val_accuracy: 0.5521\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6609 - accuracy: 0.6198 - val_loss: 0.6627 - val_accuracy: 0.5833\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6531 - accuracy: 0.6562 - val_loss: 0.6556 - val_accuracy: 0.6042\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6459 - accuracy: 0.6875 - val_loss: 0.6492 - val_accuracy: 0.6615\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6395 - accuracy: 0.6840 - val_loss: 0.6435 - val_accuracy: 0.6823\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6336 - accuracy: 0.7188 - val_loss: 0.6383 - val_accuracy: 0.7188\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6284 - accuracy: 0.7413 - val_loss: 0.6336 - val_accuracy: 0.7240\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6236 - accuracy: 0.7535 - val_loss: 0.6294 - val_accuracy: 0.7292\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6193 - accuracy: 0.7622 - val_loss: 0.6256 - val_accuracy: 0.7604\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6153 - accuracy: 0.7691 - val_loss: 0.6222 - val_accuracy: 0.7656\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6118 - accuracy: 0.7726 - val_loss: 0.6191 - val_accuracy: 0.7604\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6085 - accuracy: 0.7743 - val_loss: 0.6163 - val_accuracy: 0.7865\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6056 - accuracy: 0.7656 - val_loss: 0.6137 - val_accuracy: 0.7760\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6029 - accuracy: 0.7622 - val_loss: 0.6114 - val_accuracy: 0.7708\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6004 - accuracy: 0.7604 - val_loss: 0.6093 - val_accuracy: 0.7500\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5981 - accuracy: 0.7569 - val_loss: 0.6073 - val_accuracy: 0.7396\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5960 - accuracy: 0.7535 - val_loss: 0.6056 - val_accuracy: 0.7240\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5941 - accuracy: 0.7448 - val_loss: 0.6040 - val_accuracy: 0.7344\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5923 - accuracy: 0.7431 - val_loss: 0.6025 - val_accuracy: 0.7344\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5907 - accuracy: 0.7431 - val_loss: 0.6011 - val_accuracy: 0.7292\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5892 - accuracy: 0.7378 - val_loss: 0.5998 - val_accuracy: 0.7292\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5877 - accuracy: 0.7396 - val_loss: 0.5987 - val_accuracy: 0.7240\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5864 - accuracy: 0.7361 - val_loss: 0.5976 - val_accuracy: 0.7240\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5852 - accuracy: 0.7309 - val_loss: 0.5966 - val_accuracy: 0.7240\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5840 - accuracy: 0.7292 - val_loss: 0.5956 - val_accuracy: 0.7135\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5830 - accuracy: 0.7257 - val_loss: 0.5948 - val_accuracy: 0.6979\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5819 - accuracy: 0.7222 - val_loss: 0.5940 - val_accuracy: 0.6979\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5810 - accuracy: 0.7170 - val_loss: 0.5932 - val_accuracy: 0.6979\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5801 - accuracy: 0.7135 - val_loss: 0.5924 - val_accuracy: 0.6979\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5792 - accuracy: 0.7118 - val_loss: 0.5918 - val_accuracy: 0.6927\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5784 - accuracy: 0.7118 - val_loss: 0.5911 - val_accuracy: 0.6875\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5776 - accuracy: 0.7101 - val_loss: 0.5905 - val_accuracy: 0.6823\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5768 - accuracy: 0.7101 - val_loss: 0.5899 - val_accuracy: 0.6823\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5761 - accuracy: 0.7066 - val_loss: 0.5893 - val_accuracy: 0.6823\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5754 - accuracy: 0.7083 - val_loss: 0.5888 - val_accuracy: 0.6771\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5747 - accuracy: 0.7049 - val_loss: 0.5883 - val_accuracy: 0.6771\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5740 - accuracy: 0.7066 - val_loss: 0.5877 - val_accuracy: 0.6823\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5734 - accuracy: 0.7066 - val_loss: 0.5873 - val_accuracy: 0.6771\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5728 - accuracy: 0.7066 - val_loss: 0.5868 - val_accuracy: 0.6771\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5722 - accuracy: 0.7066 - val_loss: 0.5863 - val_accuracy: 0.6771\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5716 - accuracy: 0.7049 - val_loss: 0.5859 - val_accuracy: 0.6771\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5711 - accuracy: 0.7049 - val_loss: 0.5854 - val_accuracy: 0.6771\n",
      "Epoch 57/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5705 - accuracy: 0.7031 - val_loss: 0.5850 - val_accuracy: 0.6823\n",
      "Epoch 58/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5700 - accuracy: 0.7031 - val_loss: 0.5846 - val_accuracy: 0.6823\n",
      "Epoch 59/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5694 - accuracy: 0.7014 - val_loss: 0.5842 - val_accuracy: 0.6823\n",
      "Epoch 60/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5689 - accuracy: 0.7014 - val_loss: 0.5838 - val_accuracy: 0.6823\n",
      "Epoch 61/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5684 - accuracy: 0.7014 - val_loss: 0.5834 - val_accuracy: 0.6823\n",
      "Epoch 62/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5679 - accuracy: 0.7014 - val_loss: 0.5830 - val_accuracy: 0.6823\n",
      "Epoch 63/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5674 - accuracy: 0.6997 - val_loss: 0.5826 - val_accuracy: 0.6823\n",
      "Epoch 64/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5669 - accuracy: 0.7014 - val_loss: 0.5822 - val_accuracy: 0.6823\n",
      "Epoch 65/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5664 - accuracy: 0.7014 - val_loss: 0.5819 - val_accuracy: 0.6823\n",
      "Epoch 66/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5659 - accuracy: 0.7014 - val_loss: 0.5815 - val_accuracy: 0.6823\n",
      "Epoch 67/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5654 - accuracy: 0.7014 - val_loss: 0.5811 - val_accuracy: 0.6823\n",
      "Epoch 68/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5650 - accuracy: 0.7014 - val_loss: 0.5808 - val_accuracy: 0.6823\n",
      "Epoch 69/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5645 - accuracy: 0.7014 - val_loss: 0.5804 - val_accuracy: 0.6823\n",
      "Epoch 70/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5640 - accuracy: 0.7014 - val_loss: 0.5800 - val_accuracy: 0.6771\n",
      "Epoch 71/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5636 - accuracy: 0.7014 - val_loss: 0.5797 - val_accuracy: 0.6771\n",
      "Epoch 72/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5631 - accuracy: 0.7014 - val_loss: 0.5793 - val_accuracy: 0.6771\n",
      "Epoch 73/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5627 - accuracy: 0.7014 - val_loss: 0.5790 - val_accuracy: 0.6771\n",
      "Epoch 74/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5622 - accuracy: 0.7014 - val_loss: 0.5786 - val_accuracy: 0.6771\n",
      "Epoch 75/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5618 - accuracy: 0.7014 - val_loss: 0.5783 - val_accuracy: 0.6771\n",
      "Epoch 76/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5613 - accuracy: 0.7014 - val_loss: 0.5779 - val_accuracy: 0.6823\n",
      "Epoch 77/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5609 - accuracy: 0.7014 - val_loss: 0.5776 - val_accuracy: 0.6823\n",
      "Epoch 78/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5604 - accuracy: 0.7014 - val_loss: 0.5773 - val_accuracy: 0.6823\n",
      "Epoch 79/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5600 - accuracy: 0.7014 - val_loss: 0.5769 - val_accuracy: 0.6823\n",
      "Epoch 80/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5596 - accuracy: 0.7014 - val_loss: 0.5766 - val_accuracy: 0.6823\n",
      "Epoch 81/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5592 - accuracy: 0.6997 - val_loss: 0.5763 - val_accuracy: 0.6823\n",
      "Epoch 82/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5587 - accuracy: 0.7014 - val_loss: 0.5759 - val_accuracy: 0.6875\n",
      "Epoch 83/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5583 - accuracy: 0.7031 - val_loss: 0.5756 - val_accuracy: 0.6875\n",
      "Epoch 84/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5579 - accuracy: 0.7031 - val_loss: 0.5753 - val_accuracy: 0.6875\n",
      "Epoch 85/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5574 - accuracy: 0.7031 - val_loss: 0.5749 - val_accuracy: 0.6875\n",
      "Epoch 86/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5570 - accuracy: 0.7031 - val_loss: 0.5746 - val_accuracy: 0.6875\n",
      "Epoch 87/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5566 - accuracy: 0.7031 - val_loss: 0.5743 - val_accuracy: 0.6875\n",
      "Epoch 88/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5561 - accuracy: 0.7031 - val_loss: 0.5739 - val_accuracy: 0.6875\n",
      "Epoch 89/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5557 - accuracy: 0.7031 - val_loss: 0.5736 - val_accuracy: 0.6875\n",
      "Epoch 90/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5553 - accuracy: 0.7031 - val_loss: 0.5733 - val_accuracy: 0.6875\n",
      "Epoch 91/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5549 - accuracy: 0.7066 - val_loss: 0.5730 - val_accuracy: 0.6875\n",
      "Epoch 92/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5545 - accuracy: 0.7066 - val_loss: 0.5726 - val_accuracy: 0.6875\n",
      "Epoch 93/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5541 - accuracy: 0.7049 - val_loss: 0.5723 - val_accuracy: 0.6875\n",
      "Epoch 94/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5537 - accuracy: 0.7083 - val_loss: 0.5720 - val_accuracy: 0.6979\n",
      "Epoch 95/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5532 - accuracy: 0.7083 - val_loss: 0.5717 - val_accuracy: 0.6979\n",
      "Epoch 96/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5528 - accuracy: 0.7083 - val_loss: 0.5714 - val_accuracy: 0.7083\n",
      "Epoch 97/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5524 - accuracy: 0.7083 - val_loss: 0.5710 - val_accuracy: 0.7083\n",
      "Epoch 98/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5520 - accuracy: 0.7101 - val_loss: 0.5707 - val_accuracy: 0.7083\n",
      "Epoch 99/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5516 - accuracy: 0.7101 - val_loss: 0.5704 - val_accuracy: 0.7083\n",
      "Epoch 100/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5512 - accuracy: 0.7083 - val_loss: 0.5701 - val_accuracy: 0.7083\n",
      "Epoch 101/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5508 - accuracy: 0.7135 - val_loss: 0.5698 - val_accuracy: 0.7083\n",
      "Epoch 102/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5504 - accuracy: 0.7135 - val_loss: 0.5695 - val_accuracy: 0.7083\n",
      "Epoch 103/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5500 - accuracy: 0.7135 - val_loss: 0.5692 - val_accuracy: 0.7083\n",
      "Epoch 104/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5496 - accuracy: 0.7118 - val_loss: 0.5689 - val_accuracy: 0.7083\n",
      "Epoch 105/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5492 - accuracy: 0.7135 - val_loss: 0.5686 - val_accuracy: 0.7083\n",
      "Epoch 106/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5488 - accuracy: 0.7135 - val_loss: 0.5682 - val_accuracy: 0.7083\n",
      "Epoch 107/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5484 - accuracy: 0.7135 - val_loss: 0.5679 - val_accuracy: 0.7083\n",
      "Epoch 108/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5480 - accuracy: 0.7135 - val_loss: 0.5676 - val_accuracy: 0.7135\n",
      "Epoch 109/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5476 - accuracy: 0.7135 - val_loss: 0.5673 - val_accuracy: 0.7135\n",
      "Epoch 110/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5472 - accuracy: 0.7118 - val_loss: 0.5670 - val_accuracy: 0.7135\n",
      "Epoch 111/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5468 - accuracy: 0.7135 - val_loss: 0.5667 - val_accuracy: 0.7135\n",
      "Epoch 112/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5464 - accuracy: 0.7135 - val_loss: 0.5664 - val_accuracy: 0.7135\n",
      "Epoch 113/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5460 - accuracy: 0.7135 - val_loss: 0.5661 - val_accuracy: 0.7135\n",
      "Epoch 114/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5456 - accuracy: 0.7135 - val_loss: 0.5658 - val_accuracy: 0.7135\n",
      "Epoch 115/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5452 - accuracy: 0.7135 - val_loss: 0.5655 - val_accuracy: 0.7135\n",
      "Epoch 116/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5449 - accuracy: 0.7135 - val_loss: 0.5652 - val_accuracy: 0.7135\n",
      "Epoch 117/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5445 - accuracy: 0.7153 - val_loss: 0.5649 - val_accuracy: 0.7135\n",
      "Epoch 118/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5441 - accuracy: 0.7153 - val_loss: 0.5646 - val_accuracy: 0.7135\n",
      "Epoch 119/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5437 - accuracy: 0.7153 - val_loss: 0.5643 - val_accuracy: 0.7135\n",
      "Epoch 120/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5433 - accuracy: 0.7153 - val_loss: 0.5641 - val_accuracy: 0.7135\n",
      "Epoch 121/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5430 - accuracy: 0.7153 - val_loss: 0.5638 - val_accuracy: 0.7135\n",
      "Epoch 122/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5425 - accuracy: 0.7153 - val_loss: 0.5635 - val_accuracy: 0.7135\n",
      "Epoch 123/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5422 - accuracy: 0.7153 - val_loss: 0.5632 - val_accuracy: 0.7188\n",
      "Epoch 124/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5418 - accuracy: 0.7153 - val_loss: 0.5629 - val_accuracy: 0.7188\n",
      "Epoch 125/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5414 - accuracy: 0.7153 - val_loss: 0.5626 - val_accuracy: 0.7188\n",
      "Epoch 126/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5411 - accuracy: 0.7170 - val_loss: 0.5623 - val_accuracy: 0.7188\n",
      "Epoch 127/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5406 - accuracy: 0.7188 - val_loss: 0.5620 - val_accuracy: 0.7292\n",
      "Epoch 128/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5403 - accuracy: 0.7222 - val_loss: 0.5618 - val_accuracy: 0.7292\n",
      "Epoch 129/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5399 - accuracy: 0.7222 - val_loss: 0.5615 - val_accuracy: 0.7292\n",
      "Epoch 130/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5395 - accuracy: 0.7257 - val_loss: 0.5612 - val_accuracy: 0.7292\n",
      "Epoch 131/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5392 - accuracy: 0.7240 - val_loss: 0.5609 - val_accuracy: 0.7344\n",
      "Epoch 132/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5388 - accuracy: 0.7257 - val_loss: 0.5606 - val_accuracy: 0.7344\n",
      "Epoch 133/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5385 - accuracy: 0.7274 - val_loss: 0.5604 - val_accuracy: 0.7344\n",
      "Epoch 134/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5381 - accuracy: 0.7274 - val_loss: 0.5601 - val_accuracy: 0.7396\n",
      "Epoch 135/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5377 - accuracy: 0.7274 - val_loss: 0.5598 - val_accuracy: 0.7396\n",
      "Epoch 136/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5373 - accuracy: 0.7292 - val_loss: 0.5595 - val_accuracy: 0.7396\n",
      "Epoch 137/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5370 - accuracy: 0.7292 - val_loss: 0.5593 - val_accuracy: 0.7396\n",
      "Epoch 138/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5366 - accuracy: 0.7292 - val_loss: 0.5590 - val_accuracy: 0.7396\n",
      "Epoch 139/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5362 - accuracy: 0.7274 - val_loss: 0.5587 - val_accuracy: 0.7396\n",
      "Epoch 140/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5359 - accuracy: 0.7274 - val_loss: 0.5584 - val_accuracy: 0.7396\n",
      "Epoch 141/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5356 - accuracy: 0.7292 - val_loss: 0.5582 - val_accuracy: 0.7396\n",
      "Epoch 142/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5352 - accuracy: 0.7292 - val_loss: 0.5579 - val_accuracy: 0.7396\n",
      "Epoch 143/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5348 - accuracy: 0.7309 - val_loss: 0.5576 - val_accuracy: 0.7396\n",
      "Epoch 144/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5345 - accuracy: 0.7309 - val_loss: 0.5574 - val_accuracy: 0.7396\n",
      "Epoch 145/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5341 - accuracy: 0.7309 - val_loss: 0.5571 - val_accuracy: 0.7448\n",
      "Epoch 146/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5338 - accuracy: 0.7309 - val_loss: 0.5569 - val_accuracy: 0.7396\n",
      "Epoch 147/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5334 - accuracy: 0.7326 - val_loss: 0.5566 - val_accuracy: 0.7396\n",
      "Epoch 148/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5331 - accuracy: 0.7344 - val_loss: 0.5563 - val_accuracy: 0.7396\n",
      "Epoch 149/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5327 - accuracy: 0.7361 - val_loss: 0.5561 - val_accuracy: 0.7396\n",
      "Epoch 150/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5324 - accuracy: 0.7378 - val_loss: 0.5558 - val_accuracy: 0.7396\n",
      "Epoch 151/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5320 - accuracy: 0.7378 - val_loss: 0.5556 - val_accuracy: 0.7396\n",
      "Epoch 152/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5317 - accuracy: 0.7378 - val_loss: 0.5553 - val_accuracy: 0.7396\n",
      "Epoch 153/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5313 - accuracy: 0.7396 - val_loss: 0.5550 - val_accuracy: 0.7396\n",
      "Epoch 154/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5310 - accuracy: 0.7413 - val_loss: 0.5548 - val_accuracy: 0.7396\n",
      "Epoch 155/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5307 - accuracy: 0.7413 - val_loss: 0.5545 - val_accuracy: 0.7396\n",
      "Epoch 156/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5303 - accuracy: 0.7448 - val_loss: 0.5543 - val_accuracy: 0.7396\n",
      "Epoch 157/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5300 - accuracy: 0.7448 - val_loss: 0.5540 - val_accuracy: 0.7396\n",
      "Epoch 158/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5296 - accuracy: 0.7448 - val_loss: 0.5538 - val_accuracy: 0.7344\n",
      "Epoch 159/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5293 - accuracy: 0.7448 - val_loss: 0.5535 - val_accuracy: 0.7344\n",
      "Epoch 160/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5289 - accuracy: 0.7483 - val_loss: 0.5533 - val_accuracy: 0.7344\n",
      "Epoch 161/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5286 - accuracy: 0.7483 - val_loss: 0.5531 - val_accuracy: 0.7344\n",
      "Epoch 162/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5283 - accuracy: 0.7517 - val_loss: 0.5528 - val_accuracy: 0.7396\n",
      "Epoch 163/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5280 - accuracy: 0.7535 - val_loss: 0.5526 - val_accuracy: 0.7396\n",
      "Epoch 164/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5276 - accuracy: 0.7535 - val_loss: 0.5523 - val_accuracy: 0.7396\n",
      "Epoch 165/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5273 - accuracy: 0.7535 - val_loss: 0.5521 - val_accuracy: 0.7396\n",
      "Epoch 166/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5270 - accuracy: 0.7535 - val_loss: 0.5519 - val_accuracy: 0.7396\n",
      "Epoch 167/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5266 - accuracy: 0.7535 - val_loss: 0.5516 - val_accuracy: 0.7396\n",
      "Epoch 168/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5263 - accuracy: 0.7535 - val_loss: 0.5514 - val_accuracy: 0.7448\n",
      "Epoch 169/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5260 - accuracy: 0.7535 - val_loss: 0.5511 - val_accuracy: 0.7448\n",
      "Epoch 170/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5257 - accuracy: 0.7535 - val_loss: 0.5509 - val_accuracy: 0.7448\n",
      "Epoch 171/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5253 - accuracy: 0.7535 - val_loss: 0.5507 - val_accuracy: 0.7448\n",
      "Epoch 172/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5250 - accuracy: 0.7535 - val_loss: 0.5504 - val_accuracy: 0.7448\n",
      "Epoch 173/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5247 - accuracy: 0.7552 - val_loss: 0.5502 - val_accuracy: 0.7396\n",
      "Epoch 174/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5244 - accuracy: 0.7569 - val_loss: 0.5500 - val_accuracy: 0.7344\n",
      "Epoch 175/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5241 - accuracy: 0.7569 - val_loss: 0.5498 - val_accuracy: 0.7344\n",
      "Epoch 176/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5237 - accuracy: 0.7569 - val_loss: 0.5495 - val_accuracy: 0.7344\n",
      "Epoch 177/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5235 - accuracy: 0.7604 - val_loss: 0.5493 - val_accuracy: 0.7344\n",
      "Epoch 178/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5231 - accuracy: 0.7622 - val_loss: 0.5491 - val_accuracy: 0.7344\n",
      "Epoch 179/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5228 - accuracy: 0.7622 - val_loss: 0.5489 - val_accuracy: 0.7344\n",
      "Epoch 180/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5225 - accuracy: 0.7622 - val_loss: 0.5486 - val_accuracy: 0.7344\n",
      "Epoch 181/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5222 - accuracy: 0.7622 - val_loss: 0.5484 - val_accuracy: 0.7344\n",
      "Epoch 182/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5219 - accuracy: 0.7604 - val_loss: 0.5482 - val_accuracy: 0.7344\n",
      "Epoch 183/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5216 - accuracy: 0.7604 - val_loss: 0.5480 - val_accuracy: 0.7344\n",
      "Epoch 184/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5212 - accuracy: 0.7604 - val_loss: 0.5478 - val_accuracy: 0.7344\n",
      "Epoch 185/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5210 - accuracy: 0.7604 - val_loss: 0.5475 - val_accuracy: 0.7344\n",
      "Epoch 186/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5207 - accuracy: 0.7604 - val_loss: 0.5473 - val_accuracy: 0.7344\n",
      "Epoch 187/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5203 - accuracy: 0.7604 - val_loss: 0.5471 - val_accuracy: 0.7344\n",
      "Epoch 188/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5200 - accuracy: 0.7604 - val_loss: 0.5469 - val_accuracy: 0.7396\n",
      "Epoch 189/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5197 - accuracy: 0.7604 - val_loss: 0.5467 - val_accuracy: 0.7396\n",
      "Epoch 190/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5194 - accuracy: 0.7604 - val_loss: 0.5465 - val_accuracy: 0.7344\n",
      "Epoch 191/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5191 - accuracy: 0.7604 - val_loss: 0.5463 - val_accuracy: 0.7344\n",
      "Epoch 192/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5188 - accuracy: 0.7604 - val_loss: 0.5460 - val_accuracy: 0.7344\n",
      "Epoch 193/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5185 - accuracy: 0.7622 - val_loss: 0.5458 - val_accuracy: 0.7344\n",
      "Epoch 194/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5182 - accuracy: 0.7604 - val_loss: 0.5456 - val_accuracy: 0.7344\n",
      "Epoch 195/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5179 - accuracy: 0.7604 - val_loss: 0.5454 - val_accuracy: 0.7344\n",
      "Epoch 196/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5176 - accuracy: 0.7604 - val_loss: 0.5452 - val_accuracy: 0.7344\n",
      "Epoch 197/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5174 - accuracy: 0.7587 - val_loss: 0.5450 - val_accuracy: 0.7344\n",
      "Epoch 198/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5171 - accuracy: 0.7569 - val_loss: 0.5448 - val_accuracy: 0.7344\n",
      "Epoch 199/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5168 - accuracy: 0.7622 - val_loss: 0.5446 - val_accuracy: 0.7344\n",
      "Epoch 200/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5165 - accuracy: 0.7604 - val_loss: 0.5444 - val_accuracy: 0.7396\n"
     ]
    }
   ],
   "source": [
    "# Fit(Train) the Model\n",
    "\n",
    "# Compile the model with Optimizer, Loss Function and Metrics\n",
    "# Roc-Auc is not available in Keras as an off the shelf metric yet, so we will skip it here.\n",
    "\n",
    "model_1.compile(SGD(lr=.003), \"binary_crossentropy\", metrics=['accuracy'])\n",
    "run_hist_1 = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=200)\n",
    "# the fit function returns the run history.\n",
    "# It is very convenient, as it contains information about the model fit, iterations etc."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Like we did for the Random Forest, we generate two kinds of predictions\n",
    "#  One is a hard decision, the other is a probabilitistic score.\n",
    "\n",
    "y_pred_prob_nn_1 = model_1.predict(X_test_norm)\n",
    "y_pred_class_nn_1 = (y_pred_prob_nn_1 > 0.5).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0],\n       [0],\n       [0],\n       [0],\n       [0],\n       [0],\n       [0],\n       [0],\n       [0],\n       [1]])"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check out the outputs to get a feel for how keras apis work.\n",
    "y_pred_class_nn_1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.39327326],\n       [0.23377359],\n       [0.21723568],\n       [0.2932226 ],\n       [0.41744727],\n       [0.47314852],\n       [0.1210196 ],\n       [0.43828034],\n       [0.43265867],\n       [0.5197805 ]], dtype=float32)"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_prob_nn_1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.740\n",
      "roc-auc is 0.800\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 576x576 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print model performance and plot the roc curve\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_1)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_1)))\n",
    "\n",
    "plot_roc(y_test, y_pred_prob_nn_1, 'NN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There may be some variation in exact numbers due to randomness, but you should get results in the same ballpark as the Random Forest - between 75% and 85% accuracy, between .8 and .9 for AUC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the `run_hist_1` object that was created, specifically its `history` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_hist_1.history.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the training loss and the validation loss over the different epochs and see how it looks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.legend.Legend at 0x2b12e4e95b0>"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
    "ax.plot(run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the losses are still going down on both the training set and the validation set.  This suggests that the model might benefit from further training.  Let's train the model a little more and see what happens. Note that it will pick up from where it left off. Train for 1000 more epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5162 - accuracy: 0.7622 - val_loss: 0.5442 - val_accuracy: 0.7396\n",
      "Epoch 2/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5159 - accuracy: 0.7587 - val_loss: 0.5440 - val_accuracy: 0.7396\n",
      "Epoch 3/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5156 - accuracy: 0.7587 - val_loss: 0.5438 - val_accuracy: 0.7396\n",
      "Epoch 4/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5154 - accuracy: 0.7587 - val_loss: 0.5436 - val_accuracy: 0.7396\n",
      "Epoch 5/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5151 - accuracy: 0.7569 - val_loss: 0.5434 - val_accuracy: 0.7396\n",
      "Epoch 6/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5148 - accuracy: 0.7569 - val_loss: 0.5432 - val_accuracy: 0.7396\n",
      "Epoch 7/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5145 - accuracy: 0.7587 - val_loss: 0.5431 - val_accuracy: 0.7396\n",
      "Epoch 8/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5142 - accuracy: 0.7569 - val_loss: 0.5429 - val_accuracy: 0.7396\n",
      "Epoch 9/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5140 - accuracy: 0.7604 - val_loss: 0.5427 - val_accuracy: 0.7396\n",
      "Epoch 10/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5137 - accuracy: 0.7604 - val_loss: 0.5425 - val_accuracy: 0.7396\n",
      "Epoch 11/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5134 - accuracy: 0.7604 - val_loss: 0.5423 - val_accuracy: 0.7396\n",
      "Epoch 12/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5131 - accuracy: 0.7604 - val_loss: 0.5421 - val_accuracy: 0.7396\n",
      "Epoch 13/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5129 - accuracy: 0.7604 - val_loss: 0.5419 - val_accuracy: 0.7396\n",
      "Epoch 14/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5126 - accuracy: 0.7622 - val_loss: 0.5417 - val_accuracy: 0.7396\n",
      "Epoch 15/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5123 - accuracy: 0.7604 - val_loss: 0.5416 - val_accuracy: 0.7396\n",
      "Epoch 16/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5120 - accuracy: 0.7622 - val_loss: 0.5414 - val_accuracy: 0.7396\n",
      "Epoch 17/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5118 - accuracy: 0.7639 - val_loss: 0.5412 - val_accuracy: 0.7396\n",
      "Epoch 18/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5115 - accuracy: 0.7656 - val_loss: 0.5410 - val_accuracy: 0.7396\n",
      "Epoch 19/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5112 - accuracy: 0.7639 - val_loss: 0.5408 - val_accuracy: 0.7448\n",
      "Epoch 20/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5110 - accuracy: 0.7639 - val_loss: 0.5407 - val_accuracy: 0.7448\n",
      "Epoch 21/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5107 - accuracy: 0.7691 - val_loss: 0.5405 - val_accuracy: 0.7448\n",
      "Epoch 22/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5105 - accuracy: 0.7674 - val_loss: 0.5403 - val_accuracy: 0.7448\n",
      "Epoch 23/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5102 - accuracy: 0.7656 - val_loss: 0.5401 - val_accuracy: 0.7448\n",
      "Epoch 24/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5099 - accuracy: 0.7674 - val_loss: 0.5400 - val_accuracy: 0.7448\n",
      "Epoch 25/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5097 - accuracy: 0.7674 - val_loss: 0.5398 - val_accuracy: 0.7448\n",
      "Epoch 26/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5094 - accuracy: 0.7674 - val_loss: 0.5396 - val_accuracy: 0.7448\n",
      "Epoch 27/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7674 - val_loss: 0.5394 - val_accuracy: 0.7448\n",
      "Epoch 28/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5089 - accuracy: 0.7674 - val_loss: 0.5393 - val_accuracy: 0.7500\n",
      "Epoch 29/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5086 - accuracy: 0.7674 - val_loss: 0.5391 - val_accuracy: 0.7500\n",
      "Epoch 30/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5084 - accuracy: 0.7674 - val_loss: 0.5389 - val_accuracy: 0.7552\n",
      "Epoch 31/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5081 - accuracy: 0.7674 - val_loss: 0.5388 - val_accuracy: 0.7552\n",
      "Epoch 32/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5079 - accuracy: 0.7674 - val_loss: 0.5386 - val_accuracy: 0.7552\n",
      "Epoch 33/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5076 - accuracy: 0.7656 - val_loss: 0.5384 - val_accuracy: 0.7552\n",
      "Epoch 34/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5074 - accuracy: 0.7656 - val_loss: 0.5383 - val_accuracy: 0.7552\n",
      "Epoch 35/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5072 - accuracy: 0.7656 - val_loss: 0.5381 - val_accuracy: 0.7552\n",
      "Epoch 36/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5069 - accuracy: 0.7656 - val_loss: 0.5380 - val_accuracy: 0.7552\n",
      "Epoch 37/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5067 - accuracy: 0.7656 - val_loss: 0.5378 - val_accuracy: 0.7552\n",
      "Epoch 38/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.7691 - val_loss: 0.5376 - val_accuracy: 0.7552\n",
      "Epoch 39/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.7691 - val_loss: 0.5375 - val_accuracy: 0.7552\n",
      "Epoch 40/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7691 - val_loss: 0.5373 - val_accuracy: 0.7552\n",
      "Epoch 41/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7691 - val_loss: 0.5372 - val_accuracy: 0.7552\n",
      "Epoch 42/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7691 - val_loss: 0.5370 - val_accuracy: 0.7552\n",
      "Epoch 43/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7708 - val_loss: 0.5369 - val_accuracy: 0.7552\n",
      "Epoch 44/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7674 - val_loss: 0.5367 - val_accuracy: 0.7552\n",
      "Epoch 45/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7674 - val_loss: 0.5365 - val_accuracy: 0.7500\n",
      "Epoch 46/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7674 - val_loss: 0.5364 - val_accuracy: 0.7500\n",
      "Epoch 47/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7674 - val_loss: 0.5362 - val_accuracy: 0.7500\n",
      "Epoch 48/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7674 - val_loss: 0.5361 - val_accuracy: 0.7500\n",
      "Epoch 49/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7674 - val_loss: 0.5359 - val_accuracy: 0.7552\n",
      "Epoch 50/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7674 - val_loss: 0.5358 - val_accuracy: 0.7552\n",
      "Epoch 51/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7674 - val_loss: 0.5357 - val_accuracy: 0.7552\n",
      "Epoch 52/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7674 - val_loss: 0.5355 - val_accuracy: 0.7552\n",
      "Epoch 53/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7656 - val_loss: 0.5354 - val_accuracy: 0.7552\n",
      "Epoch 54/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7656 - val_loss: 0.5352 - val_accuracy: 0.7552\n",
      "Epoch 55/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5024 - accuracy: 0.7656 - val_loss: 0.5351 - val_accuracy: 0.7552\n",
      "Epoch 56/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5022 - accuracy: 0.7656 - val_loss: 0.5349 - val_accuracy: 0.7552\n",
      "Epoch 57/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5020 - accuracy: 0.7674 - val_loss: 0.5348 - val_accuracy: 0.7552\n",
      "Epoch 58/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5017 - accuracy: 0.7656 - val_loss: 0.5347 - val_accuracy: 0.7552\n",
      "Epoch 59/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5015 - accuracy: 0.7656 - val_loss: 0.5345 - val_accuracy: 0.7552\n",
      "Epoch 60/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5013 - accuracy: 0.7656 - val_loss: 0.5344 - val_accuracy: 0.7500\n",
      "Epoch 61/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5011 - accuracy: 0.7639 - val_loss: 0.5342 - val_accuracy: 0.7500\n",
      "Epoch 62/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5009 - accuracy: 0.7639 - val_loss: 0.5341 - val_accuracy: 0.7500\n",
      "Epoch 63/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5006 - accuracy: 0.7622 - val_loss: 0.5340 - val_accuracy: 0.7500\n",
      "Epoch 64/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5004 - accuracy: 0.7622 - val_loss: 0.5338 - val_accuracy: 0.7500\n",
      "Epoch 65/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5002 - accuracy: 0.7639 - val_loss: 0.5337 - val_accuracy: 0.7552\n",
      "Epoch 66/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5000 - accuracy: 0.7639 - val_loss: 0.5336 - val_accuracy: 0.7604\n",
      "Epoch 67/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4998 - accuracy: 0.7639 - val_loss: 0.5334 - val_accuracy: 0.7604\n",
      "Epoch 68/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4996 - accuracy: 0.7639 - val_loss: 0.5333 - val_accuracy: 0.7552\n",
      "Epoch 69/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4993 - accuracy: 0.7639 - val_loss: 0.5332 - val_accuracy: 0.7552\n",
      "Epoch 70/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4991 - accuracy: 0.7639 - val_loss: 0.5330 - val_accuracy: 0.7604\n",
      "Epoch 71/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4989 - accuracy: 0.7639 - val_loss: 0.5329 - val_accuracy: 0.7552\n",
      "Epoch 72/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4987 - accuracy: 0.7639 - val_loss: 0.5328 - val_accuracy: 0.7552\n",
      "Epoch 73/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4985 - accuracy: 0.7639 - val_loss: 0.5327 - val_accuracy: 0.7552\n",
      "Epoch 74/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4983 - accuracy: 0.7656 - val_loss: 0.5325 - val_accuracy: 0.7552\n",
      "Epoch 75/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4981 - accuracy: 0.7656 - val_loss: 0.5324 - val_accuracy: 0.7552\n",
      "Epoch 76/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4979 - accuracy: 0.7656 - val_loss: 0.5323 - val_accuracy: 0.7552\n",
      "Epoch 77/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4977 - accuracy: 0.7656 - val_loss: 0.5322 - val_accuracy: 0.7552\n",
      "Epoch 78/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4975 - accuracy: 0.7656 - val_loss: 0.5320 - val_accuracy: 0.7552\n",
      "Epoch 79/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4973 - accuracy: 0.7656 - val_loss: 0.5319 - val_accuracy: 0.7552\n",
      "Epoch 80/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4971 - accuracy: 0.7656 - val_loss: 0.5318 - val_accuracy: 0.7604\n",
      "Epoch 81/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4969 - accuracy: 0.7639 - val_loss: 0.5317 - val_accuracy: 0.7604\n",
      "Epoch 82/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4967 - accuracy: 0.7656 - val_loss: 0.5316 - val_accuracy: 0.7604\n",
      "Epoch 83/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4965 - accuracy: 0.7639 - val_loss: 0.5314 - val_accuracy: 0.7552\n",
      "Epoch 84/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4963 - accuracy: 0.7639 - val_loss: 0.5313 - val_accuracy: 0.7552\n",
      "Epoch 85/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4961 - accuracy: 0.7639 - val_loss: 0.5312 - val_accuracy: 0.7552\n",
      "Epoch 86/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4959 - accuracy: 0.7639 - val_loss: 0.5311 - val_accuracy: 0.7552\n",
      "Epoch 87/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4957 - accuracy: 0.7639 - val_loss: 0.5310 - val_accuracy: 0.7552\n",
      "Epoch 88/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4955 - accuracy: 0.7639 - val_loss: 0.5309 - val_accuracy: 0.7552\n",
      "Epoch 89/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4953 - accuracy: 0.7656 - val_loss: 0.5307 - val_accuracy: 0.7552\n",
      "Epoch 90/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4951 - accuracy: 0.7639 - val_loss: 0.5306 - val_accuracy: 0.7552\n",
      "Epoch 91/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4949 - accuracy: 0.7639 - val_loss: 0.5305 - val_accuracy: 0.7552\n",
      "Epoch 92/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4947 - accuracy: 0.7639 - val_loss: 0.5304 - val_accuracy: 0.7552\n",
      "Epoch 93/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4945 - accuracy: 0.7639 - val_loss: 0.5303 - val_accuracy: 0.7552\n",
      "Epoch 94/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4943 - accuracy: 0.7639 - val_loss: 0.5302 - val_accuracy: 0.7552\n",
      "Epoch 95/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4942 - accuracy: 0.7639 - val_loss: 0.5301 - val_accuracy: 0.7552\n",
      "Epoch 96/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4940 - accuracy: 0.7639 - val_loss: 0.5300 - val_accuracy: 0.7552\n",
      "Epoch 97/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4938 - accuracy: 0.7639 - val_loss: 0.5299 - val_accuracy: 0.7552\n",
      "Epoch 98/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4936 - accuracy: 0.7639 - val_loss: 0.5298 - val_accuracy: 0.7552\n",
      "Epoch 99/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4934 - accuracy: 0.7639 - val_loss: 0.5296 - val_accuracy: 0.7552\n",
      "Epoch 100/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4932 - accuracy: 0.7639 - val_loss: 0.5295 - val_accuracy: 0.7552\n",
      "Epoch 101/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4931 - accuracy: 0.7639 - val_loss: 0.5294 - val_accuracy: 0.7552\n",
      "Epoch 102/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4929 - accuracy: 0.7639 - val_loss: 0.5293 - val_accuracy: 0.7552\n",
      "Epoch 103/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4927 - accuracy: 0.7639 - val_loss: 0.5292 - val_accuracy: 0.7552\n",
      "Epoch 104/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4925 - accuracy: 0.7639 - val_loss: 0.5291 - val_accuracy: 0.7552\n",
      "Epoch 105/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4923 - accuracy: 0.7639 - val_loss: 0.5290 - val_accuracy: 0.7552\n",
      "Epoch 106/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4921 - accuracy: 0.7639 - val_loss: 0.5289 - val_accuracy: 0.7552\n",
      "Epoch 107/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4920 - accuracy: 0.7639 - val_loss: 0.5288 - val_accuracy: 0.7552\n",
      "Epoch 108/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4918 - accuracy: 0.7639 - val_loss: 0.5287 - val_accuracy: 0.7552\n",
      "Epoch 109/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4916 - accuracy: 0.7639 - val_loss: 0.5286 - val_accuracy: 0.7604\n",
      "Epoch 110/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4914 - accuracy: 0.7639 - val_loss: 0.5285 - val_accuracy: 0.7604\n",
      "Epoch 111/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4913 - accuracy: 0.7639 - val_loss: 0.5284 - val_accuracy: 0.7604\n",
      "Epoch 112/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4911 - accuracy: 0.7639 - val_loss: 0.5283 - val_accuracy: 0.7604\n",
      "Epoch 113/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4909 - accuracy: 0.7639 - val_loss: 0.5282 - val_accuracy: 0.7604\n",
      "Epoch 114/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4908 - accuracy: 0.7639 - val_loss: 0.5281 - val_accuracy: 0.7604\n",
      "Epoch 115/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4906 - accuracy: 0.7639 - val_loss: 0.5280 - val_accuracy: 0.7604\n",
      "Epoch 116/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4904 - accuracy: 0.7639 - val_loss: 0.5280 - val_accuracy: 0.7604\n",
      "Epoch 117/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4903 - accuracy: 0.7639 - val_loss: 0.5279 - val_accuracy: 0.7604\n",
      "Epoch 118/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4901 - accuracy: 0.7639 - val_loss: 0.5278 - val_accuracy: 0.7604\n",
      "Epoch 119/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4899 - accuracy: 0.7639 - val_loss: 0.5277 - val_accuracy: 0.7604\n",
      "Epoch 120/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4898 - accuracy: 0.7656 - val_loss: 0.5276 - val_accuracy: 0.7604\n",
      "Epoch 121/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4896 - accuracy: 0.7656 - val_loss: 0.5275 - val_accuracy: 0.7604\n",
      "Epoch 122/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4894 - accuracy: 0.7656 - val_loss: 0.5274 - val_accuracy: 0.7604\n",
      "Epoch 123/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4893 - accuracy: 0.7656 - val_loss: 0.5273 - val_accuracy: 0.7604\n",
      "Epoch 124/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4891 - accuracy: 0.7656 - val_loss: 0.5272 - val_accuracy: 0.7604\n",
      "Epoch 125/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4889 - accuracy: 0.7656 - val_loss: 0.5271 - val_accuracy: 0.7604\n",
      "Epoch 126/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4888 - accuracy: 0.7656 - val_loss: 0.5271 - val_accuracy: 0.7604\n",
      "Epoch 127/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4886 - accuracy: 0.7656 - val_loss: 0.5270 - val_accuracy: 0.7604\n",
      "Epoch 128/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.7656 - val_loss: 0.5269 - val_accuracy: 0.7604\n",
      "Epoch 129/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4883 - accuracy: 0.7656 - val_loss: 0.5268 - val_accuracy: 0.7604\n",
      "Epoch 130/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4881 - accuracy: 0.7656 - val_loss: 0.5267 - val_accuracy: 0.7604\n",
      "Epoch 131/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4880 - accuracy: 0.7656 - val_loss: 0.5266 - val_accuracy: 0.7604\n",
      "Epoch 132/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4878 - accuracy: 0.7656 - val_loss: 0.5265 - val_accuracy: 0.7604\n",
      "Epoch 133/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4877 - accuracy: 0.7656 - val_loss: 0.5265 - val_accuracy: 0.7604\n",
      "Epoch 134/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4875 - accuracy: 0.7656 - val_loss: 0.5264 - val_accuracy: 0.7604\n",
      "Epoch 135/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4873 - accuracy: 0.7656 - val_loss: 0.5263 - val_accuracy: 0.7552\n",
      "Epoch 136/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4872 - accuracy: 0.7656 - val_loss: 0.5262 - val_accuracy: 0.7552\n",
      "Epoch 137/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4870 - accuracy: 0.7674 - val_loss: 0.5261 - val_accuracy: 0.7552\n",
      "Epoch 138/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4869 - accuracy: 0.7674 - val_loss: 0.5261 - val_accuracy: 0.7552\n",
      "Epoch 139/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4867 - accuracy: 0.7674 - val_loss: 0.5260 - val_accuracy: 0.7552\n",
      "Epoch 140/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4866 - accuracy: 0.7674 - val_loss: 0.5259 - val_accuracy: 0.7552\n",
      "Epoch 141/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4864 - accuracy: 0.7674 - val_loss: 0.5258 - val_accuracy: 0.7552\n",
      "Epoch 142/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4863 - accuracy: 0.7674 - val_loss: 0.5257 - val_accuracy: 0.7552\n",
      "Epoch 143/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4861 - accuracy: 0.7674 - val_loss: 0.5257 - val_accuracy: 0.7552\n",
      "Epoch 144/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4860 - accuracy: 0.7674 - val_loss: 0.5256 - val_accuracy: 0.7500\n",
      "Epoch 145/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4858 - accuracy: 0.7674 - val_loss: 0.5255 - val_accuracy: 0.7448\n",
      "Epoch 146/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4857 - accuracy: 0.7674 - val_loss: 0.5254 - val_accuracy: 0.7448\n",
      "Epoch 147/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4855 - accuracy: 0.7674 - val_loss: 0.5254 - val_accuracy: 0.7448\n",
      "Epoch 148/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4854 - accuracy: 0.7674 - val_loss: 0.5253 - val_accuracy: 0.7448\n",
      "Epoch 149/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4852 - accuracy: 0.7674 - val_loss: 0.5252 - val_accuracy: 0.7448\n",
      "Epoch 150/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4851 - accuracy: 0.7674 - val_loss: 0.5251 - val_accuracy: 0.7500\n",
      "Epoch 151/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4850 - accuracy: 0.7674 - val_loss: 0.5251 - val_accuracy: 0.7552\n",
      "Epoch 152/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4848 - accuracy: 0.7674 - val_loss: 0.5250 - val_accuracy: 0.7552\n",
      "Epoch 153/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4847 - accuracy: 0.7674 - val_loss: 0.5249 - val_accuracy: 0.7552\n",
      "Epoch 154/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4846 - accuracy: 0.7674 - val_loss: 0.5249 - val_accuracy: 0.7552\n",
      "Epoch 155/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4844 - accuracy: 0.7656 - val_loss: 0.5248 - val_accuracy: 0.7604\n",
      "Epoch 156/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4843 - accuracy: 0.7674 - val_loss: 0.5247 - val_accuracy: 0.7552\n",
      "Epoch 157/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4841 - accuracy: 0.7656 - val_loss: 0.5246 - val_accuracy: 0.7552\n",
      "Epoch 158/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4840 - accuracy: 0.7656 - val_loss: 0.5246 - val_accuracy: 0.7552\n",
      "Epoch 159/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4838 - accuracy: 0.7639 - val_loss: 0.5245 - val_accuracy: 0.7552\n",
      "Epoch 160/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4837 - accuracy: 0.7639 - val_loss: 0.5244 - val_accuracy: 0.7552\n",
      "Epoch 161/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4836 - accuracy: 0.7639 - val_loss: 0.5244 - val_accuracy: 0.7552\n",
      "Epoch 162/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4835 - accuracy: 0.7639 - val_loss: 0.5243 - val_accuracy: 0.7552\n",
      "Epoch 163/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4833 - accuracy: 0.7639 - val_loss: 0.5242 - val_accuracy: 0.7552\n",
      "Epoch 164/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4832 - accuracy: 0.7639 - val_loss: 0.5242 - val_accuracy: 0.7500\n",
      "Epoch 165/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4830 - accuracy: 0.7639 - val_loss: 0.5241 - val_accuracy: 0.7500\n",
      "Epoch 166/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4829 - accuracy: 0.7639 - val_loss: 0.5240 - val_accuracy: 0.7500\n",
      "Epoch 167/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4828 - accuracy: 0.7639 - val_loss: 0.5240 - val_accuracy: 0.7500\n",
      "Epoch 168/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4827 - accuracy: 0.7639 - val_loss: 0.5239 - val_accuracy: 0.7500\n",
      "Epoch 169/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4825 - accuracy: 0.7639 - val_loss: 0.5239 - val_accuracy: 0.7500\n",
      "Epoch 170/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4824 - accuracy: 0.7639 - val_loss: 0.5238 - val_accuracy: 0.7500\n",
      "Epoch 171/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4822 - accuracy: 0.7639 - val_loss: 0.5237 - val_accuracy: 0.7500\n",
      "Epoch 172/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4821 - accuracy: 0.7639 - val_loss: 0.5237 - val_accuracy: 0.7500\n",
      "Epoch 173/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4820 - accuracy: 0.7639 - val_loss: 0.5236 - val_accuracy: 0.7500\n",
      "Epoch 174/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4819 - accuracy: 0.7639 - val_loss: 0.5235 - val_accuracy: 0.7500\n",
      "Epoch 175/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4817 - accuracy: 0.7639 - val_loss: 0.5235 - val_accuracy: 0.7500\n",
      "Epoch 176/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4816 - accuracy: 0.7656 - val_loss: 0.5234 - val_accuracy: 0.7500\n",
      "Epoch 177/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4815 - accuracy: 0.7639 - val_loss: 0.5234 - val_accuracy: 0.7500\n",
      "Epoch 178/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4813 - accuracy: 0.7674 - val_loss: 0.5233 - val_accuracy: 0.7500\n",
      "Epoch 179/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4812 - accuracy: 0.7656 - val_loss: 0.5232 - val_accuracy: 0.7500\n",
      "Epoch 180/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4811 - accuracy: 0.7656 - val_loss: 0.5232 - val_accuracy: 0.7500\n",
      "Epoch 181/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4810 - accuracy: 0.7674 - val_loss: 0.5231 - val_accuracy: 0.7500\n",
      "Epoch 182/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4808 - accuracy: 0.7674 - val_loss: 0.5231 - val_accuracy: 0.7552\n",
      "Epoch 183/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4807 - accuracy: 0.7674 - val_loss: 0.5230 - val_accuracy: 0.7552\n",
      "Epoch 184/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4806 - accuracy: 0.7674 - val_loss: 0.5230 - val_accuracy: 0.7552\n",
      "Epoch 185/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4805 - accuracy: 0.7674 - val_loss: 0.5229 - val_accuracy: 0.7552\n",
      "Epoch 186/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4804 - accuracy: 0.7674 - val_loss: 0.5229 - val_accuracy: 0.7552\n",
      "Epoch 187/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4802 - accuracy: 0.7674 - val_loss: 0.5228 - val_accuracy: 0.7552\n",
      "Epoch 188/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4801 - accuracy: 0.7656 - val_loss: 0.5227 - val_accuracy: 0.7552\n",
      "Epoch 189/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4800 - accuracy: 0.7674 - val_loss: 0.5227 - val_accuracy: 0.7552\n",
      "Epoch 190/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4799 - accuracy: 0.7674 - val_loss: 0.5226 - val_accuracy: 0.7552\n",
      "Epoch 191/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4798 - accuracy: 0.7674 - val_loss: 0.5226 - val_accuracy: 0.7552\n",
      "Epoch 192/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4796 - accuracy: 0.7656 - val_loss: 0.5225 - val_accuracy: 0.7552\n",
      "Epoch 193/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4795 - accuracy: 0.7674 - val_loss: 0.5225 - val_accuracy: 0.7552\n",
      "Epoch 194/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4794 - accuracy: 0.7656 - val_loss: 0.5224 - val_accuracy: 0.7552\n",
      "Epoch 195/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4793 - accuracy: 0.7674 - val_loss: 0.5224 - val_accuracy: 0.7552\n",
      "Epoch 196/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4792 - accuracy: 0.7674 - val_loss: 0.5223 - val_accuracy: 0.7552\n",
      "Epoch 197/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4791 - accuracy: 0.7674 - val_loss: 0.5223 - val_accuracy: 0.7552\n",
      "Epoch 198/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4790 - accuracy: 0.7674 - val_loss: 0.5222 - val_accuracy: 0.7552\n",
      "Epoch 199/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4788 - accuracy: 0.7674 - val_loss: 0.5222 - val_accuracy: 0.7552\n",
      "Epoch 200/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4787 - accuracy: 0.7674 - val_loss: 0.5221 - val_accuracy: 0.7552\n",
      "Epoch 201/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4786 - accuracy: 0.7674 - val_loss: 0.5221 - val_accuracy: 0.7552\n",
      "Epoch 202/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4785 - accuracy: 0.7674 - val_loss: 0.5220 - val_accuracy: 0.7552\n",
      "Epoch 203/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4784 - accuracy: 0.7674 - val_loss: 0.5220 - val_accuracy: 0.7552\n",
      "Epoch 204/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4783 - accuracy: 0.7674 - val_loss: 0.5219 - val_accuracy: 0.7552\n",
      "Epoch 205/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4782 - accuracy: 0.7674 - val_loss: 0.5219 - val_accuracy: 0.7552\n",
      "Epoch 206/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4781 - accuracy: 0.7674 - val_loss: 0.5218 - val_accuracy: 0.7552\n",
      "Epoch 207/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4779 - accuracy: 0.7674 - val_loss: 0.5218 - val_accuracy: 0.7552\n",
      "Epoch 208/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4778 - accuracy: 0.7674 - val_loss: 0.5217 - val_accuracy: 0.7552\n",
      "Epoch 209/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4777 - accuracy: 0.7674 - val_loss: 0.5217 - val_accuracy: 0.7552\n",
      "Epoch 210/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4776 - accuracy: 0.7674 - val_loss: 0.5216 - val_accuracy: 0.7552\n",
      "Epoch 211/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4775 - accuracy: 0.7674 - val_loss: 0.5216 - val_accuracy: 0.7552\n",
      "Epoch 212/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4774 - accuracy: 0.7674 - val_loss: 0.5215 - val_accuracy: 0.7552\n",
      "Epoch 213/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4773 - accuracy: 0.7674 - val_loss: 0.5215 - val_accuracy: 0.7552\n",
      "Epoch 214/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4772 - accuracy: 0.7674 - val_loss: 0.5215 - val_accuracy: 0.7552\n",
      "Epoch 215/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4771 - accuracy: 0.7674 - val_loss: 0.5214 - val_accuracy: 0.7552\n",
      "Epoch 216/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4770 - accuracy: 0.7674 - val_loss: 0.5214 - val_accuracy: 0.7552\n",
      "Epoch 217/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4769 - accuracy: 0.7674 - val_loss: 0.5213 - val_accuracy: 0.7552\n",
      "Epoch 218/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4768 - accuracy: 0.7674 - val_loss: 0.5213 - val_accuracy: 0.7552\n",
      "Epoch 219/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4767 - accuracy: 0.7691 - val_loss: 0.5212 - val_accuracy: 0.7552\n",
      "Epoch 220/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4766 - accuracy: 0.7674 - val_loss: 0.5212 - val_accuracy: 0.7552\n",
      "Epoch 221/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4765 - accuracy: 0.7674 - val_loss: 0.5212 - val_accuracy: 0.7500\n",
      "Epoch 222/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4764 - accuracy: 0.7691 - val_loss: 0.5211 - val_accuracy: 0.7500\n",
      "Epoch 223/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4763 - accuracy: 0.7674 - val_loss: 0.5211 - val_accuracy: 0.7500\n",
      "Epoch 224/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4762 - accuracy: 0.7691 - val_loss: 0.5210 - val_accuracy: 0.7500\n",
      "Epoch 225/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4761 - accuracy: 0.7674 - val_loss: 0.5210 - val_accuracy: 0.7500\n",
      "Epoch 226/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4760 - accuracy: 0.7674 - val_loss: 0.5209 - val_accuracy: 0.7500\n",
      "Epoch 227/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4758 - accuracy: 0.7691 - val_loss: 0.5209 - val_accuracy: 0.7500\n",
      "Epoch 228/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4758 - accuracy: 0.7674 - val_loss: 0.5209 - val_accuracy: 0.7500\n",
      "Epoch 229/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4757 - accuracy: 0.7674 - val_loss: 0.5208 - val_accuracy: 0.7500\n",
      "Epoch 230/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4756 - accuracy: 0.7691 - val_loss: 0.5208 - val_accuracy: 0.7448\n",
      "Epoch 231/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4755 - accuracy: 0.7691 - val_loss: 0.5208 - val_accuracy: 0.7448\n",
      "Epoch 232/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4754 - accuracy: 0.7691 - val_loss: 0.5207 - val_accuracy: 0.7448\n",
      "Epoch 233/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4753 - accuracy: 0.7691 - val_loss: 0.5207 - val_accuracy: 0.7448\n",
      "Epoch 234/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4752 - accuracy: 0.7691 - val_loss: 0.5206 - val_accuracy: 0.7448\n",
      "Epoch 235/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4751 - accuracy: 0.7691 - val_loss: 0.5206 - val_accuracy: 0.7448\n",
      "Epoch 236/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4750 - accuracy: 0.7691 - val_loss: 0.5206 - val_accuracy: 0.7448\n",
      "Epoch 237/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4749 - accuracy: 0.7691 - val_loss: 0.5205 - val_accuracy: 0.7500\n",
      "Epoch 238/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4748 - accuracy: 0.7691 - val_loss: 0.5205 - val_accuracy: 0.7500\n",
      "Epoch 239/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4747 - accuracy: 0.7708 - val_loss: 0.5205 - val_accuracy: 0.7500\n",
      "Epoch 240/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4746 - accuracy: 0.7691 - val_loss: 0.5204 - val_accuracy: 0.7500\n",
      "Epoch 241/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4745 - accuracy: 0.7708 - val_loss: 0.5204 - val_accuracy: 0.7500\n",
      "Epoch 242/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4744 - accuracy: 0.7708 - val_loss: 0.5203 - val_accuracy: 0.7500\n",
      "Epoch 243/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4743 - accuracy: 0.7691 - val_loss: 0.5203 - val_accuracy: 0.7500\n",
      "Epoch 244/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4742 - accuracy: 0.7726 - val_loss: 0.5203 - val_accuracy: 0.7500\n",
      "Epoch 245/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4741 - accuracy: 0.7708 - val_loss: 0.5202 - val_accuracy: 0.7500\n",
      "Epoch 246/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4740 - accuracy: 0.7726 - val_loss: 0.5202 - val_accuracy: 0.7500\n",
      "Epoch 247/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4740 - accuracy: 0.7726 - val_loss: 0.5202 - val_accuracy: 0.7500\n",
      "Epoch 248/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4739 - accuracy: 0.7726 - val_loss: 0.5201 - val_accuracy: 0.7500\n",
      "Epoch 249/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4738 - accuracy: 0.7726 - val_loss: 0.5201 - val_accuracy: 0.7500\n",
      "Epoch 250/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4737 - accuracy: 0.7726 - val_loss: 0.5201 - val_accuracy: 0.7500\n",
      "Epoch 251/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4736 - accuracy: 0.7726 - val_loss: 0.5200 - val_accuracy: 0.7552\n",
      "Epoch 252/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4735 - accuracy: 0.7726 - val_loss: 0.5200 - val_accuracy: 0.7552\n",
      "Epoch 253/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4734 - accuracy: 0.7726 - val_loss: 0.5200 - val_accuracy: 0.7552\n",
      "Epoch 254/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4733 - accuracy: 0.7726 - val_loss: 0.5199 - val_accuracy: 0.7552\n",
      "Epoch 255/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4732 - accuracy: 0.7726 - val_loss: 0.5199 - val_accuracy: 0.7552\n",
      "Epoch 256/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4732 - accuracy: 0.7726 - val_loss: 0.5199 - val_accuracy: 0.7552\n",
      "Epoch 257/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4731 - accuracy: 0.7726 - val_loss: 0.5198 - val_accuracy: 0.7552\n",
      "Epoch 258/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4730 - accuracy: 0.7726 - val_loss: 0.5198 - val_accuracy: 0.7552\n",
      "Epoch 259/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4729 - accuracy: 0.7726 - val_loss: 0.5198 - val_accuracy: 0.7552\n",
      "Epoch 260/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4728 - accuracy: 0.7726 - val_loss: 0.5198 - val_accuracy: 0.7552\n",
      "Epoch 261/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4727 - accuracy: 0.7726 - val_loss: 0.5197 - val_accuracy: 0.7552\n",
      "Epoch 262/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4727 - accuracy: 0.7726 - val_loss: 0.5197 - val_accuracy: 0.7552\n",
      "Epoch 263/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4726 - accuracy: 0.7726 - val_loss: 0.5197 - val_accuracy: 0.7552\n",
      "Epoch 264/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4725 - accuracy: 0.7726 - val_loss: 0.5196 - val_accuracy: 0.7552\n",
      "Epoch 265/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4724 - accuracy: 0.7726 - val_loss: 0.5196 - val_accuracy: 0.7552\n",
      "Epoch 266/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4723 - accuracy: 0.7726 - val_loss: 0.5196 - val_accuracy: 0.7552\n",
      "Epoch 267/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4722 - accuracy: 0.7726 - val_loss: 0.5195 - val_accuracy: 0.7500\n",
      "Epoch 268/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4721 - accuracy: 0.7726 - val_loss: 0.5195 - val_accuracy: 0.7500\n",
      "Epoch 269/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4721 - accuracy: 0.7726 - val_loss: 0.5195 - val_accuracy: 0.7500\n",
      "Epoch 270/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4720 - accuracy: 0.7726 - val_loss: 0.5195 - val_accuracy: 0.7500\n",
      "Epoch 271/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4719 - accuracy: 0.7726 - val_loss: 0.5194 - val_accuracy: 0.7500\n",
      "Epoch 272/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4718 - accuracy: 0.7726 - val_loss: 0.5194 - val_accuracy: 0.7500\n",
      "Epoch 273/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4717 - accuracy: 0.7726 - val_loss: 0.5194 - val_accuracy: 0.7500\n",
      "Epoch 274/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4717 - accuracy: 0.7726 - val_loss: 0.5194 - val_accuracy: 0.7500\n",
      "Epoch 275/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4716 - accuracy: 0.7726 - val_loss: 0.5193 - val_accuracy: 0.7500\n",
      "Epoch 276/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4715 - accuracy: 0.7726 - val_loss: 0.5193 - val_accuracy: 0.7500\n",
      "Epoch 277/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4714 - accuracy: 0.7726 - val_loss: 0.5193 - val_accuracy: 0.7500\n",
      "Epoch 278/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4713 - accuracy: 0.7726 - val_loss: 0.5193 - val_accuracy: 0.7500\n",
      "Epoch 279/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4713 - accuracy: 0.7726 - val_loss: 0.5192 - val_accuracy: 0.7500\n",
      "Epoch 280/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4712 - accuracy: 0.7708 - val_loss: 0.5192 - val_accuracy: 0.7500\n",
      "Epoch 281/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4711 - accuracy: 0.7708 - val_loss: 0.5192 - val_accuracy: 0.7500\n",
      "Epoch 282/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4710 - accuracy: 0.7708 - val_loss: 0.5191 - val_accuracy: 0.7500\n",
      "Epoch 283/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4710 - accuracy: 0.7726 - val_loss: 0.5191 - val_accuracy: 0.7500\n",
      "Epoch 284/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4709 - accuracy: 0.7726 - val_loss: 0.5191 - val_accuracy: 0.7500\n",
      "Epoch 285/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4708 - accuracy: 0.7708 - val_loss: 0.5191 - val_accuracy: 0.7500\n",
      "Epoch 286/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4707 - accuracy: 0.7708 - val_loss: 0.5190 - val_accuracy: 0.7500\n",
      "Epoch 287/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4706 - accuracy: 0.7708 - val_loss: 0.5190 - val_accuracy: 0.7500\n",
      "Epoch 288/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4706 - accuracy: 0.7708 - val_loss: 0.5190 - val_accuracy: 0.7500\n",
      "Epoch 289/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4705 - accuracy: 0.7708 - val_loss: 0.5190 - val_accuracy: 0.7500\n",
      "Epoch 290/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4704 - accuracy: 0.7726 - val_loss: 0.5190 - val_accuracy: 0.7500\n",
      "Epoch 291/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4704 - accuracy: 0.7708 - val_loss: 0.5189 - val_accuracy: 0.7500\n",
      "Epoch 292/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4703 - accuracy: 0.7708 - val_loss: 0.5189 - val_accuracy: 0.7448\n",
      "Epoch 293/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4702 - accuracy: 0.7708 - val_loss: 0.5189 - val_accuracy: 0.7448\n",
      "Epoch 294/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4701 - accuracy: 0.7708 - val_loss: 0.5189 - val_accuracy: 0.7448\n",
      "Epoch 295/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4700 - accuracy: 0.7708 - val_loss: 0.5188 - val_accuracy: 0.7448\n",
      "Epoch 296/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4700 - accuracy: 0.7708 - val_loss: 0.5188 - val_accuracy: 0.7448\n",
      "Epoch 297/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4699 - accuracy: 0.7708 - val_loss: 0.5188 - val_accuracy: 0.7448\n",
      "Epoch 298/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4698 - accuracy: 0.7708 - val_loss: 0.5188 - val_accuracy: 0.7448\n",
      "Epoch 299/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4698 - accuracy: 0.7708 - val_loss: 0.5187 - val_accuracy: 0.7448\n",
      "Epoch 300/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4697 - accuracy: 0.7708 - val_loss: 0.5187 - val_accuracy: 0.7448\n",
      "Epoch 301/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4696 - accuracy: 0.7708 - val_loss: 0.5187 - val_accuracy: 0.7448\n",
      "Epoch 302/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4695 - accuracy: 0.7708 - val_loss: 0.5187 - val_accuracy: 0.7448\n",
      "Epoch 303/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4695 - accuracy: 0.7708 - val_loss: 0.5187 - val_accuracy: 0.7396\n",
      "Epoch 304/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4694 - accuracy: 0.7708 - val_loss: 0.5186 - val_accuracy: 0.7396\n",
      "Epoch 305/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4693 - accuracy: 0.7708 - val_loss: 0.5186 - val_accuracy: 0.7396\n",
      "Epoch 306/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4693 - accuracy: 0.7726 - val_loss: 0.5186 - val_accuracy: 0.7396\n",
      "Epoch 307/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4692 - accuracy: 0.7726 - val_loss: 0.5186 - val_accuracy: 0.7396\n",
      "Epoch 308/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4691 - accuracy: 0.7726 - val_loss: 0.5186 - val_accuracy: 0.7396\n",
      "Epoch 309/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4691 - accuracy: 0.7726 - val_loss: 0.5185 - val_accuracy: 0.7396\n",
      "Epoch 310/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4690 - accuracy: 0.7726 - val_loss: 0.5185 - val_accuracy: 0.7396\n",
      "Epoch 311/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4689 - accuracy: 0.7726 - val_loss: 0.5185 - val_accuracy: 0.7396\n",
      "Epoch 312/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4688 - accuracy: 0.7726 - val_loss: 0.5185 - val_accuracy: 0.7396\n",
      "Epoch 313/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4688 - accuracy: 0.7726 - val_loss: 0.5185 - val_accuracy: 0.7396\n",
      "Epoch 314/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4687 - accuracy: 0.7726 - val_loss: 0.5184 - val_accuracy: 0.7396\n",
      "Epoch 315/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4686 - accuracy: 0.7726 - val_loss: 0.5184 - val_accuracy: 0.7396\n",
      "Epoch 316/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4686 - accuracy: 0.7726 - val_loss: 0.5184 - val_accuracy: 0.7396\n",
      "Epoch 317/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4685 - accuracy: 0.7708 - val_loss: 0.5184 - val_accuracy: 0.7396\n",
      "Epoch 318/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4684 - accuracy: 0.7726 - val_loss: 0.5184 - val_accuracy: 0.7396\n",
      "Epoch 319/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4684 - accuracy: 0.7726 - val_loss: 0.5183 - val_accuracy: 0.7396\n",
      "Epoch 320/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4683 - accuracy: 0.7726 - val_loss: 0.5183 - val_accuracy: 0.7396\n",
      "Epoch 321/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4682 - accuracy: 0.7726 - val_loss: 0.5183 - val_accuracy: 0.7396\n",
      "Epoch 322/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4682 - accuracy: 0.7726 - val_loss: 0.5183 - val_accuracy: 0.7396\n",
      "Epoch 323/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4681 - accuracy: 0.7726 - val_loss: 0.5183 - val_accuracy: 0.7396\n",
      "Epoch 324/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4680 - accuracy: 0.7708 - val_loss: 0.5183 - val_accuracy: 0.7396\n",
      "Epoch 325/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4680 - accuracy: 0.7726 - val_loss: 0.5182 - val_accuracy: 0.7396\n",
      "Epoch 326/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4679 - accuracy: 0.7708 - val_loss: 0.5182 - val_accuracy: 0.7396\n",
      "Epoch 327/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4679 - accuracy: 0.7726 - val_loss: 0.5182 - val_accuracy: 0.7396\n",
      "Epoch 328/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4678 - accuracy: 0.7726 - val_loss: 0.5182 - val_accuracy: 0.7396\n",
      "Epoch 329/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4677 - accuracy: 0.7708 - val_loss: 0.5182 - val_accuracy: 0.7396\n",
      "Epoch 330/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4677 - accuracy: 0.7708 - val_loss: 0.5182 - val_accuracy: 0.7396\n",
      "Epoch 331/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4676 - accuracy: 0.7708 - val_loss: 0.5181 - val_accuracy: 0.7396\n",
      "Epoch 332/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4675 - accuracy: 0.7726 - val_loss: 0.5181 - val_accuracy: 0.7396\n",
      "Epoch 333/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4675 - accuracy: 0.7726 - val_loss: 0.5181 - val_accuracy: 0.7396\n",
      "Epoch 334/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4674 - accuracy: 0.7743 - val_loss: 0.5181 - val_accuracy: 0.7396\n",
      "Epoch 335/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4673 - accuracy: 0.7726 - val_loss: 0.5181 - val_accuracy: 0.7396\n",
      "Epoch 336/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4673 - accuracy: 0.7726 - val_loss: 0.5181 - val_accuracy: 0.7396\n",
      "Epoch 337/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4673 - accuracy: 0.7726 - val_loss: 0.5180 - val_accuracy: 0.7396\n",
      "Epoch 338/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4672 - accuracy: 0.7743 - val_loss: 0.5180 - val_accuracy: 0.7396\n",
      "Epoch 339/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4671 - accuracy: 0.7726 - val_loss: 0.5180 - val_accuracy: 0.7396\n",
      "Epoch 340/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4671 - accuracy: 0.7743 - val_loss: 0.5180 - val_accuracy: 0.7396\n",
      "Epoch 341/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4670 - accuracy: 0.7743 - val_loss: 0.5180 - val_accuracy: 0.7396\n",
      "Epoch 342/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4670 - accuracy: 0.7743 - val_loss: 0.5180 - val_accuracy: 0.7396\n",
      "Epoch 343/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4669 - accuracy: 0.7743 - val_loss: 0.5180 - val_accuracy: 0.7396\n",
      "Epoch 344/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4668 - accuracy: 0.7743 - val_loss: 0.5179 - val_accuracy: 0.7396\n",
      "Epoch 345/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4668 - accuracy: 0.7743 - val_loss: 0.5179 - val_accuracy: 0.7396\n",
      "Epoch 346/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4667 - accuracy: 0.7743 - val_loss: 0.5179 - val_accuracy: 0.7396\n",
      "Epoch 347/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4667 - accuracy: 0.7743 - val_loss: 0.5179 - val_accuracy: 0.7396\n",
      "Epoch 348/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4666 - accuracy: 0.7743 - val_loss: 0.5179 - val_accuracy: 0.7396\n",
      "Epoch 349/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4665 - accuracy: 0.7760 - val_loss: 0.5179 - val_accuracy: 0.7396\n",
      "Epoch 350/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4665 - accuracy: 0.7760 - val_loss: 0.5179 - val_accuracy: 0.7396\n",
      "Epoch 351/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4664 - accuracy: 0.7760 - val_loss: 0.5178 - val_accuracy: 0.7396\n",
      "Epoch 352/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4664 - accuracy: 0.7760 - val_loss: 0.5178 - val_accuracy: 0.7396\n",
      "Epoch 353/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4663 - accuracy: 0.7778 - val_loss: 0.5178 - val_accuracy: 0.7396\n",
      "Epoch 354/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4662 - accuracy: 0.7760 - val_loss: 0.5178 - val_accuracy: 0.7396\n",
      "Epoch 355/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4662 - accuracy: 0.7760 - val_loss: 0.5178 - val_accuracy: 0.7396\n",
      "Epoch 356/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4661 - accuracy: 0.7760 - val_loss: 0.5178 - val_accuracy: 0.7396\n",
      "Epoch 357/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4661 - accuracy: 0.7778 - val_loss: 0.5178 - val_accuracy: 0.7396\n",
      "Epoch 358/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4660 - accuracy: 0.7778 - val_loss: 0.5177 - val_accuracy: 0.7396\n",
      "Epoch 359/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4660 - accuracy: 0.7795 - val_loss: 0.5177 - val_accuracy: 0.7396\n",
      "Epoch 360/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4659 - accuracy: 0.7812 - val_loss: 0.5177 - val_accuracy: 0.7396\n",
      "Epoch 361/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4659 - accuracy: 0.7760 - val_loss: 0.5177 - val_accuracy: 0.7396\n",
      "Epoch 362/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4658 - accuracy: 0.7812 - val_loss: 0.5177 - val_accuracy: 0.7396\n",
      "Epoch 363/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4657 - accuracy: 0.7812 - val_loss: 0.5177 - val_accuracy: 0.7396\n",
      "Epoch 364/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4657 - accuracy: 0.7795 - val_loss: 0.5177 - val_accuracy: 0.7396\n",
      "Epoch 365/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4656 - accuracy: 0.7812 - val_loss: 0.5177 - val_accuracy: 0.7396\n",
      "Epoch 366/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4656 - accuracy: 0.7812 - val_loss: 0.5176 - val_accuracy: 0.7396\n",
      "Epoch 367/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4655 - accuracy: 0.7812 - val_loss: 0.5176 - val_accuracy: 0.7396\n",
      "Epoch 368/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4655 - accuracy: 0.7812 - val_loss: 0.5176 - val_accuracy: 0.7396\n",
      "Epoch 369/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4654 - accuracy: 0.7795 - val_loss: 0.5176 - val_accuracy: 0.7396\n",
      "Epoch 370/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4654 - accuracy: 0.7812 - val_loss: 0.5176 - val_accuracy: 0.7396\n",
      "Epoch 371/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4653 - accuracy: 0.7812 - val_loss: 0.5176 - val_accuracy: 0.7396\n",
      "Epoch 372/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4652 - accuracy: 0.7812 - val_loss: 0.5176 - val_accuracy: 0.7396\n",
      "Epoch 373/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4652 - accuracy: 0.7812 - val_loss: 0.5176 - val_accuracy: 0.7396\n",
      "Epoch 374/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4652 - accuracy: 0.7812 - val_loss: 0.5176 - val_accuracy: 0.7396\n",
      "Epoch 375/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4651 - accuracy: 0.7812 - val_loss: 0.5176 - val_accuracy: 0.7396\n",
      "Epoch 376/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4650 - accuracy: 0.7812 - val_loss: 0.5175 - val_accuracy: 0.7396\n",
      "Epoch 377/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4650 - accuracy: 0.7812 - val_loss: 0.5175 - val_accuracy: 0.7396\n",
      "Epoch 378/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4649 - accuracy: 0.7812 - val_loss: 0.5175 - val_accuracy: 0.7396\n",
      "Epoch 379/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4649 - accuracy: 0.7812 - val_loss: 0.5175 - val_accuracy: 0.7396\n",
      "Epoch 380/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4648 - accuracy: 0.7812 - val_loss: 0.5175 - val_accuracy: 0.7396\n",
      "Epoch 381/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4648 - accuracy: 0.7812 - val_loss: 0.5175 - val_accuracy: 0.7396\n",
      "Epoch 382/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4647 - accuracy: 0.7812 - val_loss: 0.5175 - val_accuracy: 0.7396\n",
      "Epoch 383/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4647 - accuracy: 0.7812 - val_loss: 0.5175 - val_accuracy: 0.7396\n",
      "Epoch 384/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4646 - accuracy: 0.7812 - val_loss: 0.5175 - val_accuracy: 0.7396\n",
      "Epoch 385/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4646 - accuracy: 0.7812 - val_loss: 0.5175 - val_accuracy: 0.7396\n",
      "Epoch 386/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7812 - val_loss: 0.5174 - val_accuracy: 0.7396\n",
      "Epoch 387/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7812 - val_loss: 0.5174 - val_accuracy: 0.7396\n",
      "Epoch 388/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4644 - accuracy: 0.7812 - val_loss: 0.5174 - val_accuracy: 0.7396\n",
      "Epoch 389/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4644 - accuracy: 0.7812 - val_loss: 0.5174 - val_accuracy: 0.7396\n",
      "Epoch 390/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4643 - accuracy: 0.7812 - val_loss: 0.5174 - val_accuracy: 0.7396\n",
      "Epoch 391/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4643 - accuracy: 0.7812 - val_loss: 0.5174 - val_accuracy: 0.7396\n",
      "Epoch 392/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4642 - accuracy: 0.7812 - val_loss: 0.5174 - val_accuracy: 0.7396\n",
      "Epoch 393/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4642 - accuracy: 0.7812 - val_loss: 0.5174 - val_accuracy: 0.7396\n",
      "Epoch 394/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4641 - accuracy: 0.7812 - val_loss: 0.5174 - val_accuracy: 0.7396\n",
      "Epoch 395/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4641 - accuracy: 0.7812 - val_loss: 0.5174 - val_accuracy: 0.7396\n",
      "Epoch 396/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4641 - accuracy: 0.7812 - val_loss: 0.5174 - val_accuracy: 0.7396\n",
      "Epoch 397/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4640 - accuracy: 0.7812 - val_loss: 0.5173 - val_accuracy: 0.7344\n",
      "Epoch 398/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.7812 - val_loss: 0.5173 - val_accuracy: 0.7344\n",
      "Epoch 399/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.7812 - val_loss: 0.5173 - val_accuracy: 0.7344\n",
      "Epoch 400/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.7812 - val_loss: 0.5173 - val_accuracy: 0.7344\n",
      "Epoch 401/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4638 - accuracy: 0.7812 - val_loss: 0.5173 - val_accuracy: 0.7344\n",
      "Epoch 402/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4638 - accuracy: 0.7812 - val_loss: 0.5173 - val_accuracy: 0.7344\n",
      "Epoch 403/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4637 - accuracy: 0.7812 - val_loss: 0.5173 - val_accuracy: 0.7344\n",
      "Epoch 404/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4637 - accuracy: 0.7812 - val_loss: 0.5173 - val_accuracy: 0.7344\n",
      "Epoch 405/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4636 - accuracy: 0.7812 - val_loss: 0.5173 - val_accuracy: 0.7344\n",
      "Epoch 406/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4636 - accuracy: 0.7812 - val_loss: 0.5173 - val_accuracy: 0.7344\n",
      "Epoch 407/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4635 - accuracy: 0.7812 - val_loss: 0.5173 - val_accuracy: 0.7344\n",
      "Epoch 408/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4635 - accuracy: 0.7812 - val_loss: 0.5173 - val_accuracy: 0.7344\n",
      "Epoch 409/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4635 - accuracy: 0.7812 - val_loss: 0.5173 - val_accuracy: 0.7344\n",
      "Epoch 410/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4634 - accuracy: 0.7812 - val_loss: 0.5172 - val_accuracy: 0.7344\n",
      "Epoch 411/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4633 - accuracy: 0.7812 - val_loss: 0.5172 - val_accuracy: 0.7344\n",
      "Epoch 412/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4633 - accuracy: 0.7812 - val_loss: 0.5172 - val_accuracy: 0.7344\n",
      "Epoch 413/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4632 - accuracy: 0.7812 - val_loss: 0.5172 - val_accuracy: 0.7344\n",
      "Epoch 414/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4632 - accuracy: 0.7812 - val_loss: 0.5172 - val_accuracy: 0.7344\n",
      "Epoch 415/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.7812 - val_loss: 0.5172 - val_accuracy: 0.7344\n",
      "Epoch 416/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4631 - accuracy: 0.7812 - val_loss: 0.5172 - val_accuracy: 0.7344\n",
      "Epoch 417/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.7812 - val_loss: 0.5172 - val_accuracy: 0.7344\n",
      "Epoch 418/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4630 - accuracy: 0.7812 - val_loss: 0.5172 - val_accuracy: 0.7344\n",
      "Epoch 419/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4630 - accuracy: 0.7812 - val_loss: 0.5172 - val_accuracy: 0.7344\n",
      "Epoch 420/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4630 - accuracy: 0.7812 - val_loss: 0.5172 - val_accuracy: 0.7344\n",
      "Epoch 421/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4629 - accuracy: 0.7812 - val_loss: 0.5172 - val_accuracy: 0.7344\n",
      "Epoch 422/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4628 - accuracy: 0.7812 - val_loss: 0.5172 - val_accuracy: 0.7344\n",
      "Epoch 423/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4628 - accuracy: 0.7812 - val_loss: 0.5172 - val_accuracy: 0.7344\n",
      "Epoch 424/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4628 - accuracy: 0.7812 - val_loss: 0.5171 - val_accuracy: 0.7344\n",
      "Epoch 425/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4627 - accuracy: 0.7812 - val_loss: 0.5171 - val_accuracy: 0.7344\n",
      "Epoch 426/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4627 - accuracy: 0.7812 - val_loss: 0.5171 - val_accuracy: 0.7344\n",
      "Epoch 427/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4626 - accuracy: 0.7812 - val_loss: 0.5171 - val_accuracy: 0.7344\n",
      "Epoch 428/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4626 - accuracy: 0.7812 - val_loss: 0.5171 - val_accuracy: 0.7344\n",
      "Epoch 429/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 0.7812 - val_loss: 0.5171 - val_accuracy: 0.7344\n",
      "Epoch 430/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 0.7812 - val_loss: 0.5171 - val_accuracy: 0.7344\n",
      "Epoch 431/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 0.7812 - val_loss: 0.5171 - val_accuracy: 0.7344\n",
      "Epoch 432/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.7812 - val_loss: 0.5171 - val_accuracy: 0.7344\n",
      "Epoch 433/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.7812 - val_loss: 0.5171 - val_accuracy: 0.7344\n",
      "Epoch 434/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4623 - accuracy: 0.7812 - val_loss: 0.5171 - val_accuracy: 0.7344\n",
      "Epoch 435/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4623 - accuracy: 0.7812 - val_loss: 0.5171 - val_accuracy: 0.7344\n",
      "Epoch 436/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4623 - accuracy: 0.7812 - val_loss: 0.5171 - val_accuracy: 0.7344\n",
      "Epoch 437/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4622 - accuracy: 0.7812 - val_loss: 0.5171 - val_accuracy: 0.7344\n",
      "Epoch 438/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4622 - accuracy: 0.7812 - val_loss: 0.5171 - val_accuracy: 0.7344\n",
      "Epoch 439/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4621 - accuracy: 0.7812 - val_loss: 0.5171 - val_accuracy: 0.7344\n",
      "Epoch 440/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4621 - accuracy: 0.7812 - val_loss: 0.5171 - val_accuracy: 0.7344\n",
      "Epoch 441/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.7812 - val_loss: 0.5171 - val_accuracy: 0.7344\n",
      "Epoch 442/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.7812 - val_loss: 0.5170 - val_accuracy: 0.7344\n",
      "Epoch 443/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.7812 - val_loss: 0.5170 - val_accuracy: 0.7344\n",
      "Epoch 444/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4619 - accuracy: 0.7812 - val_loss: 0.5170 - val_accuracy: 0.7344\n",
      "Epoch 445/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4619 - accuracy: 0.7812 - val_loss: 0.5170 - val_accuracy: 0.7344\n",
      "Epoch 446/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.7812 - val_loss: 0.5170 - val_accuracy: 0.7344\n",
      "Epoch 447/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4618 - accuracy: 0.7812 - val_loss: 0.5170 - val_accuracy: 0.7344\n",
      "Epoch 448/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.7812 - val_loss: 0.5170 - val_accuracy: 0.7344\n",
      "Epoch 449/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4617 - accuracy: 0.7812 - val_loss: 0.5170 - val_accuracy: 0.7344\n",
      "Epoch 450/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4617 - accuracy: 0.7812 - val_loss: 0.5170 - val_accuracy: 0.7344\n",
      "Epoch 451/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.7812 - val_loss: 0.5170 - val_accuracy: 0.7344\n",
      "Epoch 452/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.7812 - val_loss: 0.5170 - val_accuracy: 0.7344\n",
      "Epoch 453/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.7812 - val_loss: 0.5170 - val_accuracy: 0.7344\n",
      "Epoch 454/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4615 - accuracy: 0.7812 - val_loss: 0.5170 - val_accuracy: 0.7344\n",
      "Epoch 455/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4615 - accuracy: 0.7812 - val_loss: 0.5170 - val_accuracy: 0.7344\n",
      "Epoch 456/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4615 - accuracy: 0.7812 - val_loss: 0.5170 - val_accuracy: 0.7344\n",
      "Epoch 457/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4614 - accuracy: 0.7812 - val_loss: 0.5170 - val_accuracy: 0.7344\n",
      "Epoch 458/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4614 - accuracy: 0.7812 - val_loss: 0.5170 - val_accuracy: 0.7344\n",
      "Epoch 459/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4614 - accuracy: 0.7812 - val_loss: 0.5170 - val_accuracy: 0.7344\n",
      "Epoch 460/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4613 - accuracy: 0.7830 - val_loss: 0.5170 - val_accuracy: 0.7344\n",
      "Epoch 461/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4613 - accuracy: 0.7830 - val_loss: 0.5170 - val_accuracy: 0.7344\n",
      "Epoch 462/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4612 - accuracy: 0.7812 - val_loss: 0.5170 - val_accuracy: 0.7344\n",
      "Epoch 463/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4612 - accuracy: 0.7830 - val_loss: 0.5170 - val_accuracy: 0.7344\n",
      "Epoch 464/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.7830 - val_loss: 0.5170 - val_accuracy: 0.7344\n",
      "Epoch 465/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.7812 - val_loss: 0.5170 - val_accuracy: 0.7344\n",
      "Epoch 466/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.7830 - val_loss: 0.5170 - val_accuracy: 0.7344\n",
      "Epoch 467/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4610 - accuracy: 0.7830 - val_loss: 0.5170 - val_accuracy: 0.7344\n",
      "Epoch 468/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4610 - accuracy: 0.7830 - val_loss: 0.5170 - val_accuracy: 0.7344\n",
      "Epoch 469/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4610 - accuracy: 0.7830 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 470/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.7830 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 471/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.7812 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 472/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.7830 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 473/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.7830 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 474/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.7812 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 475/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.7812 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 476/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.7812 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 477/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.7812 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 478/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.7812 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 479/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.7812 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 480/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.7812 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 481/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.7812 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 482/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.7812 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 483/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.7812 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 484/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.7812 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 485/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.7812 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 486/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.7812 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 487/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.7812 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 488/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.7812 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 489/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.7812 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 490/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4602 - accuracy: 0.7812 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 491/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4602 - accuracy: 0.7812 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 492/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4602 - accuracy: 0.7812 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 493/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.7812 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 494/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.7812 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 495/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.7812 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 496/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4600 - accuracy: 0.7812 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 497/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4600 - accuracy: 0.7812 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 498/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4600 - accuracy: 0.7812 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 499/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4599 - accuracy: 0.7812 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 500/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4599 - accuracy: 0.7812 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 501/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4599 - accuracy: 0.7812 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 502/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4598 - accuracy: 0.7812 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 503/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.7812 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 504/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4598 - accuracy: 0.7812 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 505/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4597 - accuracy: 0.7812 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 506/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4597 - accuracy: 0.7812 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 507/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4597 - accuracy: 0.7812 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 508/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4596 - accuracy: 0.7812 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 509/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4596 - accuracy: 0.7812 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 510/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4595 - accuracy: 0.7812 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 511/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4595 - accuracy: 0.7812 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 512/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4595 - accuracy: 0.7812 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 513/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4595 - accuracy: 0.7812 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 514/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4594 - accuracy: 0.7812 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 515/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4594 - accuracy: 0.7812 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 516/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4594 - accuracy: 0.7812 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 517/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4594 - accuracy: 0.7812 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 518/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4593 - accuracy: 0.7812 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 519/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4593 - accuracy: 0.7812 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 520/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4593 - accuracy: 0.7812 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 521/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4592 - accuracy: 0.7830 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 522/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4592 - accuracy: 0.7830 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 523/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4592 - accuracy: 0.7830 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 524/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4591 - accuracy: 0.7812 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 525/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4591 - accuracy: 0.7812 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 526/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4591 - accuracy: 0.7830 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 527/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.7830 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 528/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.7830 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 529/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.7830 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 530/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.7830 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 531/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4589 - accuracy: 0.7830 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 532/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4589 - accuracy: 0.7830 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 533/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4589 - accuracy: 0.7830 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 534/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.7830 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 535/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.7830 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 536/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.7830 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 537/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.7830 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 538/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4587 - accuracy: 0.7830 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 539/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4587 - accuracy: 0.7830 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 540/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4587 - accuracy: 0.7830 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 541/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4586 - accuracy: 0.7830 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 542/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4586 - accuracy: 0.7830 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 543/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4586 - accuracy: 0.7865 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 544/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4585 - accuracy: 0.7847 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 545/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4585 - accuracy: 0.7847 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 546/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4585 - accuracy: 0.7847 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 547/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4585 - accuracy: 0.7847 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 548/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4584 - accuracy: 0.7865 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 549/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4584 - accuracy: 0.7865 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 550/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4584 - accuracy: 0.7865 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 551/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4583 - accuracy: 0.7865 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 552/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4583 - accuracy: 0.7865 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 553/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4583 - accuracy: 0.7847 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 554/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4583 - accuracy: 0.7847 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 555/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4582 - accuracy: 0.7865 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 556/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4582 - accuracy: 0.7865 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 557/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4582 - accuracy: 0.7865 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 558/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4581 - accuracy: 0.7865 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 559/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4581 - accuracy: 0.7865 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 560/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4581 - accuracy: 0.7865 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 561/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4581 - accuracy: 0.7865 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 562/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4580 - accuracy: 0.7865 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 563/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4580 - accuracy: 0.7865 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 564/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4580 - accuracy: 0.7865 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 565/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4580 - accuracy: 0.7865 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 566/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4579 - accuracy: 0.7865 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 567/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4579 - accuracy: 0.7865 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 568/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4579 - accuracy: 0.7865 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 569/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4579 - accuracy: 0.7865 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 570/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4578 - accuracy: 0.7865 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 571/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4578 - accuracy: 0.7865 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 572/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4578 - accuracy: 0.7865 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 573/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4577 - accuracy: 0.7865 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 574/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4577 - accuracy: 0.7865 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 575/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4577 - accuracy: 0.7865 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 576/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4577 - accuracy: 0.7865 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 577/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4576 - accuracy: 0.7865 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 578/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4576 - accuracy: 0.7865 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 579/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4576 - accuracy: 0.7865 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 580/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4576 - accuracy: 0.7882 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 581/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4575 - accuracy: 0.7882 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 582/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4575 - accuracy: 0.7865 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 583/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4575 - accuracy: 0.7865 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 584/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4575 - accuracy: 0.7865 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 585/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4574 - accuracy: 0.7865 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 586/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4574 - accuracy: 0.7865 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 587/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4574 - accuracy: 0.7865 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 588/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4574 - accuracy: 0.7865 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 589/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4574 - accuracy: 0.7865 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 590/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4573 - accuracy: 0.7865 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 591/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4573 - accuracy: 0.7865 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 592/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4573 - accuracy: 0.7865 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 593/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4572 - accuracy: 0.7865 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 594/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4572 - accuracy: 0.7865 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 595/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4572 - accuracy: 0.7865 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 596/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4572 - accuracy: 0.7865 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 597/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4571 - accuracy: 0.7865 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 598/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4571 - accuracy: 0.7865 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 599/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4571 - accuracy: 0.7865 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 600/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4571 - accuracy: 0.7865 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 601/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4570 - accuracy: 0.7865 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 602/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4570 - accuracy: 0.7865 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 603/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4570 - accuracy: 0.7865 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 604/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4570 - accuracy: 0.7865 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 605/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4570 - accuracy: 0.7865 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 606/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4569 - accuracy: 0.7865 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 607/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4569 - accuracy: 0.7865 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 608/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4569 - accuracy: 0.7865 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 609/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4569 - accuracy: 0.7865 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 610/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4568 - accuracy: 0.7865 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 611/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4568 - accuracy: 0.7865 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 612/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4568 - accuracy: 0.7865 - val_loss: 0.5170 - val_accuracy: 0.7344\n",
      "Epoch 613/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4568 - accuracy: 0.7865 - val_loss: 0.5170 - val_accuracy: 0.7344\n",
      "Epoch 614/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4567 - accuracy: 0.7865 - val_loss: 0.5170 - val_accuracy: 0.7344\n",
      "Epoch 615/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4567 - accuracy: 0.7865 - val_loss: 0.5170 - val_accuracy: 0.7344\n",
      "Epoch 616/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4567 - accuracy: 0.7865 - val_loss: 0.5170 - val_accuracy: 0.7344\n",
      "Epoch 617/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4567 - accuracy: 0.7865 - val_loss: 0.5170 - val_accuracy: 0.7344\n",
      "Epoch 618/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4567 - accuracy: 0.7865 - val_loss: 0.5170 - val_accuracy: 0.7344\n",
      "Epoch 619/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4566 - accuracy: 0.7865 - val_loss: 0.5170 - val_accuracy: 0.7344\n",
      "Epoch 620/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4566 - accuracy: 0.7865 - val_loss: 0.5170 - val_accuracy: 0.7344\n",
      "Epoch 621/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4566 - accuracy: 0.7865 - val_loss: 0.5170 - val_accuracy: 0.7344\n",
      "Epoch 622/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4566 - accuracy: 0.7865 - val_loss: 0.5170 - val_accuracy: 0.7344\n",
      "Epoch 623/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4565 - accuracy: 0.7865 - val_loss: 0.5170 - val_accuracy: 0.7344\n",
      "Epoch 624/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4565 - accuracy: 0.7865 - val_loss: 0.5170 - val_accuracy: 0.7344\n",
      "Epoch 625/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4565 - accuracy: 0.7882 - val_loss: 0.5170 - val_accuracy: 0.7344\n",
      "Epoch 626/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4565 - accuracy: 0.7882 - val_loss: 0.5170 - val_accuracy: 0.7344\n",
      "Epoch 627/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4565 - accuracy: 0.7882 - val_loss: 0.5170 - val_accuracy: 0.7344\n",
      "Epoch 628/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4564 - accuracy: 0.7882 - val_loss: 0.5170 - val_accuracy: 0.7344\n",
      "Epoch 629/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4564 - accuracy: 0.7882 - val_loss: 0.5170 - val_accuracy: 0.7344\n",
      "Epoch 630/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4564 - accuracy: 0.7882 - val_loss: 0.5170 - val_accuracy: 0.7344\n",
      "Epoch 631/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4564 - accuracy: 0.7882 - val_loss: 0.5170 - val_accuracy: 0.7344\n",
      "Epoch 632/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4563 - accuracy: 0.7882 - val_loss: 0.5170 - val_accuracy: 0.7344\n",
      "Epoch 633/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4563 - accuracy: 0.7882 - val_loss: 0.5170 - val_accuracy: 0.7344\n",
      "Epoch 634/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4563 - accuracy: 0.7882 - val_loss: 0.5170 - val_accuracy: 0.7344\n",
      "Epoch 635/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4563 - accuracy: 0.7882 - val_loss: 0.5170 - val_accuracy: 0.7344\n",
      "Epoch 636/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4562 - accuracy: 0.7882 - val_loss: 0.5170 - val_accuracy: 0.7344\n",
      "Epoch 637/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4562 - accuracy: 0.7882 - val_loss: 0.5170 - val_accuracy: 0.7344\n",
      "Epoch 638/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4562 - accuracy: 0.7882 - val_loss: 0.5170 - val_accuracy: 0.7344\n",
      "Epoch 639/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4562 - accuracy: 0.7882 - val_loss: 0.5170 - val_accuracy: 0.7344\n",
      "Epoch 640/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4561 - accuracy: 0.7882 - val_loss: 0.5170 - val_accuracy: 0.7344\n",
      "Epoch 641/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4561 - accuracy: 0.7882 - val_loss: 0.5170 - val_accuracy: 0.7344\n",
      "Epoch 642/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4561 - accuracy: 0.7882 - val_loss: 0.5170 - val_accuracy: 0.7344\n",
      "Epoch 643/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4561 - accuracy: 0.7882 - val_loss: 0.5170 - val_accuracy: 0.7344\n",
      "Epoch 644/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4561 - accuracy: 0.7882 - val_loss: 0.5170 - val_accuracy: 0.7344\n",
      "Epoch 645/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4561 - accuracy: 0.7882 - val_loss: 0.5170 - val_accuracy: 0.7344\n",
      "Epoch 646/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4560 - accuracy: 0.7882 - val_loss: 0.5170 - val_accuracy: 0.7344\n",
      "Epoch 647/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4560 - accuracy: 0.7882 - val_loss: 0.5170 - val_accuracy: 0.7344\n",
      "Epoch 648/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4560 - accuracy: 0.7882 - val_loss: 0.5170 - val_accuracy: 0.7344\n",
      "Epoch 649/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4560 - accuracy: 0.7882 - val_loss: 0.5171 - val_accuracy: 0.7344\n",
      "Epoch 650/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4559 - accuracy: 0.7882 - val_loss: 0.5171 - val_accuracy: 0.7344\n",
      "Epoch 651/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4559 - accuracy: 0.7882 - val_loss: 0.5171 - val_accuracy: 0.7292\n",
      "Epoch 652/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4559 - accuracy: 0.7882 - val_loss: 0.5171 - val_accuracy: 0.7292\n",
      "Epoch 653/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4559 - accuracy: 0.7882 - val_loss: 0.5171 - val_accuracy: 0.7292\n",
      "Epoch 654/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4559 - accuracy: 0.7882 - val_loss: 0.5171 - val_accuracy: 0.7292\n",
      "Epoch 655/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4558 - accuracy: 0.7882 - val_loss: 0.5171 - val_accuracy: 0.7292\n",
      "Epoch 656/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4558 - accuracy: 0.7882 - val_loss: 0.5171 - val_accuracy: 0.7292\n",
      "Epoch 657/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4558 - accuracy: 0.7882 - val_loss: 0.5171 - val_accuracy: 0.7292\n",
      "Epoch 658/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4558 - accuracy: 0.7882 - val_loss: 0.5171 - val_accuracy: 0.7292\n",
      "Epoch 659/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4558 - accuracy: 0.7882 - val_loss: 0.5171 - val_accuracy: 0.7292\n",
      "Epoch 660/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4558 - accuracy: 0.7882 - val_loss: 0.5171 - val_accuracy: 0.7292\n",
      "Epoch 661/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4557 - accuracy: 0.7882 - val_loss: 0.5171 - val_accuracy: 0.7292\n",
      "Epoch 662/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4557 - accuracy: 0.7882 - val_loss: 0.5171 - val_accuracy: 0.7292\n",
      "Epoch 663/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4557 - accuracy: 0.7882 - val_loss: 0.5171 - val_accuracy: 0.7292\n",
      "Epoch 664/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4557 - accuracy: 0.7882 - val_loss: 0.5171 - val_accuracy: 0.7292\n",
      "Epoch 665/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4557 - accuracy: 0.7882 - val_loss: 0.5171 - val_accuracy: 0.7292\n",
      "Epoch 666/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4556 - accuracy: 0.7882 - val_loss: 0.5171 - val_accuracy: 0.7292\n",
      "Epoch 667/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4556 - accuracy: 0.7882 - val_loss: 0.5171 - val_accuracy: 0.7292\n",
      "Epoch 668/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4556 - accuracy: 0.7882 - val_loss: 0.5171 - val_accuracy: 0.7292\n",
      "Epoch 669/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4556 - accuracy: 0.7882 - val_loss: 0.5171 - val_accuracy: 0.7292\n",
      "Epoch 670/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4555 - accuracy: 0.7882 - val_loss: 0.5171 - val_accuracy: 0.7292\n",
      "Epoch 671/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4555 - accuracy: 0.7882 - val_loss: 0.5171 - val_accuracy: 0.7292\n",
      "Epoch 672/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4555 - accuracy: 0.7882 - val_loss: 0.5171 - val_accuracy: 0.7292\n",
      "Epoch 673/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4555 - accuracy: 0.7882 - val_loss: 0.5171 - val_accuracy: 0.7292\n",
      "Epoch 674/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4555 - accuracy: 0.7882 - val_loss: 0.5171 - val_accuracy: 0.7292\n",
      "Epoch 675/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4554 - accuracy: 0.7882 - val_loss: 0.5171 - val_accuracy: 0.7292\n",
      "Epoch 676/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4555 - accuracy: 0.7882 - val_loss: 0.5171 - val_accuracy: 0.7292\n",
      "Epoch 677/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4554 - accuracy: 0.7882 - val_loss: 0.5171 - val_accuracy: 0.7292\n",
      "Epoch 678/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4554 - accuracy: 0.7882 - val_loss: 0.5171 - val_accuracy: 0.7292\n",
      "Epoch 679/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4554 - accuracy: 0.7882 - val_loss: 0.5172 - val_accuracy: 0.7292\n",
      "Epoch 680/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4553 - accuracy: 0.7882 - val_loss: 0.5172 - val_accuracy: 0.7292\n",
      "Epoch 681/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4553 - accuracy: 0.7882 - val_loss: 0.5172 - val_accuracy: 0.7292\n",
      "Epoch 682/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4553 - accuracy: 0.7882 - val_loss: 0.5172 - val_accuracy: 0.7292\n",
      "Epoch 683/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4553 - accuracy: 0.7882 - val_loss: 0.5172 - val_accuracy: 0.7292\n",
      "Epoch 684/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4553 - accuracy: 0.7882 - val_loss: 0.5172 - val_accuracy: 0.7292\n",
      "Epoch 685/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4552 - accuracy: 0.7882 - val_loss: 0.5172 - val_accuracy: 0.7292\n",
      "Epoch 686/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4552 - accuracy: 0.7882 - val_loss: 0.5172 - val_accuracy: 0.7292\n",
      "Epoch 687/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4552 - accuracy: 0.7882 - val_loss: 0.5172 - val_accuracy: 0.7292\n",
      "Epoch 688/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4552 - accuracy: 0.7882 - val_loss: 0.5172 - val_accuracy: 0.7292\n",
      "Epoch 689/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4552 - accuracy: 0.7882 - val_loss: 0.5172 - val_accuracy: 0.7292\n",
      "Epoch 690/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4552 - accuracy: 0.7882 - val_loss: 0.5172 - val_accuracy: 0.7292\n",
      "Epoch 691/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4551 - accuracy: 0.7882 - val_loss: 0.5172 - val_accuracy: 0.7292\n",
      "Epoch 692/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4551 - accuracy: 0.7882 - val_loss: 0.5172 - val_accuracy: 0.7292\n",
      "Epoch 693/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4551 - accuracy: 0.7882 - val_loss: 0.5172 - val_accuracy: 0.7292\n",
      "Epoch 694/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4551 - accuracy: 0.7882 - val_loss: 0.5172 - val_accuracy: 0.7292\n",
      "Epoch 695/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4551 - accuracy: 0.7882 - val_loss: 0.5172 - val_accuracy: 0.7292\n",
      "Epoch 696/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4550 - accuracy: 0.7882 - val_loss: 0.5172 - val_accuracy: 0.7292\n",
      "Epoch 697/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4550 - accuracy: 0.7882 - val_loss: 0.5172 - val_accuracy: 0.7292\n",
      "Epoch 698/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4550 - accuracy: 0.7882 - val_loss: 0.5172 - val_accuracy: 0.7292\n",
      "Epoch 699/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4550 - accuracy: 0.7882 - val_loss: 0.5172 - val_accuracy: 0.7292\n",
      "Epoch 700/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4550 - accuracy: 0.7882 - val_loss: 0.5172 - val_accuracy: 0.7292\n",
      "Epoch 701/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4549 - accuracy: 0.7882 - val_loss: 0.5172 - val_accuracy: 0.7292\n",
      "Epoch 702/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4549 - accuracy: 0.7882 - val_loss: 0.5172 - val_accuracy: 0.7292\n",
      "Epoch 703/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4549 - accuracy: 0.7882 - val_loss: 0.5172 - val_accuracy: 0.7292\n",
      "Epoch 704/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4549 - accuracy: 0.7882 - val_loss: 0.5172 - val_accuracy: 0.7292\n",
      "Epoch 705/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4549 - accuracy: 0.7882 - val_loss: 0.5173 - val_accuracy: 0.7292\n",
      "Epoch 706/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4549 - accuracy: 0.7882 - val_loss: 0.5173 - val_accuracy: 0.7292\n",
      "Epoch 707/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4548 - accuracy: 0.7882 - val_loss: 0.5173 - val_accuracy: 0.7292\n",
      "Epoch 708/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4548 - accuracy: 0.7882 - val_loss: 0.5173 - val_accuracy: 0.7292\n",
      "Epoch 709/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4548 - accuracy: 0.7882 - val_loss: 0.5173 - val_accuracy: 0.7292\n",
      "Epoch 710/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4548 - accuracy: 0.7882 - val_loss: 0.5173 - val_accuracy: 0.7292\n",
      "Epoch 711/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4548 - accuracy: 0.7882 - val_loss: 0.5173 - val_accuracy: 0.7292\n",
      "Epoch 712/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4548 - accuracy: 0.7882 - val_loss: 0.5173 - val_accuracy: 0.7292\n",
      "Epoch 713/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4547 - accuracy: 0.7882 - val_loss: 0.5173 - val_accuracy: 0.7292\n",
      "Epoch 714/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4547 - accuracy: 0.7882 - val_loss: 0.5173 - val_accuracy: 0.7292\n",
      "Epoch 715/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4547 - accuracy: 0.7882 - val_loss: 0.5173 - val_accuracy: 0.7292\n",
      "Epoch 716/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4547 - accuracy: 0.7882 - val_loss: 0.5173 - val_accuracy: 0.7292\n",
      "Epoch 717/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4547 - accuracy: 0.7882 - val_loss: 0.5173 - val_accuracy: 0.7292\n",
      "Epoch 718/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4546 - accuracy: 0.7882 - val_loss: 0.5173 - val_accuracy: 0.7292\n",
      "Epoch 719/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4546 - accuracy: 0.7882 - val_loss: 0.5173 - val_accuracy: 0.7292\n",
      "Epoch 720/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4546 - accuracy: 0.7882 - val_loss: 0.5173 - val_accuracy: 0.7292\n",
      "Epoch 721/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4546 - accuracy: 0.7882 - val_loss: 0.5173 - val_accuracy: 0.7292\n",
      "Epoch 722/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4546 - accuracy: 0.7882 - val_loss: 0.5173 - val_accuracy: 0.7292\n",
      "Epoch 723/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4545 - accuracy: 0.7882 - val_loss: 0.5173 - val_accuracy: 0.7292\n",
      "Epoch 724/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4545 - accuracy: 0.7882 - val_loss: 0.5173 - val_accuracy: 0.7292\n",
      "Epoch 725/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4545 - accuracy: 0.7865 - val_loss: 0.5173 - val_accuracy: 0.7292\n",
      "Epoch 726/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4545 - accuracy: 0.7865 - val_loss: 0.5173 - val_accuracy: 0.7292\n",
      "Epoch 727/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4545 - accuracy: 0.7865 - val_loss: 0.5173 - val_accuracy: 0.7292\n",
      "Epoch 728/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4545 - accuracy: 0.7882 - val_loss: 0.5173 - val_accuracy: 0.7292\n",
      "Epoch 729/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4545 - accuracy: 0.7865 - val_loss: 0.5173 - val_accuracy: 0.7292\n",
      "Epoch 730/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4544 - accuracy: 0.7865 - val_loss: 0.5173 - val_accuracy: 0.7292\n",
      "Epoch 731/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4544 - accuracy: 0.7865 - val_loss: 0.5173 - val_accuracy: 0.7292\n",
      "Epoch 732/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4544 - accuracy: 0.7882 - val_loss: 0.5174 - val_accuracy: 0.7292\n",
      "Epoch 733/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4544 - accuracy: 0.7865 - val_loss: 0.5174 - val_accuracy: 0.7292\n",
      "Epoch 734/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4544 - accuracy: 0.7865 - val_loss: 0.5174 - val_accuracy: 0.7292\n",
      "Epoch 735/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4544 - accuracy: 0.7865 - val_loss: 0.5174 - val_accuracy: 0.7292\n",
      "Epoch 736/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4543 - accuracy: 0.7882 - val_loss: 0.5174 - val_accuracy: 0.7292\n",
      "Epoch 737/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4543 - accuracy: 0.7865 - val_loss: 0.5174 - val_accuracy: 0.7292\n",
      "Epoch 738/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4543 - accuracy: 0.7882 - val_loss: 0.5174 - val_accuracy: 0.7292\n",
      "Epoch 739/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4543 - accuracy: 0.7882 - val_loss: 0.5174 - val_accuracy: 0.7292\n",
      "Epoch 740/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4543 - accuracy: 0.7865 - val_loss: 0.5174 - val_accuracy: 0.7292\n",
      "Epoch 741/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4543 - accuracy: 0.7882 - val_loss: 0.5174 - val_accuracy: 0.7292\n",
      "Epoch 742/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4543 - accuracy: 0.7882 - val_loss: 0.5174 - val_accuracy: 0.7292\n",
      "Epoch 743/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4542 - accuracy: 0.7882 - val_loss: 0.5174 - val_accuracy: 0.7292\n",
      "Epoch 744/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4542 - accuracy: 0.7865 - val_loss: 0.5174 - val_accuracy: 0.7292\n",
      "Epoch 745/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4542 - accuracy: 0.7882 - val_loss: 0.5174 - val_accuracy: 0.7292\n",
      "Epoch 746/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4542 - accuracy: 0.7882 - val_loss: 0.5174 - val_accuracy: 0.7292\n",
      "Epoch 747/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4542 - accuracy: 0.7882 - val_loss: 0.5174 - val_accuracy: 0.7292\n",
      "Epoch 748/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4542 - accuracy: 0.7865 - val_loss: 0.5174 - val_accuracy: 0.7292\n",
      "Epoch 749/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4541 - accuracy: 0.7882 - val_loss: 0.5174 - val_accuracy: 0.7292\n",
      "Epoch 750/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4542 - accuracy: 0.7865 - val_loss: 0.5174 - val_accuracy: 0.7292\n",
      "Epoch 751/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4541 - accuracy: 0.7865 - val_loss: 0.5174 - val_accuracy: 0.7292\n",
      "Epoch 752/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4541 - accuracy: 0.7865 - val_loss: 0.5174 - val_accuracy: 0.7292\n",
      "Epoch 753/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4541 - accuracy: 0.7882 - val_loss: 0.5174 - val_accuracy: 0.7292\n",
      "Epoch 754/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4540 - accuracy: 0.7882 - val_loss: 0.5174 - val_accuracy: 0.7292\n",
      "Epoch 755/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4540 - accuracy: 0.7882 - val_loss: 0.5175 - val_accuracy: 0.7292\n",
      "Epoch 756/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4540 - accuracy: 0.7865 - val_loss: 0.5175 - val_accuracy: 0.7292\n",
      "Epoch 757/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4540 - accuracy: 0.7882 - val_loss: 0.5175 - val_accuracy: 0.7292\n",
      "Epoch 758/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4540 - accuracy: 0.7865 - val_loss: 0.5175 - val_accuracy: 0.7292\n",
      "Epoch 759/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4540 - accuracy: 0.7882 - val_loss: 0.5175 - val_accuracy: 0.7292\n",
      "Epoch 760/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4540 - accuracy: 0.7865 - val_loss: 0.5175 - val_accuracy: 0.7292\n",
      "Epoch 761/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4539 - accuracy: 0.7865 - val_loss: 0.5175 - val_accuracy: 0.7292\n",
      "Epoch 762/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4539 - accuracy: 0.7865 - val_loss: 0.5175 - val_accuracy: 0.7292\n",
      "Epoch 763/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4539 - accuracy: 0.7882 - val_loss: 0.5175 - val_accuracy: 0.7292\n",
      "Epoch 764/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4539 - accuracy: 0.7865 - val_loss: 0.5175 - val_accuracy: 0.7292\n",
      "Epoch 765/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4539 - accuracy: 0.7865 - val_loss: 0.5175 - val_accuracy: 0.7292\n",
      "Epoch 766/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4539 - accuracy: 0.7882 - val_loss: 0.5175 - val_accuracy: 0.7292\n",
      "Epoch 767/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4538 - accuracy: 0.7865 - val_loss: 0.5175 - val_accuracy: 0.7292\n",
      "Epoch 768/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4538 - accuracy: 0.7865 - val_loss: 0.5175 - val_accuracy: 0.7292\n",
      "Epoch 769/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4538 - accuracy: 0.7847 - val_loss: 0.5175 - val_accuracy: 0.7292\n",
      "Epoch 770/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4538 - accuracy: 0.7865 - val_loss: 0.5175 - val_accuracy: 0.7292\n",
      "Epoch 771/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4538 - accuracy: 0.7847 - val_loss: 0.5175 - val_accuracy: 0.7292\n",
      "Epoch 772/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4538 - accuracy: 0.7847 - val_loss: 0.5175 - val_accuracy: 0.7292\n",
      "Epoch 773/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4537 - accuracy: 0.7865 - val_loss: 0.5175 - val_accuracy: 0.7292\n",
      "Epoch 774/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4537 - accuracy: 0.7847 - val_loss: 0.5175 - val_accuracy: 0.7292\n",
      "Epoch 775/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4537 - accuracy: 0.7847 - val_loss: 0.5175 - val_accuracy: 0.7292\n",
      "Epoch 776/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4537 - accuracy: 0.7847 - val_loss: 0.5175 - val_accuracy: 0.7292\n",
      "Epoch 777/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4537 - accuracy: 0.7847 - val_loss: 0.5176 - val_accuracy: 0.7292\n",
      "Epoch 778/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4537 - accuracy: 0.7847 - val_loss: 0.5176 - val_accuracy: 0.7292\n",
      "Epoch 779/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4537 - accuracy: 0.7847 - val_loss: 0.5176 - val_accuracy: 0.7292\n",
      "Epoch 780/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4537 - accuracy: 0.7847 - val_loss: 0.5176 - val_accuracy: 0.7292\n",
      "Epoch 781/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4536 - accuracy: 0.7847 - val_loss: 0.5176 - val_accuracy: 0.7292\n",
      "Epoch 782/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4536 - accuracy: 0.7847 - val_loss: 0.5176 - val_accuracy: 0.7292\n",
      "Epoch 783/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4536 - accuracy: 0.7865 - val_loss: 0.5176 - val_accuracy: 0.7292\n",
      "Epoch 784/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4536 - accuracy: 0.7847 - val_loss: 0.5176 - val_accuracy: 0.7292\n",
      "Epoch 785/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4536 - accuracy: 0.7865 - val_loss: 0.5176 - val_accuracy: 0.7292\n",
      "Epoch 786/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4536 - accuracy: 0.7847 - val_loss: 0.5176 - val_accuracy: 0.7292\n",
      "Epoch 787/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4535 - accuracy: 0.7847 - val_loss: 0.5176 - val_accuracy: 0.7292\n",
      "Epoch 788/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4535 - accuracy: 0.7847 - val_loss: 0.5176 - val_accuracy: 0.7292\n",
      "Epoch 789/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4535 - accuracy: 0.7847 - val_loss: 0.5176 - val_accuracy: 0.7292\n",
      "Epoch 790/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4535 - accuracy: 0.7847 - val_loss: 0.5176 - val_accuracy: 0.7292\n",
      "Epoch 791/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4535 - accuracy: 0.7847 - val_loss: 0.5176 - val_accuracy: 0.7292\n",
      "Epoch 792/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4535 - accuracy: 0.7847 - val_loss: 0.5176 - val_accuracy: 0.7292\n",
      "Epoch 793/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4534 - accuracy: 0.7847 - val_loss: 0.5176 - val_accuracy: 0.7292\n",
      "Epoch 794/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4534 - accuracy: 0.7847 - val_loss: 0.5176 - val_accuracy: 0.7292\n",
      "Epoch 795/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4534 - accuracy: 0.7847 - val_loss: 0.5176 - val_accuracy: 0.7292\n",
      "Epoch 796/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4534 - accuracy: 0.7847 - val_loss: 0.5176 - val_accuracy: 0.7292\n",
      "Epoch 797/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4534 - accuracy: 0.7847 - val_loss: 0.5176 - val_accuracy: 0.7292\n",
      "Epoch 798/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4534 - accuracy: 0.7847 - val_loss: 0.5176 - val_accuracy: 0.7292\n",
      "Epoch 799/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4534 - accuracy: 0.7847 - val_loss: 0.5176 - val_accuracy: 0.7292\n",
      "Epoch 800/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4533 - accuracy: 0.7847 - val_loss: 0.5177 - val_accuracy: 0.7292\n",
      "Epoch 801/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4533 - accuracy: 0.7847 - val_loss: 0.5177 - val_accuracy: 0.7292\n",
      "Epoch 802/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4533 - accuracy: 0.7830 - val_loss: 0.5177 - val_accuracy: 0.7292\n",
      "Epoch 803/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4533 - accuracy: 0.7830 - val_loss: 0.5177 - val_accuracy: 0.7292\n",
      "Epoch 804/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4533 - accuracy: 0.7865 - val_loss: 0.5177 - val_accuracy: 0.7292\n",
      "Epoch 805/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4533 - accuracy: 0.7847 - val_loss: 0.5177 - val_accuracy: 0.7292\n",
      "Epoch 806/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4533 - accuracy: 0.7865 - val_loss: 0.5177 - val_accuracy: 0.7292\n",
      "Epoch 807/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4533 - accuracy: 0.7847 - val_loss: 0.5177 - val_accuracy: 0.7292\n",
      "Epoch 808/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4533 - accuracy: 0.7847 - val_loss: 0.5177 - val_accuracy: 0.7292\n",
      "Epoch 809/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4532 - accuracy: 0.7830 - val_loss: 0.5177 - val_accuracy: 0.7292\n",
      "Epoch 810/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4532 - accuracy: 0.7847 - val_loss: 0.5177 - val_accuracy: 0.7292\n",
      "Epoch 811/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4532 - accuracy: 0.7847 - val_loss: 0.5177 - val_accuracy: 0.7292\n",
      "Epoch 812/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4532 - accuracy: 0.7847 - val_loss: 0.5177 - val_accuracy: 0.7292\n",
      "Epoch 813/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4532 - accuracy: 0.7847 - val_loss: 0.5177 - val_accuracy: 0.7292\n",
      "Epoch 814/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4532 - accuracy: 0.7830 - val_loss: 0.5177 - val_accuracy: 0.7292\n",
      "Epoch 815/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4531 - accuracy: 0.7847 - val_loss: 0.5177 - val_accuracy: 0.7292\n",
      "Epoch 816/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4531 - accuracy: 0.7830 - val_loss: 0.5177 - val_accuracy: 0.7292\n",
      "Epoch 817/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4531 - accuracy: 0.7847 - val_loss: 0.5177 - val_accuracy: 0.7292\n",
      "Epoch 818/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4531 - accuracy: 0.7847 - val_loss: 0.5177 - val_accuracy: 0.7292\n",
      "Epoch 819/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4531 - accuracy: 0.7847 - val_loss: 0.5177 - val_accuracy: 0.7292\n",
      "Epoch 820/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4531 - accuracy: 0.7847 - val_loss: 0.5177 - val_accuracy: 0.7292\n",
      "Epoch 821/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4530 - accuracy: 0.7847 - val_loss: 0.5177 - val_accuracy: 0.7292\n",
      "Epoch 822/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4530 - accuracy: 0.7847 - val_loss: 0.5178 - val_accuracy: 0.7292\n",
      "Epoch 823/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4530 - accuracy: 0.7847 - val_loss: 0.5178 - val_accuracy: 0.7292\n",
      "Epoch 824/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4530 - accuracy: 0.7847 - val_loss: 0.5178 - val_accuracy: 0.7292\n",
      "Epoch 825/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4530 - accuracy: 0.7847 - val_loss: 0.5178 - val_accuracy: 0.7292\n",
      "Epoch 826/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4530 - accuracy: 0.7847 - val_loss: 0.5178 - val_accuracy: 0.7292\n",
      "Epoch 827/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4530 - accuracy: 0.7847 - val_loss: 0.5178 - val_accuracy: 0.7292\n",
      "Epoch 828/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4530 - accuracy: 0.7847 - val_loss: 0.5178 - val_accuracy: 0.7292\n",
      "Epoch 829/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4530 - accuracy: 0.7847 - val_loss: 0.5178 - val_accuracy: 0.7292\n",
      "Epoch 830/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4529 - accuracy: 0.7847 - val_loss: 0.5178 - val_accuracy: 0.7292\n",
      "Epoch 831/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4529 - accuracy: 0.7847 - val_loss: 0.5178 - val_accuracy: 0.7292\n",
      "Epoch 832/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4529 - accuracy: 0.7847 - val_loss: 0.5178 - val_accuracy: 0.7292\n",
      "Epoch 833/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4529 - accuracy: 0.7847 - val_loss: 0.5178 - val_accuracy: 0.7292\n",
      "Epoch 834/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4529 - accuracy: 0.7847 - val_loss: 0.5178 - val_accuracy: 0.7292\n",
      "Epoch 835/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4528 - accuracy: 0.7847 - val_loss: 0.5178 - val_accuracy: 0.7292\n",
      "Epoch 836/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4529 - accuracy: 0.7847 - val_loss: 0.5178 - val_accuracy: 0.7292\n",
      "Epoch 837/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4528 - accuracy: 0.7847 - val_loss: 0.5178 - val_accuracy: 0.7292\n",
      "Epoch 838/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4528 - accuracy: 0.7847 - val_loss: 0.5178 - val_accuracy: 0.7292\n",
      "Epoch 839/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4528 - accuracy: 0.7847 - val_loss: 0.5178 - val_accuracy: 0.7292\n",
      "Epoch 840/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4528 - accuracy: 0.7847 - val_loss: 0.5178 - val_accuracy: 0.7292\n",
      "Epoch 841/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4528 - accuracy: 0.7847 - val_loss: 0.5178 - val_accuracy: 0.7292\n",
      "Epoch 842/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4528 - accuracy: 0.7847 - val_loss: 0.5179 - val_accuracy: 0.7292\n",
      "Epoch 843/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4528 - accuracy: 0.7847 - val_loss: 0.5179 - val_accuracy: 0.7292\n",
      "Epoch 844/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4528 - accuracy: 0.7847 - val_loss: 0.5179 - val_accuracy: 0.7292\n",
      "Epoch 845/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4527 - accuracy: 0.7847 - val_loss: 0.5179 - val_accuracy: 0.7292\n",
      "Epoch 846/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4527 - accuracy: 0.7847 - val_loss: 0.5179 - val_accuracy: 0.7292\n",
      "Epoch 847/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4527 - accuracy: 0.7847 - val_loss: 0.5179 - val_accuracy: 0.7292\n",
      "Epoch 848/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4527 - accuracy: 0.7847 - val_loss: 0.5179 - val_accuracy: 0.7292\n",
      "Epoch 849/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4527 - accuracy: 0.7847 - val_loss: 0.5179 - val_accuracy: 0.7292\n",
      "Epoch 850/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4527 - accuracy: 0.7847 - val_loss: 0.5179 - val_accuracy: 0.7292\n",
      "Epoch 851/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4526 - accuracy: 0.7847 - val_loss: 0.5179 - val_accuracy: 0.7344\n",
      "Epoch 852/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4526 - accuracy: 0.7847 - val_loss: 0.5179 - val_accuracy: 0.7344\n",
      "Epoch 853/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4526 - accuracy: 0.7847 - val_loss: 0.5179 - val_accuracy: 0.7344\n",
      "Epoch 854/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4526 - accuracy: 0.7847 - val_loss: 0.5179 - val_accuracy: 0.7344\n",
      "Epoch 855/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4526 - accuracy: 0.7847 - val_loss: 0.5179 - val_accuracy: 0.7344\n",
      "Epoch 856/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4526 - accuracy: 0.7847 - val_loss: 0.5179 - val_accuracy: 0.7344\n",
      "Epoch 857/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4526 - accuracy: 0.7847 - val_loss: 0.5179 - val_accuracy: 0.7344\n",
      "Epoch 858/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4526 - accuracy: 0.7847 - val_loss: 0.5179 - val_accuracy: 0.7344\n",
      "Epoch 859/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4525 - accuracy: 0.7847 - val_loss: 0.5179 - val_accuracy: 0.7344\n",
      "Epoch 860/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4525 - accuracy: 0.7847 - val_loss: 0.5179 - val_accuracy: 0.7344\n",
      "Epoch 861/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4525 - accuracy: 0.7847 - val_loss: 0.5179 - val_accuracy: 0.7344\n",
      "Epoch 862/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4525 - accuracy: 0.7847 - val_loss: 0.5179 - val_accuracy: 0.7344\n",
      "Epoch 863/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4525 - accuracy: 0.7847 - val_loss: 0.5180 - val_accuracy: 0.7344\n",
      "Epoch 864/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4525 - accuracy: 0.7847 - val_loss: 0.5180 - val_accuracy: 0.7344\n",
      "Epoch 865/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4525 - accuracy: 0.7847 - val_loss: 0.5180 - val_accuracy: 0.7344\n",
      "Epoch 866/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4524 - accuracy: 0.7847 - val_loss: 0.5180 - val_accuracy: 0.7344\n",
      "Epoch 867/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4525 - accuracy: 0.7847 - val_loss: 0.5180 - val_accuracy: 0.7344\n",
      "Epoch 868/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4524 - accuracy: 0.7847 - val_loss: 0.5180 - val_accuracy: 0.7344\n",
      "Epoch 869/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4524 - accuracy: 0.7847 - val_loss: 0.5180 - val_accuracy: 0.7344\n",
      "Epoch 870/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4524 - accuracy: 0.7847 - val_loss: 0.5180 - val_accuracy: 0.7344\n",
      "Epoch 871/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4524 - accuracy: 0.7847 - val_loss: 0.5180 - val_accuracy: 0.7344\n",
      "Epoch 872/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4524 - accuracy: 0.7847 - val_loss: 0.5180 - val_accuracy: 0.7344\n",
      "Epoch 873/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4524 - accuracy: 0.7847 - val_loss: 0.5180 - val_accuracy: 0.7344\n",
      "Epoch 874/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4524 - accuracy: 0.7847 - val_loss: 0.5180 - val_accuracy: 0.7344\n",
      "Epoch 875/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4524 - accuracy: 0.7847 - val_loss: 0.5180 - val_accuracy: 0.7344\n",
      "Epoch 876/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4523 - accuracy: 0.7847 - val_loss: 0.5180 - val_accuracy: 0.7344\n",
      "Epoch 877/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4523 - accuracy: 0.7847 - val_loss: 0.5180 - val_accuracy: 0.7344\n",
      "Epoch 878/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4523 - accuracy: 0.7847 - val_loss: 0.5180 - val_accuracy: 0.7344\n",
      "Epoch 879/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4523 - accuracy: 0.7847 - val_loss: 0.5180 - val_accuracy: 0.7344\n",
      "Epoch 880/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4523 - accuracy: 0.7847 - val_loss: 0.5180 - val_accuracy: 0.7344\n",
      "Epoch 881/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4523 - accuracy: 0.7847 - val_loss: 0.5180 - val_accuracy: 0.7344\n",
      "Epoch 882/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4523 - accuracy: 0.7847 - val_loss: 0.5180 - val_accuracy: 0.7344\n",
      "Epoch 883/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4523 - accuracy: 0.7847 - val_loss: 0.5180 - val_accuracy: 0.7344\n",
      "Epoch 884/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4522 - accuracy: 0.7847 - val_loss: 0.5181 - val_accuracy: 0.7344\n",
      "Epoch 885/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4522 - accuracy: 0.7847 - val_loss: 0.5181 - val_accuracy: 0.7344\n",
      "Epoch 886/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4522 - accuracy: 0.7847 - val_loss: 0.5181 - val_accuracy: 0.7344\n",
      "Epoch 887/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4522 - accuracy: 0.7847 - val_loss: 0.5181 - val_accuracy: 0.7344\n",
      "Epoch 888/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4522 - accuracy: 0.7847 - val_loss: 0.5181 - val_accuracy: 0.7344\n",
      "Epoch 889/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4522 - accuracy: 0.7847 - val_loss: 0.5181 - val_accuracy: 0.7344\n",
      "Epoch 890/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4522 - accuracy: 0.7847 - val_loss: 0.5181 - val_accuracy: 0.7344\n",
      "Epoch 891/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4521 - accuracy: 0.7847 - val_loss: 0.5181 - val_accuracy: 0.7344\n",
      "Epoch 892/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4522 - accuracy: 0.7847 - val_loss: 0.5181 - val_accuracy: 0.7344\n",
      "Epoch 893/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4521 - accuracy: 0.7847 - val_loss: 0.5181 - val_accuracy: 0.7344\n",
      "Epoch 894/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4521 - accuracy: 0.7847 - val_loss: 0.5181 - val_accuracy: 0.7344\n",
      "Epoch 895/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4521 - accuracy: 0.7847 - val_loss: 0.5181 - val_accuracy: 0.7344\n",
      "Epoch 896/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4521 - accuracy: 0.7847 - val_loss: 0.5181 - val_accuracy: 0.7344\n",
      "Epoch 897/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4521 - accuracy: 0.7847 - val_loss: 0.5181 - val_accuracy: 0.7344\n",
      "Epoch 898/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4521 - accuracy: 0.7847 - val_loss: 0.5181 - val_accuracy: 0.7344\n",
      "Epoch 899/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4521 - accuracy: 0.7847 - val_loss: 0.5181 - val_accuracy: 0.7344\n",
      "Epoch 900/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4521 - accuracy: 0.7847 - val_loss: 0.5181 - val_accuracy: 0.7344\n",
      "Epoch 901/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4520 - accuracy: 0.7847 - val_loss: 0.5181 - val_accuracy: 0.7344\n",
      "Epoch 902/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4520 - accuracy: 0.7847 - val_loss: 0.5181 - val_accuracy: 0.7344\n",
      "Epoch 903/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4520 - accuracy: 0.7847 - val_loss: 0.5181 - val_accuracy: 0.7344\n",
      "Epoch 904/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4520 - accuracy: 0.7847 - val_loss: 0.5181 - val_accuracy: 0.7344\n",
      "Epoch 905/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4520 - accuracy: 0.7847 - val_loss: 0.5181 - val_accuracy: 0.7344\n",
      "Epoch 906/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4520 - accuracy: 0.7847 - val_loss: 0.5182 - val_accuracy: 0.7344\n",
      "Epoch 907/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4520 - accuracy: 0.7847 - val_loss: 0.5182 - val_accuracy: 0.7344\n",
      "Epoch 908/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4520 - accuracy: 0.7847 - val_loss: 0.5182 - val_accuracy: 0.7292\n",
      "Epoch 909/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4519 - accuracy: 0.7847 - val_loss: 0.5182 - val_accuracy: 0.7292\n",
      "Epoch 910/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4519 - accuracy: 0.7847 - val_loss: 0.5182 - val_accuracy: 0.7292\n",
      "Epoch 911/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4519 - accuracy: 0.7847 - val_loss: 0.5182 - val_accuracy: 0.7292\n",
      "Epoch 912/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4519 - accuracy: 0.7847 - val_loss: 0.5182 - val_accuracy: 0.7292\n",
      "Epoch 913/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4519 - accuracy: 0.7847 - val_loss: 0.5182 - val_accuracy: 0.7292\n",
      "Epoch 914/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4519 - accuracy: 0.7847 - val_loss: 0.5182 - val_accuracy: 0.7292\n",
      "Epoch 915/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4519 - accuracy: 0.7847 - val_loss: 0.5182 - val_accuracy: 0.7292\n",
      "Epoch 916/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4519 - accuracy: 0.7847 - val_loss: 0.5182 - val_accuracy: 0.7292\n",
      "Epoch 917/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4519 - accuracy: 0.7847 - val_loss: 0.5182 - val_accuracy: 0.7292\n",
      "Epoch 918/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4519 - accuracy: 0.7847 - val_loss: 0.5182 - val_accuracy: 0.7292\n",
      "Epoch 919/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4518 - accuracy: 0.7847 - val_loss: 0.5182 - val_accuracy: 0.7292\n",
      "Epoch 920/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4518 - accuracy: 0.7847 - val_loss: 0.5182 - val_accuracy: 0.7292\n",
      "Epoch 921/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4518 - accuracy: 0.7847 - val_loss: 0.5182 - val_accuracy: 0.7292\n",
      "Epoch 922/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4518 - accuracy: 0.7847 - val_loss: 0.5182 - val_accuracy: 0.7292\n",
      "Epoch 923/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4518 - accuracy: 0.7847 - val_loss: 0.5182 - val_accuracy: 0.7292\n",
      "Epoch 924/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4518 - accuracy: 0.7847 - val_loss: 0.5182 - val_accuracy: 0.7292\n",
      "Epoch 925/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4518 - accuracy: 0.7847 - val_loss: 0.5182 - val_accuracy: 0.7292\n",
      "Epoch 926/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4518 - accuracy: 0.7847 - val_loss: 0.5183 - val_accuracy: 0.7292\n",
      "Epoch 927/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4518 - accuracy: 0.7847 - val_loss: 0.5183 - val_accuracy: 0.7292\n",
      "Epoch 928/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4517 - accuracy: 0.7847 - val_loss: 0.5183 - val_accuracy: 0.7292\n",
      "Epoch 929/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4517 - accuracy: 0.7847 - val_loss: 0.5183 - val_accuracy: 0.7292\n",
      "Epoch 930/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4517 - accuracy: 0.7847 - val_loss: 0.5183 - val_accuracy: 0.7292\n",
      "Epoch 931/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4517 - accuracy: 0.7847 - val_loss: 0.5183 - val_accuracy: 0.7292\n",
      "Epoch 932/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4517 - accuracy: 0.7847 - val_loss: 0.5183 - val_accuracy: 0.7292\n",
      "Epoch 933/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4517 - accuracy: 0.7847 - val_loss: 0.5183 - val_accuracy: 0.7292\n",
      "Epoch 934/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4517 - accuracy: 0.7847 - val_loss: 0.5183 - val_accuracy: 0.7292\n",
      "Epoch 935/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4517 - accuracy: 0.7847 - val_loss: 0.5183 - val_accuracy: 0.7292\n",
      "Epoch 936/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4516 - accuracy: 0.7847 - val_loss: 0.5183 - val_accuracy: 0.7292\n",
      "Epoch 937/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4516 - accuracy: 0.7847 - val_loss: 0.5183 - val_accuracy: 0.7292\n",
      "Epoch 938/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4516 - accuracy: 0.7847 - val_loss: 0.5183 - val_accuracy: 0.7292\n",
      "Epoch 939/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4516 - accuracy: 0.7847 - val_loss: 0.5183 - val_accuracy: 0.7292\n",
      "Epoch 940/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4516 - accuracy: 0.7847 - val_loss: 0.5183 - val_accuracy: 0.7292\n",
      "Epoch 941/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4516 - accuracy: 0.7847 - val_loss: 0.5183 - val_accuracy: 0.7292\n",
      "Epoch 942/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4516 - accuracy: 0.7847 - val_loss: 0.5183 - val_accuracy: 0.7292\n",
      "Epoch 943/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4516 - accuracy: 0.7847 - val_loss: 0.5183 - val_accuracy: 0.7292\n",
      "Epoch 944/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4516 - accuracy: 0.7847 - val_loss: 0.5183 - val_accuracy: 0.7292\n",
      "Epoch 945/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4515 - accuracy: 0.7847 - val_loss: 0.5184 - val_accuracy: 0.7292\n",
      "Epoch 946/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4515 - accuracy: 0.7847 - val_loss: 0.5184 - val_accuracy: 0.7292\n",
      "Epoch 947/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4515 - accuracy: 0.7847 - val_loss: 0.5184 - val_accuracy: 0.7292\n",
      "Epoch 948/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4515 - accuracy: 0.7847 - val_loss: 0.5184 - val_accuracy: 0.7292\n",
      "Epoch 949/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4515 - accuracy: 0.7847 - val_loss: 0.5184 - val_accuracy: 0.7292\n",
      "Epoch 950/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4515 - accuracy: 0.7847 - val_loss: 0.5184 - val_accuracy: 0.7292\n",
      "Epoch 951/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4515 - accuracy: 0.7847 - val_loss: 0.5184 - val_accuracy: 0.7292\n",
      "Epoch 952/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4515 - accuracy: 0.7847 - val_loss: 0.5184 - val_accuracy: 0.7292\n",
      "Epoch 953/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4514 - accuracy: 0.7847 - val_loss: 0.5184 - val_accuracy: 0.7292\n",
      "Epoch 954/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4514 - accuracy: 0.7847 - val_loss: 0.5184 - val_accuracy: 0.7292\n",
      "Epoch 955/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4514 - accuracy: 0.7847 - val_loss: 0.5184 - val_accuracy: 0.7292\n",
      "Epoch 956/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4514 - accuracy: 0.7847 - val_loss: 0.5184 - val_accuracy: 0.7292\n",
      "Epoch 957/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4514 - accuracy: 0.7847 - val_loss: 0.5184 - val_accuracy: 0.7292\n",
      "Epoch 958/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4514 - accuracy: 0.7847 - val_loss: 0.5184 - val_accuracy: 0.7292\n",
      "Epoch 959/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4514 - accuracy: 0.7847 - val_loss: 0.5184 - val_accuracy: 0.7292\n",
      "Epoch 960/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4514 - accuracy: 0.7847 - val_loss: 0.5184 - val_accuracy: 0.7292\n",
      "Epoch 961/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4514 - accuracy: 0.7847 - val_loss: 0.5184 - val_accuracy: 0.7292\n",
      "Epoch 962/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4514 - accuracy: 0.7847 - val_loss: 0.5184 - val_accuracy: 0.7292\n",
      "Epoch 963/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4514 - accuracy: 0.7847 - val_loss: 0.5184 - val_accuracy: 0.7292\n",
      "Epoch 964/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4514 - accuracy: 0.7847 - val_loss: 0.5184 - val_accuracy: 0.7292\n",
      "Epoch 965/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4514 - accuracy: 0.7847 - val_loss: 0.5184 - val_accuracy: 0.7292\n",
      "Epoch 966/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4513 - accuracy: 0.7847 - val_loss: 0.5184 - val_accuracy: 0.7292\n",
      "Epoch 967/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4513 - accuracy: 0.7847 - val_loss: 0.5185 - val_accuracy: 0.7292\n",
      "Epoch 968/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4513 - accuracy: 0.7847 - val_loss: 0.5185 - val_accuracy: 0.7292\n",
      "Epoch 969/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4513 - accuracy: 0.7847 - val_loss: 0.5185 - val_accuracy: 0.7292\n",
      "Epoch 970/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4513 - accuracy: 0.7847 - val_loss: 0.5185 - val_accuracy: 0.7292\n",
      "Epoch 971/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4513 - accuracy: 0.7847 - val_loss: 0.5185 - val_accuracy: 0.7292\n",
      "Epoch 972/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4513 - accuracy: 0.7847 - val_loss: 0.5185 - val_accuracy: 0.7292\n",
      "Epoch 973/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4512 - accuracy: 0.7847 - val_loss: 0.5185 - val_accuracy: 0.7292\n",
      "Epoch 974/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4512 - accuracy: 0.7847 - val_loss: 0.5185 - val_accuracy: 0.7292\n",
      "Epoch 975/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4512 - accuracy: 0.7847 - val_loss: 0.5185 - val_accuracy: 0.7292\n",
      "Epoch 976/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4512 - accuracy: 0.7847 - val_loss: 0.5185 - val_accuracy: 0.7292\n",
      "Epoch 977/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4512 - accuracy: 0.7847 - val_loss: 0.5185 - val_accuracy: 0.7292\n",
      "Epoch 978/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4512 - accuracy: 0.7847 - val_loss: 0.5185 - val_accuracy: 0.7292\n",
      "Epoch 979/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4512 - accuracy: 0.7847 - val_loss: 0.5185 - val_accuracy: 0.7292\n",
      "Epoch 980/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4512 - accuracy: 0.7830 - val_loss: 0.5185 - val_accuracy: 0.7344\n",
      "Epoch 981/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4512 - accuracy: 0.7847 - val_loss: 0.5185 - val_accuracy: 0.7344\n",
      "Epoch 982/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4512 - accuracy: 0.7847 - val_loss: 0.5185 - val_accuracy: 0.7344\n",
      "Epoch 983/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4511 - accuracy: 0.7847 - val_loss: 0.5185 - val_accuracy: 0.7344\n",
      "Epoch 984/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4511 - accuracy: 0.7847 - val_loss: 0.5185 - val_accuracy: 0.7344\n",
      "Epoch 985/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4511 - accuracy: 0.7847 - val_loss: 0.5185 - val_accuracy: 0.7344\n",
      "Epoch 986/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4511 - accuracy: 0.7830 - val_loss: 0.5185 - val_accuracy: 0.7344\n",
      "Epoch 987/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4511 - accuracy: 0.7847 - val_loss: 0.5185 - val_accuracy: 0.7344\n",
      "Epoch 988/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4511 - accuracy: 0.7847 - val_loss: 0.5185 - val_accuracy: 0.7344\n",
      "Epoch 989/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4511 - accuracy: 0.7830 - val_loss: 0.5186 - val_accuracy: 0.7344\n",
      "Epoch 990/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4511 - accuracy: 0.7830 - val_loss: 0.5186 - val_accuracy: 0.7344\n",
      "Epoch 991/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4511 - accuracy: 0.7830 - val_loss: 0.5186 - val_accuracy: 0.7344\n",
      "Epoch 992/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4510 - accuracy: 0.7830 - val_loss: 0.5186 - val_accuracy: 0.7344\n",
      "Epoch 993/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4510 - accuracy: 0.7830 - val_loss: 0.5186 - val_accuracy: 0.7344\n",
      "Epoch 994/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4510 - accuracy: 0.7830 - val_loss: 0.5186 - val_accuracy: 0.7344\n",
      "Epoch 995/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4510 - accuracy: 0.7830 - val_loss: 0.5186 - val_accuracy: 0.7344\n",
      "Epoch 996/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4510 - accuracy: 0.7830 - val_loss: 0.5186 - val_accuracy: 0.7344\n",
      "Epoch 997/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4510 - accuracy: 0.7830 - val_loss: 0.5186 - val_accuracy: 0.7344\n",
      "Epoch 998/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4510 - accuracy: 0.7830 - val_loss: 0.5186 - val_accuracy: 0.7344\n",
      "Epoch 999/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4510 - accuracy: 0.7830 - val_loss: 0.5186 - val_accuracy: 0.7344\n",
      "Epoch 1000/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4510 - accuracy: 0.7830 - val_loss: 0.5186 - val_accuracy: 0.7344\n"
     ]
    }
   ],
   "source": [
    "## Note that when we call \"fit\" again, it picks up where it left off\n",
    "run_hist1b = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1000)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.legend.Legend at 0x2b12e5196d0>"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 1152x576 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = len(run_hist_1.history['loss'])\n",
    "m = len(run_hist1b.history['loss'])\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "ax.plot(range(n), run_hist_1.history['loss'], 'r', marker='.', label='Train Loss - Run 1')\n",
    "ax.plot(range(n, n+m), run_hist1b.history['loss'], 'hotpink', marker='.', label='Train Loss - Run 2')\n",
    "\n",
    "ax.plot(range(n), run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss - Run 1\")\n",
    "ax.plot(range(n, n+m), run_hist1b.history[\"val_loss\"], 'LightSkyBlue', marker='.',  label=\"Validation Loss - Run 2\")\n",
    "\n",
    "ax.legend()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this graph begins where the other left off.  While the training loss is still going down, it looks like the validation loss has stabilized (or even gotten worse!).  This suggests that our network will not benefit from further training.  What is the appropriate number of epochs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "For this exercise, do the following in the cells below:\n",
    "- Build a model with two hidden layers, each with 6 nodes\n",
    "- Use the \"relu\" activation function for the hidden layers, and \"sigmoid\" for the final layer\n",
    "- Use a learning rate of .003 and train for 1500 epochs\n",
    "- Graph the trajectory of the loss functions, accuracy on both train and test set\n",
    "- Plot the roc curve for the predictions\n",
    "\n",
    "Experiment with different learning rates, numbers of epochs, and network structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.8049 - accuracy: 0.3420 - val_loss: 0.7738 - val_accuracy: 0.3802\n",
      "Epoch 2/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7900 - accuracy: 0.3559 - val_loss: 0.7611 - val_accuracy: 0.3906\n",
      "Epoch 3/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7767 - accuracy: 0.3559 - val_loss: 0.7498 - val_accuracy: 0.3906\n",
      "Epoch 4/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7645 - accuracy: 0.3594 - val_loss: 0.7394 - val_accuracy: 0.4062\n",
      "Epoch 5/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7534 - accuracy: 0.3698 - val_loss: 0.7299 - val_accuracy: 0.4167\n",
      "Epoch 6/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7432 - accuracy: 0.3767 - val_loss: 0.7214 - val_accuracy: 0.4167\n",
      "Epoch 7/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7338 - accuracy: 0.4167 - val_loss: 0.7136 - val_accuracy: 0.4635\n",
      "Epoch 8/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7253 - accuracy: 0.4705 - val_loss: 0.7063 - val_accuracy: 0.5104\n",
      "Epoch 9/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7173 - accuracy: 0.5000 - val_loss: 0.6996 - val_accuracy: 0.5469\n",
      "Epoch 10/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7098 - accuracy: 0.5469 - val_loss: 0.6933 - val_accuracy: 0.5781\n",
      "Epoch 11/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7029 - accuracy: 0.5781 - val_loss: 0.6874 - val_accuracy: 0.5938\n",
      "Epoch 12/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6964 - accuracy: 0.5972 - val_loss: 0.6820 - val_accuracy: 0.6094\n",
      "Epoch 13/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6904 - accuracy: 0.6267 - val_loss: 0.6770 - val_accuracy: 0.6406\n",
      "Epoch 14/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6848 - accuracy: 0.6337 - val_loss: 0.6724 - val_accuracy: 0.6458\n",
      "Epoch 15/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6795 - accuracy: 0.6562 - val_loss: 0.6681 - val_accuracy: 0.6667\n",
      "Epoch 16/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6745 - accuracy: 0.6632 - val_loss: 0.6640 - val_accuracy: 0.6823\n",
      "Epoch 17/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6698 - accuracy: 0.6771 - val_loss: 0.6602 - val_accuracy: 0.6927\n",
      "Epoch 18/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6653 - accuracy: 0.6753 - val_loss: 0.6566 - val_accuracy: 0.6927\n",
      "Epoch 19/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6611 - accuracy: 0.6788 - val_loss: 0.6532 - val_accuracy: 0.6875\n",
      "Epoch 20/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6572 - accuracy: 0.6823 - val_loss: 0.6500 - val_accuracy: 0.6823\n",
      "Epoch 21/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6534 - accuracy: 0.6892 - val_loss: 0.6470 - val_accuracy: 0.6875\n",
      "Epoch 22/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6498 - accuracy: 0.6875 - val_loss: 0.6441 - val_accuracy: 0.6875\n",
      "Epoch 23/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6465 - accuracy: 0.6892 - val_loss: 0.6413 - val_accuracy: 0.6927\n",
      "Epoch 24/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6433 - accuracy: 0.6875 - val_loss: 0.6387 - val_accuracy: 0.6927\n",
      "Epoch 25/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6403 - accuracy: 0.6840 - val_loss: 0.6362 - val_accuracy: 0.6927\n",
      "Epoch 26/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6373 - accuracy: 0.6788 - val_loss: 0.6339 - val_accuracy: 0.7083\n",
      "Epoch 27/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6345 - accuracy: 0.6771 - val_loss: 0.6316 - val_accuracy: 0.7083\n",
      "Epoch 28/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6319 - accuracy: 0.6753 - val_loss: 0.6294 - val_accuracy: 0.7135\n",
      "Epoch 29/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6294 - accuracy: 0.6788 - val_loss: 0.6273 - val_accuracy: 0.7135\n",
      "Epoch 30/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6270 - accuracy: 0.6823 - val_loss: 0.6254 - val_accuracy: 0.7135\n",
      "Epoch 31/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6246 - accuracy: 0.6840 - val_loss: 0.6235 - val_accuracy: 0.7135\n",
      "Epoch 32/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6224 - accuracy: 0.6875 - val_loss: 0.6217 - val_accuracy: 0.7188\n",
      "Epoch 33/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6203 - accuracy: 0.6858 - val_loss: 0.6200 - val_accuracy: 0.7188\n",
      "Epoch 34/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6182 - accuracy: 0.6858 - val_loss: 0.6183 - val_accuracy: 0.7135\n",
      "Epoch 35/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6162 - accuracy: 0.6892 - val_loss: 0.6167 - val_accuracy: 0.7083\n",
      "Epoch 36/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6142 - accuracy: 0.6875 - val_loss: 0.6152 - val_accuracy: 0.7083\n",
      "Epoch 37/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6124 - accuracy: 0.6858 - val_loss: 0.6137 - val_accuracy: 0.7083\n",
      "Epoch 38/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6106 - accuracy: 0.6875 - val_loss: 0.6123 - val_accuracy: 0.7083\n",
      "Epoch 39/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6088 - accuracy: 0.6892 - val_loss: 0.6109 - val_accuracy: 0.7083\n",
      "Epoch 40/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6072 - accuracy: 0.6927 - val_loss: 0.6096 - val_accuracy: 0.7135\n",
      "Epoch 41/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6055 - accuracy: 0.6944 - val_loss: 0.6083 - val_accuracy: 0.7135\n",
      "Epoch 42/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6039 - accuracy: 0.6944 - val_loss: 0.6070 - val_accuracy: 0.7135\n",
      "Epoch 43/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6023 - accuracy: 0.6962 - val_loss: 0.6058 - val_accuracy: 0.7135\n",
      "Epoch 44/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6007 - accuracy: 0.6997 - val_loss: 0.6046 - val_accuracy: 0.7135\n",
      "Epoch 45/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5992 - accuracy: 0.7014 - val_loss: 0.6034 - val_accuracy: 0.7135\n",
      "Epoch 46/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5977 - accuracy: 0.7014 - val_loss: 0.6023 - val_accuracy: 0.7135\n",
      "Epoch 47/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5963 - accuracy: 0.7049 - val_loss: 0.6011 - val_accuracy: 0.7083\n",
      "Epoch 48/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5948 - accuracy: 0.7083 - val_loss: 0.6000 - val_accuracy: 0.7031\n",
      "Epoch 49/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5934 - accuracy: 0.7083 - val_loss: 0.5990 - val_accuracy: 0.7031\n",
      "Epoch 50/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5921 - accuracy: 0.7101 - val_loss: 0.5979 - val_accuracy: 0.7083\n",
      "Epoch 51/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5908 - accuracy: 0.7101 - val_loss: 0.5969 - val_accuracy: 0.7083\n",
      "Epoch 52/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5895 - accuracy: 0.7083 - val_loss: 0.5959 - val_accuracy: 0.7083\n",
      "Epoch 53/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5882 - accuracy: 0.7101 - val_loss: 0.5949 - val_accuracy: 0.7188\n",
      "Epoch 54/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5869 - accuracy: 0.7118 - val_loss: 0.5939 - val_accuracy: 0.7240\n",
      "Epoch 55/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5857 - accuracy: 0.7135 - val_loss: 0.5929 - val_accuracy: 0.7188\n",
      "Epoch 56/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5844 - accuracy: 0.7135 - val_loss: 0.5920 - val_accuracy: 0.7188\n",
      "Epoch 57/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5832 - accuracy: 0.7170 - val_loss: 0.5910 - val_accuracy: 0.7240\n",
      "Epoch 58/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5821 - accuracy: 0.7170 - val_loss: 0.5901 - val_accuracy: 0.7240\n",
      "Epoch 59/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5809 - accuracy: 0.7153 - val_loss: 0.5892 - val_accuracy: 0.7240\n",
      "Epoch 60/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5797 - accuracy: 0.7153 - val_loss: 0.5883 - val_accuracy: 0.7240\n",
      "Epoch 61/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5786 - accuracy: 0.7153 - val_loss: 0.5874 - val_accuracy: 0.7240\n",
      "Epoch 62/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5774 - accuracy: 0.7135 - val_loss: 0.5865 - val_accuracy: 0.7240\n",
      "Epoch 63/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5762 - accuracy: 0.7153 - val_loss: 0.5856 - val_accuracy: 0.7240\n",
      "Epoch 64/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5751 - accuracy: 0.7170 - val_loss: 0.5848 - val_accuracy: 0.7135\n",
      "Epoch 65/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5740 - accuracy: 0.7170 - val_loss: 0.5840 - val_accuracy: 0.7240\n",
      "Epoch 66/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5729 - accuracy: 0.7170 - val_loss: 0.5832 - val_accuracy: 0.7240\n",
      "Epoch 67/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5718 - accuracy: 0.7170 - val_loss: 0.5824 - val_accuracy: 0.7240\n",
      "Epoch 68/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5708 - accuracy: 0.7170 - val_loss: 0.5816 - val_accuracy: 0.7240\n",
      "Epoch 69/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5697 - accuracy: 0.7153 - val_loss: 0.5808 - val_accuracy: 0.7240\n",
      "Epoch 70/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5686 - accuracy: 0.7188 - val_loss: 0.5800 - val_accuracy: 0.7240\n",
      "Epoch 71/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5676 - accuracy: 0.7188 - val_loss: 0.5793 - val_accuracy: 0.7240\n",
      "Epoch 72/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5665 - accuracy: 0.7170 - val_loss: 0.5786 - val_accuracy: 0.7240\n",
      "Epoch 73/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5655 - accuracy: 0.7188 - val_loss: 0.5778 - val_accuracy: 0.7240\n",
      "Epoch 74/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5645 - accuracy: 0.7205 - val_loss: 0.5771 - val_accuracy: 0.7240\n",
      "Epoch 75/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5634 - accuracy: 0.7205 - val_loss: 0.5764 - val_accuracy: 0.7240\n",
      "Epoch 76/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5624 - accuracy: 0.7222 - val_loss: 0.5758 - val_accuracy: 0.7240\n",
      "Epoch 77/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5614 - accuracy: 0.7222 - val_loss: 0.5751 - val_accuracy: 0.7240\n",
      "Epoch 78/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5604 - accuracy: 0.7222 - val_loss: 0.5744 - val_accuracy: 0.7292\n",
      "Epoch 79/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5594 - accuracy: 0.7222 - val_loss: 0.5738 - val_accuracy: 0.7292\n",
      "Epoch 80/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5585 - accuracy: 0.7240 - val_loss: 0.5731 - val_accuracy: 0.7292\n",
      "Epoch 81/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5575 - accuracy: 0.7240 - val_loss: 0.5725 - val_accuracy: 0.7292\n",
      "Epoch 82/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5565 - accuracy: 0.7240 - val_loss: 0.5719 - val_accuracy: 0.7292\n",
      "Epoch 83/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5556 - accuracy: 0.7240 - val_loss: 0.5712 - val_accuracy: 0.7292\n",
      "Epoch 84/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5546 - accuracy: 0.7240 - val_loss: 0.5706 - val_accuracy: 0.7344\n",
      "Epoch 85/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5537 - accuracy: 0.7257 - val_loss: 0.5700 - val_accuracy: 0.7344\n",
      "Epoch 86/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5527 - accuracy: 0.7274 - val_loss: 0.5695 - val_accuracy: 0.7344\n",
      "Epoch 87/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5518 - accuracy: 0.7257 - val_loss: 0.5689 - val_accuracy: 0.7344\n",
      "Epoch 88/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5509 - accuracy: 0.7257 - val_loss: 0.5683 - val_accuracy: 0.7344\n",
      "Epoch 89/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5500 - accuracy: 0.7257 - val_loss: 0.5678 - val_accuracy: 0.7344\n",
      "Epoch 90/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5491 - accuracy: 0.7257 - val_loss: 0.5673 - val_accuracy: 0.7344\n",
      "Epoch 91/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5482 - accuracy: 0.7292 - val_loss: 0.5667 - val_accuracy: 0.7344\n",
      "Epoch 92/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5473 - accuracy: 0.7292 - val_loss: 0.5661 - val_accuracy: 0.7292\n",
      "Epoch 93/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5464 - accuracy: 0.7309 - val_loss: 0.5656 - val_accuracy: 0.7292\n",
      "Epoch 94/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5455 - accuracy: 0.7309 - val_loss: 0.5651 - val_accuracy: 0.7292\n",
      "Epoch 95/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5447 - accuracy: 0.7292 - val_loss: 0.5646 - val_accuracy: 0.7292\n",
      "Epoch 96/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5438 - accuracy: 0.7292 - val_loss: 0.5641 - val_accuracy: 0.7292\n",
      "Epoch 97/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5430 - accuracy: 0.7326 - val_loss: 0.5636 - val_accuracy: 0.7292\n",
      "Epoch 98/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5421 - accuracy: 0.7326 - val_loss: 0.5631 - val_accuracy: 0.7292\n",
      "Epoch 99/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5413 - accuracy: 0.7344 - val_loss: 0.5627 - val_accuracy: 0.7240\n",
      "Epoch 100/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5405 - accuracy: 0.7344 - val_loss: 0.5622 - val_accuracy: 0.7240\n",
      "Epoch 101/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5397 - accuracy: 0.7326 - val_loss: 0.5618 - val_accuracy: 0.7135\n",
      "Epoch 102/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5389 - accuracy: 0.7326 - val_loss: 0.5613 - val_accuracy: 0.7135\n",
      "Epoch 103/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5381 - accuracy: 0.7309 - val_loss: 0.5609 - val_accuracy: 0.7083\n",
      "Epoch 104/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5373 - accuracy: 0.7292 - val_loss: 0.5604 - val_accuracy: 0.7083\n",
      "Epoch 105/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5365 - accuracy: 0.7274 - val_loss: 0.5600 - val_accuracy: 0.7083\n",
      "Epoch 106/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5357 - accuracy: 0.7274 - val_loss: 0.5595 - val_accuracy: 0.7135\n",
      "Epoch 107/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5349 - accuracy: 0.7309 - val_loss: 0.5590 - val_accuracy: 0.7135\n",
      "Epoch 108/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5341 - accuracy: 0.7309 - val_loss: 0.5586 - val_accuracy: 0.7135\n",
      "Epoch 109/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5333 - accuracy: 0.7326 - val_loss: 0.5581 - val_accuracy: 0.7135\n",
      "Epoch 110/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5325 - accuracy: 0.7326 - val_loss: 0.5577 - val_accuracy: 0.7135\n",
      "Epoch 111/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5317 - accuracy: 0.7344 - val_loss: 0.5573 - val_accuracy: 0.7135\n",
      "Epoch 112/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5310 - accuracy: 0.7344 - val_loss: 0.5568 - val_accuracy: 0.7135\n",
      "Epoch 113/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5302 - accuracy: 0.7361 - val_loss: 0.5564 - val_accuracy: 0.7135\n",
      "Epoch 114/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5294 - accuracy: 0.7344 - val_loss: 0.5560 - val_accuracy: 0.7135\n",
      "Epoch 115/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5287 - accuracy: 0.7344 - val_loss: 0.5556 - val_accuracy: 0.7083\n",
      "Epoch 116/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5280 - accuracy: 0.7378 - val_loss: 0.5552 - val_accuracy: 0.7031\n",
      "Epoch 117/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5273 - accuracy: 0.7396 - val_loss: 0.5549 - val_accuracy: 0.7031\n",
      "Epoch 118/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5266 - accuracy: 0.7361 - val_loss: 0.5545 - val_accuracy: 0.7031\n",
      "Epoch 119/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5259 - accuracy: 0.7396 - val_loss: 0.5542 - val_accuracy: 0.7031\n",
      "Epoch 120/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5253 - accuracy: 0.7396 - val_loss: 0.5538 - val_accuracy: 0.7031\n",
      "Epoch 121/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5246 - accuracy: 0.7396 - val_loss: 0.5535 - val_accuracy: 0.7031\n",
      "Epoch 122/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5239 - accuracy: 0.7431 - val_loss: 0.5531 - val_accuracy: 0.7031\n",
      "Epoch 123/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5232 - accuracy: 0.7413 - val_loss: 0.5528 - val_accuracy: 0.7031\n",
      "Epoch 124/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5226 - accuracy: 0.7396 - val_loss: 0.5524 - val_accuracy: 0.7031\n",
      "Epoch 125/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5219 - accuracy: 0.7413 - val_loss: 0.5521 - val_accuracy: 0.7031\n",
      "Epoch 126/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5212 - accuracy: 0.7448 - val_loss: 0.5518 - val_accuracy: 0.7031\n",
      "Epoch 127/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5206 - accuracy: 0.7448 - val_loss: 0.5515 - val_accuracy: 0.7031\n",
      "Epoch 128/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5199 - accuracy: 0.7465 - val_loss: 0.5512 - val_accuracy: 0.7031\n",
      "Epoch 129/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5193 - accuracy: 0.7483 - val_loss: 0.5509 - val_accuracy: 0.7031\n",
      "Epoch 130/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5186 - accuracy: 0.7483 - val_loss: 0.5506 - val_accuracy: 0.7031\n",
      "Epoch 131/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5179 - accuracy: 0.7483 - val_loss: 0.5504 - val_accuracy: 0.7031\n",
      "Epoch 132/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5172 - accuracy: 0.7483 - val_loss: 0.5501 - val_accuracy: 0.7031\n",
      "Epoch 133/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5165 - accuracy: 0.7483 - val_loss: 0.5498 - val_accuracy: 0.7031\n",
      "Epoch 134/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5159 - accuracy: 0.7483 - val_loss: 0.5496 - val_accuracy: 0.7031\n",
      "Epoch 135/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5152 - accuracy: 0.7483 - val_loss: 0.5493 - val_accuracy: 0.7083\n",
      "Epoch 136/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5146 - accuracy: 0.7483 - val_loss: 0.5490 - val_accuracy: 0.7083\n",
      "Epoch 137/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5140 - accuracy: 0.7483 - val_loss: 0.5487 - val_accuracy: 0.7083\n",
      "Epoch 138/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5134 - accuracy: 0.7483 - val_loss: 0.5484 - val_accuracy: 0.7083\n",
      "Epoch 139/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5128 - accuracy: 0.7483 - val_loss: 0.5481 - val_accuracy: 0.7083\n",
      "Epoch 140/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5122 - accuracy: 0.7483 - val_loss: 0.5479 - val_accuracy: 0.7083\n",
      "Epoch 141/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5116 - accuracy: 0.7483 - val_loss: 0.5476 - val_accuracy: 0.7031\n",
      "Epoch 142/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5111 - accuracy: 0.7500 - val_loss: 0.5474 - val_accuracy: 0.7031\n",
      "Epoch 143/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5105 - accuracy: 0.7483 - val_loss: 0.5471 - val_accuracy: 0.7083\n",
      "Epoch 144/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5099 - accuracy: 0.7517 - val_loss: 0.5469 - val_accuracy: 0.7083\n",
      "Epoch 145/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5094 - accuracy: 0.7500 - val_loss: 0.5466 - val_accuracy: 0.7083\n",
      "Epoch 146/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5089 - accuracy: 0.7483 - val_loss: 0.5464 - val_accuracy: 0.7135\n",
      "Epoch 147/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5084 - accuracy: 0.7483 - val_loss: 0.5462 - val_accuracy: 0.7135\n",
      "Epoch 148/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5079 - accuracy: 0.7517 - val_loss: 0.5460 - val_accuracy: 0.7188\n",
      "Epoch 149/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5073 - accuracy: 0.7500 - val_loss: 0.5458 - val_accuracy: 0.7188\n",
      "Epoch 150/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.7535 - val_loss: 0.5456 - val_accuracy: 0.7188\n",
      "Epoch 151/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.7552 - val_loss: 0.5454 - val_accuracy: 0.7188\n",
      "Epoch 152/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7569 - val_loss: 0.5452 - val_accuracy: 0.7240\n",
      "Epoch 153/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7587 - val_loss: 0.5451 - val_accuracy: 0.7240\n",
      "Epoch 154/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7587 - val_loss: 0.5449 - val_accuracy: 0.7240\n",
      "Epoch 155/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7569 - val_loss: 0.5447 - val_accuracy: 0.7292\n",
      "Epoch 156/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7569 - val_loss: 0.5446 - val_accuracy: 0.7292\n",
      "Epoch 157/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7569 - val_loss: 0.5444 - val_accuracy: 0.7292\n",
      "Epoch 158/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7552 - val_loss: 0.5443 - val_accuracy: 0.7292\n",
      "Epoch 159/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7569 - val_loss: 0.5442 - val_accuracy: 0.7292\n",
      "Epoch 160/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5020 - accuracy: 0.7552 - val_loss: 0.5440 - val_accuracy: 0.7292\n",
      "Epoch 161/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5015 - accuracy: 0.7552 - val_loss: 0.5439 - val_accuracy: 0.7292\n",
      "Epoch 162/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5010 - accuracy: 0.7552 - val_loss: 0.5438 - val_accuracy: 0.7344\n",
      "Epoch 163/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5006 - accuracy: 0.7535 - val_loss: 0.5437 - val_accuracy: 0.7344\n",
      "Epoch 164/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5001 - accuracy: 0.7552 - val_loss: 0.5435 - val_accuracy: 0.7396\n",
      "Epoch 165/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4997 - accuracy: 0.7535 - val_loss: 0.5435 - val_accuracy: 0.7396\n",
      "Epoch 166/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4992 - accuracy: 0.7552 - val_loss: 0.5434 - val_accuracy: 0.7344\n",
      "Epoch 167/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4988 - accuracy: 0.7552 - val_loss: 0.5433 - val_accuracy: 0.7344\n",
      "Epoch 168/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4984 - accuracy: 0.7552 - val_loss: 0.5432 - val_accuracy: 0.7344\n",
      "Epoch 169/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4979 - accuracy: 0.7552 - val_loss: 0.5431 - val_accuracy: 0.7344\n",
      "Epoch 170/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4976 - accuracy: 0.7552 - val_loss: 0.5430 - val_accuracy: 0.7344\n",
      "Epoch 171/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4972 - accuracy: 0.7569 - val_loss: 0.5429 - val_accuracy: 0.7344\n",
      "Epoch 172/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4968 - accuracy: 0.7569 - val_loss: 0.5428 - val_accuracy: 0.7344\n",
      "Epoch 173/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4963 - accuracy: 0.7569 - val_loss: 0.5428 - val_accuracy: 0.7344\n",
      "Epoch 174/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4960 - accuracy: 0.7569 - val_loss: 0.5427 - val_accuracy: 0.7344\n",
      "Epoch 175/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4956 - accuracy: 0.7569 - val_loss: 0.5426 - val_accuracy: 0.7396\n",
      "Epoch 176/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4952 - accuracy: 0.7604 - val_loss: 0.5426 - val_accuracy: 0.7396\n",
      "Epoch 177/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4948 - accuracy: 0.7604 - val_loss: 0.5425 - val_accuracy: 0.7396\n",
      "Epoch 178/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4945 - accuracy: 0.7604 - val_loss: 0.5425 - val_accuracy: 0.7344\n",
      "Epoch 179/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4941 - accuracy: 0.7587 - val_loss: 0.5424 - val_accuracy: 0.7344\n",
      "Epoch 180/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4938 - accuracy: 0.7587 - val_loss: 0.5424 - val_accuracy: 0.7344\n",
      "Epoch 181/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4934 - accuracy: 0.7587 - val_loss: 0.5423 - val_accuracy: 0.7292\n",
      "Epoch 182/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4931 - accuracy: 0.7587 - val_loss: 0.5423 - val_accuracy: 0.7292\n",
      "Epoch 183/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4928 - accuracy: 0.7587 - val_loss: 0.5422 - val_accuracy: 0.7292\n",
      "Epoch 184/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4924 - accuracy: 0.7587 - val_loss: 0.5422 - val_accuracy: 0.7292\n",
      "Epoch 185/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4921 - accuracy: 0.7587 - val_loss: 0.5422 - val_accuracy: 0.7240\n",
      "Epoch 186/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4917 - accuracy: 0.7587 - val_loss: 0.5422 - val_accuracy: 0.7292\n",
      "Epoch 187/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4914 - accuracy: 0.7604 - val_loss: 0.5422 - val_accuracy: 0.7292\n",
      "Epoch 188/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4911 - accuracy: 0.7622 - val_loss: 0.5422 - val_accuracy: 0.7292\n",
      "Epoch 189/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4907 - accuracy: 0.7622 - val_loss: 0.5422 - val_accuracy: 0.7292\n",
      "Epoch 190/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4904 - accuracy: 0.7622 - val_loss: 0.5422 - val_accuracy: 0.7292\n",
      "Epoch 191/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4901 - accuracy: 0.7622 - val_loss: 0.5422 - val_accuracy: 0.7240\n",
      "Epoch 192/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4898 - accuracy: 0.7622 - val_loss: 0.5423 - val_accuracy: 0.7240\n",
      "Epoch 193/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4895 - accuracy: 0.7622 - val_loss: 0.5423 - val_accuracy: 0.7240\n",
      "Epoch 194/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4892 - accuracy: 0.7622 - val_loss: 0.5423 - val_accuracy: 0.7240\n",
      "Epoch 195/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4889 - accuracy: 0.7639 - val_loss: 0.5424 - val_accuracy: 0.7240\n",
      "Epoch 196/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4886 - accuracy: 0.7622 - val_loss: 0.5424 - val_accuracy: 0.7188\n",
      "Epoch 197/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4883 - accuracy: 0.7622 - val_loss: 0.5424 - val_accuracy: 0.7188\n",
      "Epoch 198/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4880 - accuracy: 0.7604 - val_loss: 0.5424 - val_accuracy: 0.7188\n",
      "Epoch 199/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4877 - accuracy: 0.7604 - val_loss: 0.5425 - val_accuracy: 0.7188\n",
      "Epoch 200/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4874 - accuracy: 0.7604 - val_loss: 0.5425 - val_accuracy: 0.7188\n",
      "Epoch 201/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4871 - accuracy: 0.7622 - val_loss: 0.5425 - val_accuracy: 0.7188\n",
      "Epoch 202/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4869 - accuracy: 0.7622 - val_loss: 0.5426 - val_accuracy: 0.7188\n",
      "Epoch 203/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4866 - accuracy: 0.7622 - val_loss: 0.5426 - val_accuracy: 0.7188\n",
      "Epoch 204/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4863 - accuracy: 0.7622 - val_loss: 0.5426 - val_accuracy: 0.7135\n",
      "Epoch 205/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4860 - accuracy: 0.7639 - val_loss: 0.5426 - val_accuracy: 0.7135\n",
      "Epoch 206/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4858 - accuracy: 0.7639 - val_loss: 0.5427 - val_accuracy: 0.7135\n",
      "Epoch 207/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4855 - accuracy: 0.7639 - val_loss: 0.5427 - val_accuracy: 0.7135\n",
      "Epoch 208/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4853 - accuracy: 0.7622 - val_loss: 0.5428 - val_accuracy: 0.7135\n",
      "Epoch 209/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4850 - accuracy: 0.7639 - val_loss: 0.5428 - val_accuracy: 0.7135\n",
      "Epoch 210/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4847 - accuracy: 0.7639 - val_loss: 0.5428 - val_accuracy: 0.7135\n",
      "Epoch 211/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4845 - accuracy: 0.7622 - val_loss: 0.5429 - val_accuracy: 0.7135\n",
      "Epoch 212/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4843 - accuracy: 0.7622 - val_loss: 0.5429 - val_accuracy: 0.7135\n",
      "Epoch 213/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4840 - accuracy: 0.7639 - val_loss: 0.5429 - val_accuracy: 0.7135\n",
      "Epoch 214/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4838 - accuracy: 0.7639 - val_loss: 0.5430 - val_accuracy: 0.7135\n",
      "Epoch 215/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4835 - accuracy: 0.7639 - val_loss: 0.5430 - val_accuracy: 0.7135\n",
      "Epoch 216/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4833 - accuracy: 0.7639 - val_loss: 0.5431 - val_accuracy: 0.7135\n",
      "Epoch 217/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4830 - accuracy: 0.7639 - val_loss: 0.5431 - val_accuracy: 0.7135\n",
      "Epoch 218/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4828 - accuracy: 0.7656 - val_loss: 0.5432 - val_accuracy: 0.7135\n",
      "Epoch 219/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4825 - accuracy: 0.7656 - val_loss: 0.5432 - val_accuracy: 0.7135\n",
      "Epoch 220/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4822 - accuracy: 0.7656 - val_loss: 0.5433 - val_accuracy: 0.7135\n",
      "Epoch 221/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4820 - accuracy: 0.7656 - val_loss: 0.5434 - val_accuracy: 0.7135\n",
      "Epoch 222/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4818 - accuracy: 0.7656 - val_loss: 0.5434 - val_accuracy: 0.7135\n",
      "Epoch 223/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4815 - accuracy: 0.7639 - val_loss: 0.5435 - val_accuracy: 0.7135\n",
      "Epoch 224/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4813 - accuracy: 0.7639 - val_loss: 0.5436 - val_accuracy: 0.7135\n",
      "Epoch 225/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4811 - accuracy: 0.7639 - val_loss: 0.5436 - val_accuracy: 0.7135\n",
      "Epoch 226/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4808 - accuracy: 0.7622 - val_loss: 0.5437 - val_accuracy: 0.7135\n",
      "Epoch 227/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4806 - accuracy: 0.7639 - val_loss: 0.5438 - val_accuracy: 0.7135\n",
      "Epoch 228/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4804 - accuracy: 0.7622 - val_loss: 0.5438 - val_accuracy: 0.7135\n",
      "Epoch 229/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4802 - accuracy: 0.7622 - val_loss: 0.5439 - val_accuracy: 0.7135\n",
      "Epoch 230/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4800 - accuracy: 0.7622 - val_loss: 0.5440 - val_accuracy: 0.7135\n",
      "Epoch 231/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4798 - accuracy: 0.7622 - val_loss: 0.5440 - val_accuracy: 0.7135\n",
      "Epoch 232/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4796 - accuracy: 0.7639 - val_loss: 0.5441 - val_accuracy: 0.7188\n",
      "Epoch 233/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4794 - accuracy: 0.7639 - val_loss: 0.5441 - val_accuracy: 0.7188\n",
      "Epoch 234/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4792 - accuracy: 0.7639 - val_loss: 0.5442 - val_accuracy: 0.7188\n",
      "Epoch 235/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4790 - accuracy: 0.7639 - val_loss: 0.5443 - val_accuracy: 0.7188\n",
      "Epoch 236/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4788 - accuracy: 0.7639 - val_loss: 0.5443 - val_accuracy: 0.7188\n",
      "Epoch 237/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4786 - accuracy: 0.7656 - val_loss: 0.5444 - val_accuracy: 0.7188\n",
      "Epoch 238/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4784 - accuracy: 0.7639 - val_loss: 0.5444 - val_accuracy: 0.7188\n",
      "Epoch 239/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4782 - accuracy: 0.7656 - val_loss: 0.5445 - val_accuracy: 0.7188\n",
      "Epoch 240/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4781 - accuracy: 0.7656 - val_loss: 0.5445 - val_accuracy: 0.7188\n",
      "Epoch 241/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4779 - accuracy: 0.7656 - val_loss: 0.5445 - val_accuracy: 0.7188\n",
      "Epoch 242/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4777 - accuracy: 0.7656 - val_loss: 0.5446 - val_accuracy: 0.7188\n",
      "Epoch 243/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4775 - accuracy: 0.7656 - val_loss: 0.5446 - val_accuracy: 0.7188\n",
      "Epoch 244/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4774 - accuracy: 0.7656 - val_loss: 0.5447 - val_accuracy: 0.7240\n",
      "Epoch 245/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4771 - accuracy: 0.7656 - val_loss: 0.5447 - val_accuracy: 0.7240\n",
      "Epoch 246/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4770 - accuracy: 0.7656 - val_loss: 0.5447 - val_accuracy: 0.7292\n",
      "Epoch 247/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4768 - accuracy: 0.7656 - val_loss: 0.5448 - val_accuracy: 0.7292\n",
      "Epoch 248/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4767 - accuracy: 0.7639 - val_loss: 0.5448 - val_accuracy: 0.7292\n",
      "Epoch 249/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4765 - accuracy: 0.7656 - val_loss: 0.5449 - val_accuracy: 0.7292\n",
      "Epoch 250/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4763 - accuracy: 0.7656 - val_loss: 0.5449 - val_accuracy: 0.7292\n",
      "Epoch 251/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4761 - accuracy: 0.7656 - val_loss: 0.5450 - val_accuracy: 0.7292\n",
      "Epoch 252/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4760 - accuracy: 0.7656 - val_loss: 0.5450 - val_accuracy: 0.7292\n",
      "Epoch 253/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4758 - accuracy: 0.7656 - val_loss: 0.5450 - val_accuracy: 0.7292\n",
      "Epoch 254/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4757 - accuracy: 0.7656 - val_loss: 0.5451 - val_accuracy: 0.7292\n",
      "Epoch 255/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4755 - accuracy: 0.7656 - val_loss: 0.5451 - val_accuracy: 0.7292\n",
      "Epoch 256/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4754 - accuracy: 0.7674 - val_loss: 0.5452 - val_accuracy: 0.7292\n",
      "Epoch 257/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4752 - accuracy: 0.7674 - val_loss: 0.5452 - val_accuracy: 0.7292\n",
      "Epoch 258/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4751 - accuracy: 0.7674 - val_loss: 0.5452 - val_accuracy: 0.7344\n",
      "Epoch 259/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4749 - accuracy: 0.7674 - val_loss: 0.5453 - val_accuracy: 0.7396\n",
      "Epoch 260/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4748 - accuracy: 0.7674 - val_loss: 0.5453 - val_accuracy: 0.7396\n",
      "Epoch 261/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4746 - accuracy: 0.7691 - val_loss: 0.5454 - val_accuracy: 0.7396\n",
      "Epoch 262/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4745 - accuracy: 0.7691 - val_loss: 0.5454 - val_accuracy: 0.7396\n",
      "Epoch 263/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4743 - accuracy: 0.7691 - val_loss: 0.5454 - val_accuracy: 0.7396\n",
      "Epoch 264/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4741 - accuracy: 0.7691 - val_loss: 0.5455 - val_accuracy: 0.7396\n",
      "Epoch 265/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4740 - accuracy: 0.7708 - val_loss: 0.5455 - val_accuracy: 0.7396\n",
      "Epoch 266/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4739 - accuracy: 0.7708 - val_loss: 0.5456 - val_accuracy: 0.7396\n",
      "Epoch 267/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4737 - accuracy: 0.7708 - val_loss: 0.5456 - val_accuracy: 0.7396\n",
      "Epoch 268/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4736 - accuracy: 0.7708 - val_loss: 0.5456 - val_accuracy: 0.7396\n",
      "Epoch 269/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4734 - accuracy: 0.7708 - val_loss: 0.5457 - val_accuracy: 0.7396\n",
      "Epoch 270/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4733 - accuracy: 0.7708 - val_loss: 0.5457 - val_accuracy: 0.7396\n",
      "Epoch 271/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4731 - accuracy: 0.7708 - val_loss: 0.5458 - val_accuracy: 0.7396\n",
      "Epoch 272/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4730 - accuracy: 0.7708 - val_loss: 0.5458 - val_accuracy: 0.7396\n",
      "Epoch 273/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4729 - accuracy: 0.7708 - val_loss: 0.5458 - val_accuracy: 0.7396\n",
      "Epoch 274/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4727 - accuracy: 0.7691 - val_loss: 0.5459 - val_accuracy: 0.7396\n",
      "Epoch 275/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4725 - accuracy: 0.7708 - val_loss: 0.5459 - val_accuracy: 0.7396\n",
      "Epoch 276/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4724 - accuracy: 0.7708 - val_loss: 0.5460 - val_accuracy: 0.7396\n",
      "Epoch 277/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4723 - accuracy: 0.7708 - val_loss: 0.5460 - val_accuracy: 0.7396\n",
      "Epoch 278/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4721 - accuracy: 0.7708 - val_loss: 0.5461 - val_accuracy: 0.7448\n",
      "Epoch 279/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4719 - accuracy: 0.7708 - val_loss: 0.5461 - val_accuracy: 0.7448\n",
      "Epoch 280/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4718 - accuracy: 0.7708 - val_loss: 0.5462 - val_accuracy: 0.7448\n",
      "Epoch 281/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4717 - accuracy: 0.7708 - val_loss: 0.5462 - val_accuracy: 0.7448\n",
      "Epoch 282/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4715 - accuracy: 0.7708 - val_loss: 0.5462 - val_accuracy: 0.7448\n",
      "Epoch 283/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4714 - accuracy: 0.7691 - val_loss: 0.5463 - val_accuracy: 0.7448\n",
      "Epoch 284/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4713 - accuracy: 0.7691 - val_loss: 0.5463 - val_accuracy: 0.7448\n",
      "Epoch 285/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4711 - accuracy: 0.7691 - val_loss: 0.5463 - val_accuracy: 0.7448\n",
      "Epoch 286/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4709 - accuracy: 0.7674 - val_loss: 0.5464 - val_accuracy: 0.7448\n",
      "Epoch 287/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4708 - accuracy: 0.7674 - val_loss: 0.5464 - val_accuracy: 0.7448\n",
      "Epoch 288/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4707 - accuracy: 0.7656 - val_loss: 0.5465 - val_accuracy: 0.7448\n",
      "Epoch 289/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4705 - accuracy: 0.7656 - val_loss: 0.5465 - val_accuracy: 0.7448\n",
      "Epoch 290/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4704 - accuracy: 0.7656 - val_loss: 0.5466 - val_accuracy: 0.7448\n",
      "Epoch 291/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4702 - accuracy: 0.7656 - val_loss: 0.5466 - val_accuracy: 0.7448\n",
      "Epoch 292/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4701 - accuracy: 0.7656 - val_loss: 0.5467 - val_accuracy: 0.7396\n",
      "Epoch 293/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4699 - accuracy: 0.7656 - val_loss: 0.5468 - val_accuracy: 0.7344\n",
      "Epoch 294/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4697 - accuracy: 0.7656 - val_loss: 0.5468 - val_accuracy: 0.7344\n",
      "Epoch 295/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4696 - accuracy: 0.7674 - val_loss: 0.5469 - val_accuracy: 0.7344\n",
      "Epoch 296/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4695 - accuracy: 0.7656 - val_loss: 0.5469 - val_accuracy: 0.7344\n",
      "Epoch 297/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4693 - accuracy: 0.7674 - val_loss: 0.5470 - val_accuracy: 0.7344\n",
      "Epoch 298/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4692 - accuracy: 0.7674 - val_loss: 0.5470 - val_accuracy: 0.7344\n",
      "Epoch 299/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4690 - accuracy: 0.7674 - val_loss: 0.5471 - val_accuracy: 0.7344\n",
      "Epoch 300/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4689 - accuracy: 0.7691 - val_loss: 0.5472 - val_accuracy: 0.7344\n",
      "Epoch 301/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4688 - accuracy: 0.7726 - val_loss: 0.5472 - val_accuracy: 0.7344\n",
      "Epoch 302/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4687 - accuracy: 0.7708 - val_loss: 0.5473 - val_accuracy: 0.7344\n",
      "Epoch 303/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4685 - accuracy: 0.7726 - val_loss: 0.5473 - val_accuracy: 0.7344\n",
      "Epoch 304/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4684 - accuracy: 0.7726 - val_loss: 0.5474 - val_accuracy: 0.7344\n",
      "Epoch 305/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4682 - accuracy: 0.7726 - val_loss: 0.5474 - val_accuracy: 0.7344\n",
      "Epoch 306/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4681 - accuracy: 0.7726 - val_loss: 0.5475 - val_accuracy: 0.7344\n",
      "Epoch 307/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4680 - accuracy: 0.7726 - val_loss: 0.5475 - val_accuracy: 0.7344\n",
      "Epoch 308/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4678 - accuracy: 0.7726 - val_loss: 0.5475 - val_accuracy: 0.7344\n",
      "Epoch 309/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4677 - accuracy: 0.7726 - val_loss: 0.5476 - val_accuracy: 0.7344\n",
      "Epoch 310/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4675 - accuracy: 0.7726 - val_loss: 0.5476 - val_accuracy: 0.7292\n",
      "Epoch 311/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4674 - accuracy: 0.7726 - val_loss: 0.5477 - val_accuracy: 0.7292\n",
      "Epoch 312/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4673 - accuracy: 0.7726 - val_loss: 0.5477 - val_accuracy: 0.7292\n",
      "Epoch 313/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4672 - accuracy: 0.7708 - val_loss: 0.5477 - val_accuracy: 0.7240\n",
      "Epoch 314/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4670 - accuracy: 0.7743 - val_loss: 0.5478 - val_accuracy: 0.7240\n",
      "Epoch 315/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4669 - accuracy: 0.7743 - val_loss: 0.5478 - val_accuracy: 0.7240\n",
      "Epoch 316/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4668 - accuracy: 0.7743 - val_loss: 0.5479 - val_accuracy: 0.7240\n",
      "Epoch 317/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4667 - accuracy: 0.7743 - val_loss: 0.5479 - val_accuracy: 0.7240\n",
      "Epoch 318/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4665 - accuracy: 0.7743 - val_loss: 0.5479 - val_accuracy: 0.7240\n",
      "Epoch 319/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4664 - accuracy: 0.7743 - val_loss: 0.5480 - val_accuracy: 0.7240\n",
      "Epoch 320/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4663 - accuracy: 0.7760 - val_loss: 0.5480 - val_accuracy: 0.7240\n",
      "Epoch 321/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4662 - accuracy: 0.7743 - val_loss: 0.5481 - val_accuracy: 0.7240\n",
      "Epoch 322/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4660 - accuracy: 0.7760 - val_loss: 0.5481 - val_accuracy: 0.7240\n",
      "Epoch 323/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4659 - accuracy: 0.7726 - val_loss: 0.5481 - val_accuracy: 0.7240\n",
      "Epoch 324/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4658 - accuracy: 0.7726 - val_loss: 0.5482 - val_accuracy: 0.7240\n",
      "Epoch 325/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4657 - accuracy: 0.7726 - val_loss: 0.5482 - val_accuracy: 0.7188\n",
      "Epoch 326/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4656 - accuracy: 0.7743 - val_loss: 0.5482 - val_accuracy: 0.7188\n",
      "Epoch 327/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4655 - accuracy: 0.7726 - val_loss: 0.5483 - val_accuracy: 0.7188\n",
      "Epoch 328/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4653 - accuracy: 0.7726 - val_loss: 0.5483 - val_accuracy: 0.7188\n",
      "Epoch 329/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4652 - accuracy: 0.7726 - val_loss: 0.5483 - val_accuracy: 0.7188\n",
      "Epoch 330/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4651 - accuracy: 0.7726 - val_loss: 0.5484 - val_accuracy: 0.7188\n",
      "Epoch 331/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4650 - accuracy: 0.7726 - val_loss: 0.5484 - val_accuracy: 0.7188\n",
      "Epoch 332/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4649 - accuracy: 0.7726 - val_loss: 0.5485 - val_accuracy: 0.7188\n",
      "Epoch 333/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4648 - accuracy: 0.7726 - val_loss: 0.5485 - val_accuracy: 0.7188\n",
      "Epoch 334/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4647 - accuracy: 0.7726 - val_loss: 0.5485 - val_accuracy: 0.7188\n",
      "Epoch 335/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7708 - val_loss: 0.5486 - val_accuracy: 0.7188\n",
      "Epoch 336/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4644 - accuracy: 0.7726 - val_loss: 0.5486 - val_accuracy: 0.7188\n",
      "Epoch 337/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4643 - accuracy: 0.7726 - val_loss: 0.5487 - val_accuracy: 0.7188\n",
      "Epoch 338/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4642 - accuracy: 0.7708 - val_loss: 0.5487 - val_accuracy: 0.7188\n",
      "Epoch 339/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4641 - accuracy: 0.7708 - val_loss: 0.5487 - val_accuracy: 0.7188\n",
      "Epoch 340/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4640 - accuracy: 0.7726 - val_loss: 0.5488 - val_accuracy: 0.7188\n",
      "Epoch 341/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4638 - accuracy: 0.7708 - val_loss: 0.5488 - val_accuracy: 0.7188\n",
      "Epoch 342/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4637 - accuracy: 0.7708 - val_loss: 0.5489 - val_accuracy: 0.7188\n",
      "Epoch 343/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 0.7708 - val_loss: 0.5489 - val_accuracy: 0.7188\n",
      "Epoch 344/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4635 - accuracy: 0.7708 - val_loss: 0.5489 - val_accuracy: 0.7188\n",
      "Epoch 345/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4634 - accuracy: 0.7708 - val_loss: 0.5490 - val_accuracy: 0.7188\n",
      "Epoch 346/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4633 - accuracy: 0.7708 - val_loss: 0.5490 - val_accuracy: 0.7188\n",
      "Epoch 347/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4632 - accuracy: 0.7708 - val_loss: 0.5491 - val_accuracy: 0.7188\n",
      "Epoch 348/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.7708 - val_loss: 0.5491 - val_accuracy: 0.7188\n",
      "Epoch 349/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4630 - accuracy: 0.7726 - val_loss: 0.5491 - val_accuracy: 0.7188\n",
      "Epoch 350/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4629 - accuracy: 0.7726 - val_loss: 0.5492 - val_accuracy: 0.7188\n",
      "Epoch 351/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4628 - accuracy: 0.7726 - val_loss: 0.5492 - val_accuracy: 0.7188\n",
      "Epoch 352/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4627 - accuracy: 0.7743 - val_loss: 0.5492 - val_accuracy: 0.7188\n",
      "Epoch 353/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4626 - accuracy: 0.7726 - val_loss: 0.5492 - val_accuracy: 0.7188\n",
      "Epoch 354/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 0.7726 - val_loss: 0.5493 - val_accuracy: 0.7188\n",
      "Epoch 355/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.7726 - val_loss: 0.5493 - val_accuracy: 0.7188\n",
      "Epoch 356/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4623 - accuracy: 0.7726 - val_loss: 0.5493 - val_accuracy: 0.7188\n",
      "Epoch 357/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4622 - accuracy: 0.7726 - val_loss: 0.5494 - val_accuracy: 0.7188\n",
      "Epoch 358/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4621 - accuracy: 0.7743 - val_loss: 0.5494 - val_accuracy: 0.7188\n",
      "Epoch 359/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.7708 - val_loss: 0.5494 - val_accuracy: 0.7188\n",
      "Epoch 360/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4619 - accuracy: 0.7743 - val_loss: 0.5495 - val_accuracy: 0.7188\n",
      "Epoch 361/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.7743 - val_loss: 0.5495 - val_accuracy: 0.7188\n",
      "Epoch 362/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4617 - accuracy: 0.7726 - val_loss: 0.5495 - val_accuracy: 0.7188\n",
      "Epoch 363/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4617 - accuracy: 0.7743 - val_loss: 0.5495 - val_accuracy: 0.7188\n",
      "Epoch 364/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.7743 - val_loss: 0.5496 - val_accuracy: 0.7188\n",
      "Epoch 365/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4614 - accuracy: 0.7743 - val_loss: 0.5496 - val_accuracy: 0.7188\n",
      "Epoch 366/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4613 - accuracy: 0.7743 - val_loss: 0.5496 - val_accuracy: 0.7188\n",
      "Epoch 367/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4613 - accuracy: 0.7743 - val_loss: 0.5496 - val_accuracy: 0.7188\n",
      "Epoch 368/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.7795 - val_loss: 0.5496 - val_accuracy: 0.7188\n",
      "Epoch 369/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4610 - accuracy: 0.7760 - val_loss: 0.5497 - val_accuracy: 0.7188\n",
      "Epoch 370/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.7778 - val_loss: 0.5497 - val_accuracy: 0.7188\n",
      "Epoch 371/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.7778 - val_loss: 0.5497 - val_accuracy: 0.7188\n",
      "Epoch 372/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.7778 - val_loss: 0.5497 - val_accuracy: 0.7240\n",
      "Epoch 373/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.7778 - val_loss: 0.5497 - val_accuracy: 0.7240\n",
      "Epoch 374/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.7778 - val_loss: 0.5497 - val_accuracy: 0.7188\n",
      "Epoch 375/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.7778 - val_loss: 0.5497 - val_accuracy: 0.7188\n",
      "Epoch 376/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.7778 - val_loss: 0.5498 - val_accuracy: 0.7188\n",
      "Epoch 377/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.7778 - val_loss: 0.5498 - val_accuracy: 0.7188\n",
      "Epoch 378/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4600 - accuracy: 0.7778 - val_loss: 0.5498 - val_accuracy: 0.7188\n",
      "Epoch 379/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.7778 - val_loss: 0.5498 - val_accuracy: 0.7188\n",
      "Epoch 380/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4597 - accuracy: 0.7778 - val_loss: 0.5498 - val_accuracy: 0.7188\n",
      "Epoch 381/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4596 - accuracy: 0.7778 - val_loss: 0.5498 - val_accuracy: 0.7188\n",
      "Epoch 382/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4595 - accuracy: 0.7778 - val_loss: 0.5499 - val_accuracy: 0.7188\n",
      "Epoch 383/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4594 - accuracy: 0.7778 - val_loss: 0.5499 - val_accuracy: 0.7188\n",
      "Epoch 384/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4592 - accuracy: 0.7795 - val_loss: 0.5499 - val_accuracy: 0.7188\n",
      "Epoch 385/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4591 - accuracy: 0.7795 - val_loss: 0.5499 - val_accuracy: 0.7188\n",
      "Epoch 386/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.7795 - val_loss: 0.5499 - val_accuracy: 0.7188\n",
      "Epoch 387/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4589 - accuracy: 0.7795 - val_loss: 0.5498 - val_accuracy: 0.7188\n",
      "Epoch 388/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.7795 - val_loss: 0.5498 - val_accuracy: 0.7188\n",
      "Epoch 389/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4587 - accuracy: 0.7778 - val_loss: 0.5498 - val_accuracy: 0.7188\n",
      "Epoch 390/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4586 - accuracy: 0.7795 - val_loss: 0.5498 - val_accuracy: 0.7188\n",
      "Epoch 391/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4584 - accuracy: 0.7778 - val_loss: 0.5498 - val_accuracy: 0.7188\n",
      "Epoch 392/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4583 - accuracy: 0.7795 - val_loss: 0.5498 - val_accuracy: 0.7135\n",
      "Epoch 393/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4582 - accuracy: 0.7795 - val_loss: 0.5497 - val_accuracy: 0.7135\n",
      "Epoch 394/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4581 - accuracy: 0.7795 - val_loss: 0.5497 - val_accuracy: 0.7135\n",
      "Epoch 395/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4580 - accuracy: 0.7795 - val_loss: 0.5497 - val_accuracy: 0.7135\n",
      "Epoch 396/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4580 - accuracy: 0.7795 - val_loss: 0.5496 - val_accuracy: 0.7135\n",
      "Epoch 397/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4578 - accuracy: 0.7795 - val_loss: 0.5496 - val_accuracy: 0.7135\n",
      "Epoch 398/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4577 - accuracy: 0.7795 - val_loss: 0.5496 - val_accuracy: 0.7135\n",
      "Epoch 399/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4576 - accuracy: 0.7795 - val_loss: 0.5496 - val_accuracy: 0.7135\n",
      "Epoch 400/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4575 - accuracy: 0.7795 - val_loss: 0.5495 - val_accuracy: 0.7135\n",
      "Epoch 401/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4574 - accuracy: 0.7795 - val_loss: 0.5495 - val_accuracy: 0.7135\n",
      "Epoch 402/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4573 - accuracy: 0.7795 - val_loss: 0.5495 - val_accuracy: 0.7135\n",
      "Epoch 403/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4572 - accuracy: 0.7795 - val_loss: 0.5495 - val_accuracy: 0.7135\n",
      "Epoch 404/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4571 - accuracy: 0.7795 - val_loss: 0.5494 - val_accuracy: 0.7135\n",
      "Epoch 405/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4570 - accuracy: 0.7812 - val_loss: 0.5494 - val_accuracy: 0.7135\n",
      "Epoch 406/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4568 - accuracy: 0.7795 - val_loss: 0.5494 - val_accuracy: 0.7135\n",
      "Epoch 407/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4567 - accuracy: 0.7795 - val_loss: 0.5493 - val_accuracy: 0.7135\n",
      "Epoch 408/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4566 - accuracy: 0.7795 - val_loss: 0.5493 - val_accuracy: 0.7135\n",
      "Epoch 409/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4566 - accuracy: 0.7812 - val_loss: 0.5493 - val_accuracy: 0.7135\n",
      "Epoch 410/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4565 - accuracy: 0.7812 - val_loss: 0.5493 - val_accuracy: 0.7135\n",
      "Epoch 411/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4563 - accuracy: 0.7795 - val_loss: 0.5492 - val_accuracy: 0.7135\n",
      "Epoch 412/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4562 - accuracy: 0.7812 - val_loss: 0.5492 - val_accuracy: 0.7135\n",
      "Epoch 413/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4562 - accuracy: 0.7812 - val_loss: 0.5492 - val_accuracy: 0.7135\n",
      "Epoch 414/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4560 - accuracy: 0.7795 - val_loss: 0.5491 - val_accuracy: 0.7135\n",
      "Epoch 415/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4559 - accuracy: 0.7812 - val_loss: 0.5491 - val_accuracy: 0.7135\n",
      "Epoch 416/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4559 - accuracy: 0.7812 - val_loss: 0.5491 - val_accuracy: 0.7135\n",
      "Epoch 417/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4557 - accuracy: 0.7812 - val_loss: 0.5490 - val_accuracy: 0.7135\n",
      "Epoch 418/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4556 - accuracy: 0.7812 - val_loss: 0.5490 - val_accuracy: 0.7135\n",
      "Epoch 419/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4555 - accuracy: 0.7812 - val_loss: 0.5490 - val_accuracy: 0.7135\n",
      "Epoch 420/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4554 - accuracy: 0.7812 - val_loss: 0.5490 - val_accuracy: 0.7135\n",
      "Epoch 421/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4553 - accuracy: 0.7812 - val_loss: 0.5489 - val_accuracy: 0.7135\n",
      "Epoch 422/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4552 - accuracy: 0.7812 - val_loss: 0.5489 - val_accuracy: 0.7135\n",
      "Epoch 423/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4551 - accuracy: 0.7812 - val_loss: 0.5489 - val_accuracy: 0.7135\n",
      "Epoch 424/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4550 - accuracy: 0.7812 - val_loss: 0.5489 - val_accuracy: 0.7135\n",
      "Epoch 425/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4549 - accuracy: 0.7812 - val_loss: 0.5489 - val_accuracy: 0.7135\n",
      "Epoch 426/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4547 - accuracy: 0.7812 - val_loss: 0.5488 - val_accuracy: 0.7135\n",
      "Epoch 427/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4547 - accuracy: 0.7812 - val_loss: 0.5488 - val_accuracy: 0.7135\n",
      "Epoch 428/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4545 - accuracy: 0.7812 - val_loss: 0.5487 - val_accuracy: 0.7135\n",
      "Epoch 429/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4544 - accuracy: 0.7812 - val_loss: 0.5487 - val_accuracy: 0.7135\n",
      "Epoch 430/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4543 - accuracy: 0.7812 - val_loss: 0.5487 - val_accuracy: 0.7135\n",
      "Epoch 431/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4542 - accuracy: 0.7812 - val_loss: 0.5486 - val_accuracy: 0.7135\n",
      "Epoch 432/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4540 - accuracy: 0.7795 - val_loss: 0.5486 - val_accuracy: 0.7135\n",
      "Epoch 433/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4539 - accuracy: 0.7812 - val_loss: 0.5486 - val_accuracy: 0.7135\n",
      "Epoch 434/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4538 - accuracy: 0.7812 - val_loss: 0.5485 - val_accuracy: 0.7188\n",
      "Epoch 435/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4537 - accuracy: 0.7795 - val_loss: 0.5485 - val_accuracy: 0.7188\n",
      "Epoch 436/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4536 - accuracy: 0.7795 - val_loss: 0.5485 - val_accuracy: 0.7188\n",
      "Epoch 437/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4535 - accuracy: 0.7795 - val_loss: 0.5485 - val_accuracy: 0.7188\n",
      "Epoch 438/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4534 - accuracy: 0.7795 - val_loss: 0.5484 - val_accuracy: 0.7188\n",
      "Epoch 439/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4533 - accuracy: 0.7795 - val_loss: 0.5484 - val_accuracy: 0.7188\n",
      "Epoch 440/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4531 - accuracy: 0.7795 - val_loss: 0.5484 - val_accuracy: 0.7188\n",
      "Epoch 441/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4530 - accuracy: 0.7795 - val_loss: 0.5483 - val_accuracy: 0.7188\n",
      "Epoch 442/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4529 - accuracy: 0.7812 - val_loss: 0.5483 - val_accuracy: 0.7188\n",
      "Epoch 443/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4529 - accuracy: 0.7778 - val_loss: 0.5483 - val_accuracy: 0.7188\n",
      "Epoch 444/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4527 - accuracy: 0.7812 - val_loss: 0.5483 - val_accuracy: 0.7188\n",
      "Epoch 445/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4527 - accuracy: 0.7795 - val_loss: 0.5483 - val_accuracy: 0.7188\n",
      "Epoch 446/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4525 - accuracy: 0.7778 - val_loss: 0.5482 - val_accuracy: 0.7188\n",
      "Epoch 447/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4525 - accuracy: 0.7795 - val_loss: 0.5482 - val_accuracy: 0.7188\n",
      "Epoch 448/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4523 - accuracy: 0.7778 - val_loss: 0.5482 - val_accuracy: 0.7188\n",
      "Epoch 449/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4523 - accuracy: 0.7795 - val_loss: 0.5482 - val_accuracy: 0.7240\n",
      "Epoch 450/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4522 - accuracy: 0.7795 - val_loss: 0.5482 - val_accuracy: 0.7240\n",
      "Epoch 451/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4521 - accuracy: 0.7795 - val_loss: 0.5482 - val_accuracy: 0.7240\n",
      "Epoch 452/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4520 - accuracy: 0.7812 - val_loss: 0.5481 - val_accuracy: 0.7240\n",
      "Epoch 453/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4518 - accuracy: 0.7795 - val_loss: 0.5481 - val_accuracy: 0.7240\n",
      "Epoch 454/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4518 - accuracy: 0.7795 - val_loss: 0.5481 - val_accuracy: 0.7240\n",
      "Epoch 455/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4517 - accuracy: 0.7795 - val_loss: 0.5480 - val_accuracy: 0.7240\n",
      "Epoch 456/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4516 - accuracy: 0.7795 - val_loss: 0.5480 - val_accuracy: 0.7240\n",
      "Epoch 457/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4515 - accuracy: 0.7795 - val_loss: 0.5480 - val_accuracy: 0.7240\n",
      "Epoch 458/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4514 - accuracy: 0.7778 - val_loss: 0.5479 - val_accuracy: 0.7240\n",
      "Epoch 459/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4514 - accuracy: 0.7795 - val_loss: 0.5479 - val_accuracy: 0.7240\n",
      "Epoch 460/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4512 - accuracy: 0.7795 - val_loss: 0.5479 - val_accuracy: 0.7240\n",
      "Epoch 461/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4511 - accuracy: 0.7778 - val_loss: 0.5478 - val_accuracy: 0.7240\n",
      "Epoch 462/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4510 - accuracy: 0.7778 - val_loss: 0.5478 - val_accuracy: 0.7240\n",
      "Epoch 463/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4509 - accuracy: 0.7778 - val_loss: 0.5478 - val_accuracy: 0.7240\n",
      "Epoch 464/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4508 - accuracy: 0.7778 - val_loss: 0.5477 - val_accuracy: 0.7240\n",
      "Epoch 465/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4507 - accuracy: 0.7778 - val_loss: 0.5477 - val_accuracy: 0.7240\n",
      "Epoch 466/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4507 - accuracy: 0.7778 - val_loss: 0.5477 - val_accuracy: 0.7240\n",
      "Epoch 467/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4506 - accuracy: 0.7778 - val_loss: 0.5476 - val_accuracy: 0.7240\n",
      "Epoch 468/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4505 - accuracy: 0.7778 - val_loss: 0.5476 - val_accuracy: 0.7240\n",
      "Epoch 469/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4505 - accuracy: 0.7778 - val_loss: 0.5476 - val_accuracy: 0.7240\n",
      "Epoch 470/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4503 - accuracy: 0.7778 - val_loss: 0.5475 - val_accuracy: 0.7240\n",
      "Epoch 471/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4502 - accuracy: 0.7778 - val_loss: 0.5475 - val_accuracy: 0.7240\n",
      "Epoch 472/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4502 - accuracy: 0.7778 - val_loss: 0.5474 - val_accuracy: 0.7240\n",
      "Epoch 473/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4501 - accuracy: 0.7778 - val_loss: 0.5474 - val_accuracy: 0.7240\n",
      "Epoch 474/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4500 - accuracy: 0.7778 - val_loss: 0.5474 - val_accuracy: 0.7240\n",
      "Epoch 475/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4499 - accuracy: 0.7778 - val_loss: 0.5473 - val_accuracy: 0.7240\n",
      "Epoch 476/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4498 - accuracy: 0.7778 - val_loss: 0.5473 - val_accuracy: 0.7240\n",
      "Epoch 477/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4497 - accuracy: 0.7778 - val_loss: 0.5473 - val_accuracy: 0.7240\n",
      "Epoch 478/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4496 - accuracy: 0.7778 - val_loss: 0.5472 - val_accuracy: 0.7240\n",
      "Epoch 479/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4495 - accuracy: 0.7795 - val_loss: 0.5472 - val_accuracy: 0.7240\n",
      "Epoch 480/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4494 - accuracy: 0.7795 - val_loss: 0.5472 - val_accuracy: 0.7240\n",
      "Epoch 481/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4494 - accuracy: 0.7795 - val_loss: 0.5471 - val_accuracy: 0.7240\n",
      "Epoch 482/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4493 - accuracy: 0.7795 - val_loss: 0.5471 - val_accuracy: 0.7240\n",
      "Epoch 483/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4492 - accuracy: 0.7795 - val_loss: 0.5471 - val_accuracy: 0.7240\n",
      "Epoch 484/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4491 - accuracy: 0.7795 - val_loss: 0.5470 - val_accuracy: 0.7240\n",
      "Epoch 485/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4490 - accuracy: 0.7795 - val_loss: 0.5470 - val_accuracy: 0.7240\n",
      "Epoch 486/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4489 - accuracy: 0.7795 - val_loss: 0.5470 - val_accuracy: 0.7240\n",
      "Epoch 487/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4489 - accuracy: 0.7795 - val_loss: 0.5469 - val_accuracy: 0.7240\n",
      "Epoch 488/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4488 - accuracy: 0.7795 - val_loss: 0.5469 - val_accuracy: 0.7240\n",
      "Epoch 489/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4488 - accuracy: 0.7795 - val_loss: 0.5469 - val_accuracy: 0.7240\n",
      "Epoch 490/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4487 - accuracy: 0.7795 - val_loss: 0.5469 - val_accuracy: 0.7240\n",
      "Epoch 491/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4486 - accuracy: 0.7795 - val_loss: 0.5468 - val_accuracy: 0.7240\n",
      "Epoch 492/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4485 - accuracy: 0.7795 - val_loss: 0.5468 - val_accuracy: 0.7240\n",
      "Epoch 493/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4484 - accuracy: 0.7795 - val_loss: 0.5468 - val_accuracy: 0.7240\n",
      "Epoch 494/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4483 - accuracy: 0.7795 - val_loss: 0.5467 - val_accuracy: 0.7240\n",
      "Epoch 495/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4483 - accuracy: 0.7795 - val_loss: 0.5467 - val_accuracy: 0.7240\n",
      "Epoch 496/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4482 - accuracy: 0.7795 - val_loss: 0.5467 - val_accuracy: 0.7240\n",
      "Epoch 497/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4482 - accuracy: 0.7795 - val_loss: 0.5467 - val_accuracy: 0.7240\n",
      "Epoch 498/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4481 - accuracy: 0.7778 - val_loss: 0.5467 - val_accuracy: 0.7240\n",
      "Epoch 499/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4480 - accuracy: 0.7795 - val_loss: 0.5466 - val_accuracy: 0.7240\n",
      "Epoch 500/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4479 - accuracy: 0.7795 - val_loss: 0.5466 - val_accuracy: 0.7240\n",
      "Epoch 501/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4478 - accuracy: 0.7778 - val_loss: 0.5466 - val_accuracy: 0.7240\n",
      "Epoch 502/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4477 - accuracy: 0.7795 - val_loss: 0.5466 - val_accuracy: 0.7240\n",
      "Epoch 503/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4476 - accuracy: 0.7795 - val_loss: 0.5465 - val_accuracy: 0.7240\n",
      "Epoch 504/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4476 - accuracy: 0.7778 - val_loss: 0.5465 - val_accuracy: 0.7240\n",
      "Epoch 505/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4475 - accuracy: 0.7760 - val_loss: 0.5465 - val_accuracy: 0.7240\n",
      "Epoch 506/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4473 - accuracy: 0.7760 - val_loss: 0.5465 - val_accuracy: 0.7240\n",
      "Epoch 507/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4473 - accuracy: 0.7760 - val_loss: 0.5464 - val_accuracy: 0.7240\n",
      "Epoch 508/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4473 - accuracy: 0.7760 - val_loss: 0.5464 - val_accuracy: 0.7240\n",
      "Epoch 509/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4471 - accuracy: 0.7760 - val_loss: 0.5464 - val_accuracy: 0.7240\n",
      "Epoch 510/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4471 - accuracy: 0.7760 - val_loss: 0.5464 - val_accuracy: 0.7240\n",
      "Epoch 511/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4470 - accuracy: 0.7760 - val_loss: 0.5464 - val_accuracy: 0.7240\n",
      "Epoch 512/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4470 - accuracy: 0.7760 - val_loss: 0.5463 - val_accuracy: 0.7240\n",
      "Epoch 513/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4469 - accuracy: 0.7760 - val_loss: 0.5463 - val_accuracy: 0.7240\n",
      "Epoch 514/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4468 - accuracy: 0.7760 - val_loss: 0.5463 - val_accuracy: 0.7240\n",
      "Epoch 515/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4467 - accuracy: 0.7760 - val_loss: 0.5463 - val_accuracy: 0.7240\n",
      "Epoch 516/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4467 - accuracy: 0.7778 - val_loss: 0.5463 - val_accuracy: 0.7240\n",
      "Epoch 517/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4466 - accuracy: 0.7760 - val_loss: 0.5463 - val_accuracy: 0.7240\n",
      "Epoch 518/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4465 - accuracy: 0.7778 - val_loss: 0.5462 - val_accuracy: 0.7240\n",
      "Epoch 519/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4465 - accuracy: 0.7778 - val_loss: 0.5462 - val_accuracy: 0.7240\n",
      "Epoch 520/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4464 - accuracy: 0.7778 - val_loss: 0.5462 - val_accuracy: 0.7240\n",
      "Epoch 521/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4463 - accuracy: 0.7778 - val_loss: 0.5462 - val_accuracy: 0.7240\n",
      "Epoch 522/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4463 - accuracy: 0.7778 - val_loss: 0.5462 - val_accuracy: 0.7240\n",
      "Epoch 523/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4462 - accuracy: 0.7760 - val_loss: 0.5462 - val_accuracy: 0.7240\n",
      "Epoch 524/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4461 - accuracy: 0.7778 - val_loss: 0.5462 - val_accuracy: 0.7240\n",
      "Epoch 525/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4461 - accuracy: 0.7778 - val_loss: 0.5462 - val_accuracy: 0.7240\n",
      "Epoch 526/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4460 - accuracy: 0.7778 - val_loss: 0.5462 - val_accuracy: 0.7240\n",
      "Epoch 527/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4459 - accuracy: 0.7778 - val_loss: 0.5462 - val_accuracy: 0.7240\n",
      "Epoch 528/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4459 - accuracy: 0.7778 - val_loss: 0.5461 - val_accuracy: 0.7240\n",
      "Epoch 529/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4458 - accuracy: 0.7778 - val_loss: 0.5461 - val_accuracy: 0.7240\n",
      "Epoch 530/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4458 - accuracy: 0.7778 - val_loss: 0.5461 - val_accuracy: 0.7240\n",
      "Epoch 531/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4457 - accuracy: 0.7778 - val_loss: 0.5461 - val_accuracy: 0.7240\n",
      "Epoch 532/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4456 - accuracy: 0.7778 - val_loss: 0.5461 - val_accuracy: 0.7240\n",
      "Epoch 533/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4456 - accuracy: 0.7778 - val_loss: 0.5461 - val_accuracy: 0.7240\n",
      "Epoch 534/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4455 - accuracy: 0.7778 - val_loss: 0.5461 - val_accuracy: 0.7240\n",
      "Epoch 535/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4455 - accuracy: 0.7760 - val_loss: 0.5461 - val_accuracy: 0.7240\n",
      "Epoch 536/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4454 - accuracy: 0.7760 - val_loss: 0.5461 - val_accuracy: 0.7240\n",
      "Epoch 537/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4454 - accuracy: 0.7778 - val_loss: 0.5461 - val_accuracy: 0.7240\n",
      "Epoch 538/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4453 - accuracy: 0.7743 - val_loss: 0.5461 - val_accuracy: 0.7240\n",
      "Epoch 539/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4452 - accuracy: 0.7760 - val_loss: 0.5461 - val_accuracy: 0.7240\n",
      "Epoch 540/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4452 - accuracy: 0.7743 - val_loss: 0.5461 - val_accuracy: 0.7240\n",
      "Epoch 541/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4452 - accuracy: 0.7743 - val_loss: 0.5461 - val_accuracy: 0.7240\n",
      "Epoch 542/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4451 - accuracy: 0.7743 - val_loss: 0.5461 - val_accuracy: 0.7240\n",
      "Epoch 543/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4450 - accuracy: 0.7743 - val_loss: 0.5461 - val_accuracy: 0.7240\n",
      "Epoch 544/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4450 - accuracy: 0.7743 - val_loss: 0.5461 - val_accuracy: 0.7240\n",
      "Epoch 545/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4449 - accuracy: 0.7743 - val_loss: 0.5461 - val_accuracy: 0.7240\n",
      "Epoch 546/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4449 - accuracy: 0.7743 - val_loss: 0.5461 - val_accuracy: 0.7240\n",
      "Epoch 547/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4448 - accuracy: 0.7743 - val_loss: 0.5460 - val_accuracy: 0.7240\n",
      "Epoch 548/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4447 - accuracy: 0.7760 - val_loss: 0.5460 - val_accuracy: 0.7240\n",
      "Epoch 549/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4447 - accuracy: 0.7743 - val_loss: 0.5460 - val_accuracy: 0.7240\n",
      "Epoch 550/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4447 - accuracy: 0.7760 - val_loss: 0.5460 - val_accuracy: 0.7240\n",
      "Epoch 551/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4446 - accuracy: 0.7726 - val_loss: 0.5460 - val_accuracy: 0.7240\n",
      "Epoch 552/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4445 - accuracy: 0.7743 - val_loss: 0.5460 - val_accuracy: 0.7240\n",
      "Epoch 553/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4445 - accuracy: 0.7726 - val_loss: 0.5459 - val_accuracy: 0.7240\n",
      "Epoch 554/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4444 - accuracy: 0.7760 - val_loss: 0.5459 - val_accuracy: 0.7240\n",
      "Epoch 555/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4443 - accuracy: 0.7760 - val_loss: 0.5459 - val_accuracy: 0.7240\n",
      "Epoch 556/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4443 - accuracy: 0.7760 - val_loss: 0.5459 - val_accuracy: 0.7240\n",
      "Epoch 557/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4442 - accuracy: 0.7760 - val_loss: 0.5459 - val_accuracy: 0.7240\n",
      "Epoch 558/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4442 - accuracy: 0.7760 - val_loss: 0.5459 - val_accuracy: 0.7240\n",
      "Epoch 559/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4441 - accuracy: 0.7760 - val_loss: 0.5459 - val_accuracy: 0.7240\n",
      "Epoch 560/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4441 - accuracy: 0.7760 - val_loss: 0.5458 - val_accuracy: 0.7240\n",
      "Epoch 561/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4440 - accuracy: 0.7760 - val_loss: 0.5458 - val_accuracy: 0.7240\n",
      "Epoch 562/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4440 - accuracy: 0.7760 - val_loss: 0.5458 - val_accuracy: 0.7240\n",
      "Epoch 563/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4439 - accuracy: 0.7760 - val_loss: 0.5458 - val_accuracy: 0.7240\n",
      "Epoch 564/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4439 - accuracy: 0.7760 - val_loss: 0.5458 - val_accuracy: 0.7240\n",
      "Epoch 565/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4438 - accuracy: 0.7760 - val_loss: 0.5458 - val_accuracy: 0.7292\n",
      "Epoch 566/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4438 - accuracy: 0.7760 - val_loss: 0.5458 - val_accuracy: 0.7292\n",
      "Epoch 567/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4437 - accuracy: 0.7760 - val_loss: 0.5458 - val_accuracy: 0.7292\n",
      "Epoch 568/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4437 - accuracy: 0.7760 - val_loss: 0.5457 - val_accuracy: 0.7292\n",
      "Epoch 569/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4436 - accuracy: 0.7760 - val_loss: 0.5457 - val_accuracy: 0.7292\n",
      "Epoch 570/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4436 - accuracy: 0.7760 - val_loss: 0.5457 - val_accuracy: 0.7292\n",
      "Epoch 571/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4435 - accuracy: 0.7760 - val_loss: 0.5457 - val_accuracy: 0.7292\n",
      "Epoch 572/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4434 - accuracy: 0.7760 - val_loss: 0.5457 - val_accuracy: 0.7292\n",
      "Epoch 573/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4434 - accuracy: 0.7760 - val_loss: 0.5457 - val_accuracy: 0.7292\n",
      "Epoch 574/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4434 - accuracy: 0.7760 - val_loss: 0.5457 - val_accuracy: 0.7292\n",
      "Epoch 575/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4433 - accuracy: 0.7760 - val_loss: 0.5456 - val_accuracy: 0.7292\n",
      "Epoch 576/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4433 - accuracy: 0.7760 - val_loss: 0.5456 - val_accuracy: 0.7292\n",
      "Epoch 577/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4432 - accuracy: 0.7760 - val_loss: 0.5456 - val_accuracy: 0.7292\n",
      "Epoch 578/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4432 - accuracy: 0.7760 - val_loss: 0.5456 - val_accuracy: 0.7292\n",
      "Epoch 579/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4431 - accuracy: 0.7760 - val_loss: 0.5455 - val_accuracy: 0.7292\n",
      "Epoch 580/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4431 - accuracy: 0.7760 - val_loss: 0.5455 - val_accuracy: 0.7292\n",
      "Epoch 581/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4430 - accuracy: 0.7760 - val_loss: 0.5455 - val_accuracy: 0.7292\n",
      "Epoch 582/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4429 - accuracy: 0.7760 - val_loss: 0.5455 - val_accuracy: 0.7292\n",
      "Epoch 583/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4429 - accuracy: 0.7760 - val_loss: 0.5455 - val_accuracy: 0.7292\n",
      "Epoch 584/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4429 - accuracy: 0.7760 - val_loss: 0.5455 - val_accuracy: 0.7292\n",
      "Epoch 585/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4428 - accuracy: 0.7760 - val_loss: 0.5454 - val_accuracy: 0.7292\n",
      "Epoch 586/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4428 - accuracy: 0.7760 - val_loss: 0.5454 - val_accuracy: 0.7292\n",
      "Epoch 587/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4427 - accuracy: 0.7760 - val_loss: 0.5454 - val_accuracy: 0.7292\n",
      "Epoch 588/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4426 - accuracy: 0.7760 - val_loss: 0.5454 - val_accuracy: 0.7292\n",
      "Epoch 589/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4426 - accuracy: 0.7760 - val_loss: 0.5454 - val_accuracy: 0.7292\n",
      "Epoch 590/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4425 - accuracy: 0.7760 - val_loss: 0.5454 - val_accuracy: 0.7292\n",
      "Epoch 591/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4425 - accuracy: 0.7760 - val_loss: 0.5454 - val_accuracy: 0.7292\n",
      "Epoch 592/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4425 - accuracy: 0.7760 - val_loss: 0.5454 - val_accuracy: 0.7292\n",
      "Epoch 593/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4424 - accuracy: 0.7760 - val_loss: 0.5454 - val_accuracy: 0.7292\n",
      "Epoch 594/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4423 - accuracy: 0.7760 - val_loss: 0.5454 - val_accuracy: 0.7292\n",
      "Epoch 595/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4423 - accuracy: 0.7760 - val_loss: 0.5453 - val_accuracy: 0.7292\n",
      "Epoch 596/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4422 - accuracy: 0.7760 - val_loss: 0.5453 - val_accuracy: 0.7292\n",
      "Epoch 597/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4422 - accuracy: 0.7760 - val_loss: 0.5453 - val_accuracy: 0.7292\n",
      "Epoch 598/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4422 - accuracy: 0.7760 - val_loss: 0.5453 - val_accuracy: 0.7292\n",
      "Epoch 599/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4421 - accuracy: 0.7760 - val_loss: 0.5453 - val_accuracy: 0.7292\n",
      "Epoch 600/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4421 - accuracy: 0.7760 - val_loss: 0.5453 - val_accuracy: 0.7292\n",
      "Epoch 601/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4421 - accuracy: 0.7760 - val_loss: 0.5452 - val_accuracy: 0.7292\n",
      "Epoch 602/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4419 - accuracy: 0.7760 - val_loss: 0.5452 - val_accuracy: 0.7292\n",
      "Epoch 603/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4419 - accuracy: 0.7760 - val_loss: 0.5452 - val_accuracy: 0.7240\n",
      "Epoch 604/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4419 - accuracy: 0.7760 - val_loss: 0.5452 - val_accuracy: 0.7240\n",
      "Epoch 605/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4418 - accuracy: 0.7760 - val_loss: 0.5452 - val_accuracy: 0.7240\n",
      "Epoch 606/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4418 - accuracy: 0.7760 - val_loss: 0.5451 - val_accuracy: 0.7240\n",
      "Epoch 607/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4417 - accuracy: 0.7760 - val_loss: 0.5451 - val_accuracy: 0.7240\n",
      "Epoch 608/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4418 - accuracy: 0.7760 - val_loss: 0.5451 - val_accuracy: 0.7240\n",
      "Epoch 609/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4417 - accuracy: 0.7760 - val_loss: 0.5451 - val_accuracy: 0.7240\n",
      "Epoch 610/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4417 - accuracy: 0.7760 - val_loss: 0.5451 - val_accuracy: 0.7240\n",
      "Epoch 611/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4416 - accuracy: 0.7760 - val_loss: 0.5450 - val_accuracy: 0.7240\n",
      "Epoch 612/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4415 - accuracy: 0.7760 - val_loss: 0.5450 - val_accuracy: 0.7240\n",
      "Epoch 613/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4415 - accuracy: 0.7760 - val_loss: 0.5450 - val_accuracy: 0.7240\n",
      "Epoch 614/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4415 - accuracy: 0.7760 - val_loss: 0.5450 - val_accuracy: 0.7240\n",
      "Epoch 615/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4414 - accuracy: 0.7760 - val_loss: 0.5450 - val_accuracy: 0.7240\n",
      "Epoch 616/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4414 - accuracy: 0.7760 - val_loss: 0.5449 - val_accuracy: 0.7240\n",
      "Epoch 617/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4413 - accuracy: 0.7760 - val_loss: 0.5449 - val_accuracy: 0.7240\n",
      "Epoch 618/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4413 - accuracy: 0.7760 - val_loss: 0.5449 - val_accuracy: 0.7240\n",
      "Epoch 619/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4412 - accuracy: 0.7760 - val_loss: 0.5449 - val_accuracy: 0.7240\n",
      "Epoch 620/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4412 - accuracy: 0.7760 - val_loss: 0.5449 - val_accuracy: 0.7240\n",
      "Epoch 621/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4411 - accuracy: 0.7778 - val_loss: 0.5449 - val_accuracy: 0.7240\n",
      "Epoch 622/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4411 - accuracy: 0.7795 - val_loss: 0.5448 - val_accuracy: 0.7240\n",
      "Epoch 623/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4410 - accuracy: 0.7778 - val_loss: 0.5448 - val_accuracy: 0.7240\n",
      "Epoch 624/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4410 - accuracy: 0.7760 - val_loss: 0.5448 - val_accuracy: 0.7240\n",
      "Epoch 625/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4410 - accuracy: 0.7778 - val_loss: 0.5448 - val_accuracy: 0.7240\n",
      "Epoch 626/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4409 - accuracy: 0.7778 - val_loss: 0.5448 - val_accuracy: 0.7240\n",
      "Epoch 627/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4409 - accuracy: 0.7795 - val_loss: 0.5448 - val_accuracy: 0.7240\n",
      "Epoch 628/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4408 - accuracy: 0.7778 - val_loss: 0.5448 - val_accuracy: 0.7240\n",
      "Epoch 629/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4408 - accuracy: 0.7795 - val_loss: 0.5448 - val_accuracy: 0.7240\n",
      "Epoch 630/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4408 - accuracy: 0.7778 - val_loss: 0.5447 - val_accuracy: 0.7240\n",
      "Epoch 631/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4407 - accuracy: 0.7795 - val_loss: 0.5447 - val_accuracy: 0.7240\n",
      "Epoch 632/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4407 - accuracy: 0.7778 - val_loss: 0.5447 - val_accuracy: 0.7240\n",
      "Epoch 633/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4406 - accuracy: 0.7778 - val_loss: 0.5447 - val_accuracy: 0.7240\n",
      "Epoch 634/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4406 - accuracy: 0.7778 - val_loss: 0.5447 - val_accuracy: 0.7240\n",
      "Epoch 635/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4406 - accuracy: 0.7795 - val_loss: 0.5447 - val_accuracy: 0.7240\n",
      "Epoch 636/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4405 - accuracy: 0.7812 - val_loss: 0.5446 - val_accuracy: 0.7240\n",
      "Epoch 637/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4404 - accuracy: 0.7778 - val_loss: 0.5446 - val_accuracy: 0.7240\n",
      "Epoch 638/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4404 - accuracy: 0.7812 - val_loss: 0.5446 - val_accuracy: 0.7240\n",
      "Epoch 639/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4404 - accuracy: 0.7795 - val_loss: 0.5446 - val_accuracy: 0.7240\n",
      "Epoch 640/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4404 - accuracy: 0.7795 - val_loss: 0.5446 - val_accuracy: 0.7240\n",
      "Epoch 641/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4403 - accuracy: 0.7812 - val_loss: 0.5446 - val_accuracy: 0.7240\n",
      "Epoch 642/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4403 - accuracy: 0.7795 - val_loss: 0.5446 - val_accuracy: 0.7240\n",
      "Epoch 643/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4402 - accuracy: 0.7778 - val_loss: 0.5446 - val_accuracy: 0.7240\n",
      "Epoch 644/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4402 - accuracy: 0.7795 - val_loss: 0.5446 - val_accuracy: 0.7240\n",
      "Epoch 645/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4401 - accuracy: 0.7795 - val_loss: 0.5446 - val_accuracy: 0.7240\n",
      "Epoch 646/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4401 - accuracy: 0.7795 - val_loss: 0.5446 - val_accuracy: 0.7240\n",
      "Epoch 647/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4401 - accuracy: 0.7778 - val_loss: 0.5446 - val_accuracy: 0.7240\n",
      "Epoch 648/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4401 - accuracy: 0.7795 - val_loss: 0.5446 - val_accuracy: 0.7240\n",
      "Epoch 649/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4400 - accuracy: 0.7778 - val_loss: 0.5446 - val_accuracy: 0.7240\n",
      "Epoch 650/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4400 - accuracy: 0.7795 - val_loss: 0.5446 - val_accuracy: 0.7240\n",
      "Epoch 651/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4399 - accuracy: 0.7795 - val_loss: 0.5446 - val_accuracy: 0.7240\n",
      "Epoch 652/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4399 - accuracy: 0.7795 - val_loss: 0.5446 - val_accuracy: 0.7240\n",
      "Epoch 653/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4399 - accuracy: 0.7795 - val_loss: 0.5446 - val_accuracy: 0.7240\n",
      "Epoch 654/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4399 - accuracy: 0.7795 - val_loss: 0.5446 - val_accuracy: 0.7240\n",
      "Epoch 655/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4398 - accuracy: 0.7795 - val_loss: 0.5446 - val_accuracy: 0.7240\n",
      "Epoch 656/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4398 - accuracy: 0.7795 - val_loss: 0.5446 - val_accuracy: 0.7240\n",
      "Epoch 657/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4397 - accuracy: 0.7795 - val_loss: 0.5446 - val_accuracy: 0.7240\n",
      "Epoch 658/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4397 - accuracy: 0.7795 - val_loss: 0.5446 - val_accuracy: 0.7240\n",
      "Epoch 659/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4397 - accuracy: 0.7795 - val_loss: 0.5446 - val_accuracy: 0.7240\n",
      "Epoch 660/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4397 - accuracy: 0.7795 - val_loss: 0.5446 - val_accuracy: 0.7240\n",
      "Epoch 661/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4396 - accuracy: 0.7795 - val_loss: 0.5446 - val_accuracy: 0.7240\n",
      "Epoch 662/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4396 - accuracy: 0.7795 - val_loss: 0.5445 - val_accuracy: 0.7240\n",
      "Epoch 663/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4395 - accuracy: 0.7812 - val_loss: 0.5445 - val_accuracy: 0.7240\n",
      "Epoch 664/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4395 - accuracy: 0.7795 - val_loss: 0.5445 - val_accuracy: 0.7240\n",
      "Epoch 665/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4395 - accuracy: 0.7795 - val_loss: 0.5445 - val_accuracy: 0.7240\n",
      "Epoch 666/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4394 - accuracy: 0.7795 - val_loss: 0.5445 - val_accuracy: 0.7240\n",
      "Epoch 667/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4394 - accuracy: 0.7795 - val_loss: 0.5445 - val_accuracy: 0.7240\n",
      "Epoch 668/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4394 - accuracy: 0.7812 - val_loss: 0.5445 - val_accuracy: 0.7240\n",
      "Epoch 669/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4394 - accuracy: 0.7812 - val_loss: 0.5445 - val_accuracy: 0.7240\n",
      "Epoch 670/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4393 - accuracy: 0.7812 - val_loss: 0.5445 - val_accuracy: 0.7240\n",
      "Epoch 671/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4394 - accuracy: 0.7812 - val_loss: 0.5445 - val_accuracy: 0.7240\n",
      "Epoch 672/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4392 - accuracy: 0.7812 - val_loss: 0.5444 - val_accuracy: 0.7240\n",
      "Epoch 673/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4393 - accuracy: 0.7812 - val_loss: 0.5444 - val_accuracy: 0.7240\n",
      "Epoch 674/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4392 - accuracy: 0.7812 - val_loss: 0.5444 - val_accuracy: 0.7240\n",
      "Epoch 675/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4392 - accuracy: 0.7812 - val_loss: 0.5444 - val_accuracy: 0.7240\n",
      "Epoch 676/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4391 - accuracy: 0.7812 - val_loss: 0.5444 - val_accuracy: 0.7240\n",
      "Epoch 677/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4391 - accuracy: 0.7812 - val_loss: 0.5444 - val_accuracy: 0.7240\n",
      "Epoch 678/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4391 - accuracy: 0.7812 - val_loss: 0.5444 - val_accuracy: 0.7240\n",
      "Epoch 679/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4391 - accuracy: 0.7812 - val_loss: 0.5444 - val_accuracy: 0.7240\n",
      "Epoch 680/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4390 - accuracy: 0.7812 - val_loss: 0.5444 - val_accuracy: 0.7240\n",
      "Epoch 681/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4390 - accuracy: 0.7812 - val_loss: 0.5444 - val_accuracy: 0.7240\n",
      "Epoch 682/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4390 - accuracy: 0.7812 - val_loss: 0.5443 - val_accuracy: 0.7240\n",
      "Epoch 683/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4389 - accuracy: 0.7812 - val_loss: 0.5443 - val_accuracy: 0.7240\n",
      "Epoch 684/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4389 - accuracy: 0.7812 - val_loss: 0.5443 - val_accuracy: 0.7240\n",
      "Epoch 685/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4389 - accuracy: 0.7812 - val_loss: 0.5443 - val_accuracy: 0.7240\n",
      "Epoch 686/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4388 - accuracy: 0.7812 - val_loss: 0.5443 - val_accuracy: 0.7240\n",
      "Epoch 687/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4389 - accuracy: 0.7812 - val_loss: 0.5443 - val_accuracy: 0.7240\n",
      "Epoch 688/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4388 - accuracy: 0.7812 - val_loss: 0.5443 - val_accuracy: 0.7240\n",
      "Epoch 689/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4387 - accuracy: 0.7812 - val_loss: 0.5443 - val_accuracy: 0.7240\n",
      "Epoch 690/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4387 - accuracy: 0.7812 - val_loss: 0.5443 - val_accuracy: 0.7240\n",
      "Epoch 691/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4387 - accuracy: 0.7812 - val_loss: 0.5443 - val_accuracy: 0.7240\n",
      "Epoch 692/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4387 - accuracy: 0.7812 - val_loss: 0.5442 - val_accuracy: 0.7240\n",
      "Epoch 693/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4387 - accuracy: 0.7812 - val_loss: 0.5442 - val_accuracy: 0.7240\n",
      "Epoch 694/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4386 - accuracy: 0.7812 - val_loss: 0.5442 - val_accuracy: 0.7240\n",
      "Epoch 695/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4387 - accuracy: 0.7812 - val_loss: 0.5442 - val_accuracy: 0.7240\n",
      "Epoch 696/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4385 - accuracy: 0.7812 - val_loss: 0.5442 - val_accuracy: 0.7240\n",
      "Epoch 697/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4386 - accuracy: 0.7812 - val_loss: 0.5442 - val_accuracy: 0.7240\n",
      "Epoch 698/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4386 - accuracy: 0.7812 - val_loss: 0.5442 - val_accuracy: 0.7240\n",
      "Epoch 699/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4385 - accuracy: 0.7812 - val_loss: 0.5442 - val_accuracy: 0.7240\n",
      "Epoch 700/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4385 - accuracy: 0.7812 - val_loss: 0.5442 - val_accuracy: 0.7240\n",
      "Epoch 701/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4384 - accuracy: 0.7812 - val_loss: 0.5442 - val_accuracy: 0.7240\n",
      "Epoch 702/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4384 - accuracy: 0.7812 - val_loss: 0.5442 - val_accuracy: 0.7240\n",
      "Epoch 703/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4384 - accuracy: 0.7812 - val_loss: 0.5442 - val_accuracy: 0.7240\n",
      "Epoch 704/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4384 - accuracy: 0.7812 - val_loss: 0.5442 - val_accuracy: 0.7240\n",
      "Epoch 705/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4383 - accuracy: 0.7812 - val_loss: 0.5442 - val_accuracy: 0.7240\n",
      "Epoch 706/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4383 - accuracy: 0.7812 - val_loss: 0.5442 - val_accuracy: 0.7240\n",
      "Epoch 707/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4383 - accuracy: 0.7812 - val_loss: 0.5441 - val_accuracy: 0.7240\n",
      "Epoch 708/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4383 - accuracy: 0.7812 - val_loss: 0.5441 - val_accuracy: 0.7240\n",
      "Epoch 709/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4382 - accuracy: 0.7812 - val_loss: 0.5441 - val_accuracy: 0.7240\n",
      "Epoch 710/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4382 - accuracy: 0.7812 - val_loss: 0.5441 - val_accuracy: 0.7240\n",
      "Epoch 711/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4382 - accuracy: 0.7812 - val_loss: 0.5441 - val_accuracy: 0.7240\n",
      "Epoch 712/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4382 - accuracy: 0.7812 - val_loss: 0.5441 - val_accuracy: 0.7240\n",
      "Epoch 713/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4381 - accuracy: 0.7812 - val_loss: 0.5441 - val_accuracy: 0.7240\n",
      "Epoch 714/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4381 - accuracy: 0.7812 - val_loss: 0.5441 - val_accuracy: 0.7240\n",
      "Epoch 715/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4381 - accuracy: 0.7812 - val_loss: 0.5441 - val_accuracy: 0.7240\n",
      "Epoch 716/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4382 - accuracy: 0.7812 - val_loss: 0.5441 - val_accuracy: 0.7240\n",
      "Epoch 717/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4381 - accuracy: 0.7812 - val_loss: 0.5441 - val_accuracy: 0.7240\n",
      "Epoch 718/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4380 - accuracy: 0.7812 - val_loss: 0.5440 - val_accuracy: 0.7240\n",
      "Epoch 719/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4380 - accuracy: 0.7812 - val_loss: 0.5441 - val_accuracy: 0.7240\n",
      "Epoch 720/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4380 - accuracy: 0.7812 - val_loss: 0.5440 - val_accuracy: 0.7240\n",
      "Epoch 721/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4379 - accuracy: 0.7812 - val_loss: 0.5440 - val_accuracy: 0.7240\n",
      "Epoch 722/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4379 - accuracy: 0.7812 - val_loss: 0.5440 - val_accuracy: 0.7240\n",
      "Epoch 723/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4379 - accuracy: 0.7812 - val_loss: 0.5440 - val_accuracy: 0.7240\n",
      "Epoch 724/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4379 - accuracy: 0.7812 - val_loss: 0.5440 - val_accuracy: 0.7240\n",
      "Epoch 725/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4379 - accuracy: 0.7812 - val_loss: 0.5440 - val_accuracy: 0.7240\n",
      "Epoch 726/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4379 - accuracy: 0.7830 - val_loss: 0.5440 - val_accuracy: 0.7240\n",
      "Epoch 727/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4378 - accuracy: 0.7812 - val_loss: 0.5440 - val_accuracy: 0.7240\n",
      "Epoch 728/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4378 - accuracy: 0.7830 - val_loss: 0.5439 - val_accuracy: 0.7240\n",
      "Epoch 729/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4377 - accuracy: 0.7830 - val_loss: 0.5439 - val_accuracy: 0.7240\n",
      "Epoch 730/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4377 - accuracy: 0.7830 - val_loss: 0.5439 - val_accuracy: 0.7240\n",
      "Epoch 731/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4377 - accuracy: 0.7830 - val_loss: 0.5439 - val_accuracy: 0.7240\n",
      "Epoch 732/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4377 - accuracy: 0.7830 - val_loss: 0.5439 - val_accuracy: 0.7240\n",
      "Epoch 733/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4376 - accuracy: 0.7830 - val_loss: 0.5439 - val_accuracy: 0.7240\n",
      "Epoch 734/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4376 - accuracy: 0.7830 - val_loss: 0.5438 - val_accuracy: 0.7240\n",
      "Epoch 735/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4376 - accuracy: 0.7830 - val_loss: 0.5438 - val_accuracy: 0.7240\n",
      "Epoch 736/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4376 - accuracy: 0.7847 - val_loss: 0.5438 - val_accuracy: 0.7240\n",
      "Epoch 737/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4376 - accuracy: 0.7830 - val_loss: 0.5438 - val_accuracy: 0.7240\n",
      "Epoch 738/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4375 - accuracy: 0.7830 - val_loss: 0.5438 - val_accuracy: 0.7240\n",
      "Epoch 739/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4375 - accuracy: 0.7830 - val_loss: 0.5438 - val_accuracy: 0.7240\n",
      "Epoch 740/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4375 - accuracy: 0.7830 - val_loss: 0.5438 - val_accuracy: 0.7240\n",
      "Epoch 741/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4374 - accuracy: 0.7830 - val_loss: 0.5438 - val_accuracy: 0.7240\n",
      "Epoch 742/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4374 - accuracy: 0.7830 - val_loss: 0.5438 - val_accuracy: 0.7240\n",
      "Epoch 743/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4374 - accuracy: 0.7847 - val_loss: 0.5437 - val_accuracy: 0.7240\n",
      "Epoch 744/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4374 - accuracy: 0.7847 - val_loss: 0.5437 - val_accuracy: 0.7240\n",
      "Epoch 745/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4373 - accuracy: 0.7830 - val_loss: 0.5437 - val_accuracy: 0.7240\n",
      "Epoch 746/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4373 - accuracy: 0.7830 - val_loss: 0.5437 - val_accuracy: 0.7240\n",
      "Epoch 747/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4373 - accuracy: 0.7847 - val_loss: 0.5437 - val_accuracy: 0.7240\n",
      "Epoch 748/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4372 - accuracy: 0.7830 - val_loss: 0.5437 - val_accuracy: 0.7240\n",
      "Epoch 749/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4372 - accuracy: 0.7847 - val_loss: 0.5437 - val_accuracy: 0.7240\n",
      "Epoch 750/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4372 - accuracy: 0.7847 - val_loss: 0.5436 - val_accuracy: 0.7240\n",
      "Epoch 751/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4372 - accuracy: 0.7847 - val_loss: 0.5436 - val_accuracy: 0.7240\n",
      "Epoch 752/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.7847 - val_loss: 0.5436 - val_accuracy: 0.7240\n",
      "Epoch 753/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4372 - accuracy: 0.7847 - val_loss: 0.5436 - val_accuracy: 0.7240\n",
      "Epoch 754/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.7847 - val_loss: 0.5436 - val_accuracy: 0.7240\n",
      "Epoch 755/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.7830 - val_loss: 0.5436 - val_accuracy: 0.7240\n",
      "Epoch 756/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.7847 - val_loss: 0.5436 - val_accuracy: 0.7240\n",
      "Epoch 757/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.7847 - val_loss: 0.5436 - val_accuracy: 0.7240\n",
      "Epoch 758/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.7847 - val_loss: 0.5436 - val_accuracy: 0.7240\n",
      "Epoch 759/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4370 - accuracy: 0.7830 - val_loss: 0.5436 - val_accuracy: 0.7240\n",
      "Epoch 760/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4370 - accuracy: 0.7847 - val_loss: 0.5436 - val_accuracy: 0.7240\n",
      "Epoch 761/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4370 - accuracy: 0.7847 - val_loss: 0.5436 - val_accuracy: 0.7240\n",
      "Epoch 762/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4369 - accuracy: 0.7847 - val_loss: 0.5436 - val_accuracy: 0.7240\n",
      "Epoch 763/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4369 - accuracy: 0.7847 - val_loss: 0.5436 - val_accuracy: 0.7240\n",
      "Epoch 764/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4369 - accuracy: 0.7847 - val_loss: 0.5435 - val_accuracy: 0.7240\n",
      "Epoch 765/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4369 - accuracy: 0.7847 - val_loss: 0.5435 - val_accuracy: 0.7240\n",
      "Epoch 766/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4368 - accuracy: 0.7847 - val_loss: 0.5435 - val_accuracy: 0.7240\n",
      "Epoch 767/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4369 - accuracy: 0.7847 - val_loss: 0.5435 - val_accuracy: 0.7240\n",
      "Epoch 768/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4368 - accuracy: 0.7847 - val_loss: 0.5435 - val_accuracy: 0.7240\n",
      "Epoch 769/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4368 - accuracy: 0.7830 - val_loss: 0.5435 - val_accuracy: 0.7240\n",
      "Epoch 770/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4368 - accuracy: 0.7847 - val_loss: 0.5435 - val_accuracy: 0.7240\n",
      "Epoch 771/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4367 - accuracy: 0.7847 - val_loss: 0.5435 - val_accuracy: 0.7240\n",
      "Epoch 772/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4368 - accuracy: 0.7847 - val_loss: 0.5435 - val_accuracy: 0.7240\n",
      "Epoch 773/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4367 - accuracy: 0.7847 - val_loss: 0.5435 - val_accuracy: 0.7240\n",
      "Epoch 774/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4367 - accuracy: 0.7847 - val_loss: 0.5434 - val_accuracy: 0.7240\n",
      "Epoch 775/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4367 - accuracy: 0.7847 - val_loss: 0.5434 - val_accuracy: 0.7292\n",
      "Epoch 776/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4366 - accuracy: 0.7847 - val_loss: 0.5434 - val_accuracy: 0.7240\n",
      "Epoch 777/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4366 - accuracy: 0.7847 - val_loss: 0.5434 - val_accuracy: 0.7240\n",
      "Epoch 778/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4366 - accuracy: 0.7847 - val_loss: 0.5434 - val_accuracy: 0.7292\n",
      "Epoch 779/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4366 - accuracy: 0.7847 - val_loss: 0.5434 - val_accuracy: 0.7240\n",
      "Epoch 780/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4366 - accuracy: 0.7847 - val_loss: 0.5434 - val_accuracy: 0.7240\n",
      "Epoch 781/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4365 - accuracy: 0.7847 - val_loss: 0.5434 - val_accuracy: 0.7240\n",
      "Epoch 782/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4366 - accuracy: 0.7847 - val_loss: 0.5434 - val_accuracy: 0.7240\n",
      "Epoch 783/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4365 - accuracy: 0.7847 - val_loss: 0.5434 - val_accuracy: 0.7240\n",
      "Epoch 784/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4365 - accuracy: 0.7847 - val_loss: 0.5434 - val_accuracy: 0.7240\n",
      "Epoch 785/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4365 - accuracy: 0.7847 - val_loss: 0.5434 - val_accuracy: 0.7240\n",
      "Epoch 786/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4364 - accuracy: 0.7847 - val_loss: 0.5433 - val_accuracy: 0.7292\n",
      "Epoch 787/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4365 - accuracy: 0.7847 - val_loss: 0.5433 - val_accuracy: 0.7292\n",
      "Epoch 788/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4364 - accuracy: 0.7847 - val_loss: 0.5433 - val_accuracy: 0.7292\n",
      "Epoch 789/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4364 - accuracy: 0.7847 - val_loss: 0.5433 - val_accuracy: 0.7292\n",
      "Epoch 790/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4363 - accuracy: 0.7847 - val_loss: 0.5433 - val_accuracy: 0.7292\n",
      "Epoch 791/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4363 - accuracy: 0.7847 - val_loss: 0.5433 - val_accuracy: 0.7292\n",
      "Epoch 792/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4363 - accuracy: 0.7847 - val_loss: 0.5433 - val_accuracy: 0.7292\n",
      "Epoch 793/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4363 - accuracy: 0.7847 - val_loss: 0.5432 - val_accuracy: 0.7292\n",
      "Epoch 794/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4363 - accuracy: 0.7847 - val_loss: 0.5432 - val_accuracy: 0.7292\n",
      "Epoch 795/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4362 - accuracy: 0.7847 - val_loss: 0.5432 - val_accuracy: 0.7292\n",
      "Epoch 796/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4362 - accuracy: 0.7847 - val_loss: 0.5432 - val_accuracy: 0.7292\n",
      "Epoch 797/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4362 - accuracy: 0.7847 - val_loss: 0.5432 - val_accuracy: 0.7292\n",
      "Epoch 798/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4361 - accuracy: 0.7847 - val_loss: 0.5432 - val_accuracy: 0.7292\n",
      "Epoch 799/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4361 - accuracy: 0.7847 - val_loss: 0.5432 - val_accuracy: 0.7292\n",
      "Epoch 800/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4361 - accuracy: 0.7847 - val_loss: 0.5432 - val_accuracy: 0.7292\n",
      "Epoch 801/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4361 - accuracy: 0.7847 - val_loss: 0.5431 - val_accuracy: 0.7292\n",
      "Epoch 802/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4361 - accuracy: 0.7847 - val_loss: 0.5432 - val_accuracy: 0.7292\n",
      "Epoch 803/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4361 - accuracy: 0.7847 - val_loss: 0.5431 - val_accuracy: 0.7292\n",
      "Epoch 804/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4360 - accuracy: 0.7847 - val_loss: 0.5431 - val_accuracy: 0.7292\n",
      "Epoch 805/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4360 - accuracy: 0.7847 - val_loss: 0.5431 - val_accuracy: 0.7292\n",
      "Epoch 806/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4360 - accuracy: 0.7847 - val_loss: 0.5431 - val_accuracy: 0.7292\n",
      "Epoch 807/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4360 - accuracy: 0.7847 - val_loss: 0.5431 - val_accuracy: 0.7292\n",
      "Epoch 808/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4359 - accuracy: 0.7847 - val_loss: 0.5431 - val_accuracy: 0.7292\n",
      "Epoch 809/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4360 - accuracy: 0.7847 - val_loss: 0.5431 - val_accuracy: 0.7292\n",
      "Epoch 810/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4359 - accuracy: 0.7847 - val_loss: 0.5430 - val_accuracy: 0.7292\n",
      "Epoch 811/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4359 - accuracy: 0.7847 - val_loss: 0.5430 - val_accuracy: 0.7292\n",
      "Epoch 812/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4359 - accuracy: 0.7830 - val_loss: 0.5430 - val_accuracy: 0.7292\n",
      "Epoch 813/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4358 - accuracy: 0.7847 - val_loss: 0.5430 - val_accuracy: 0.7292\n",
      "Epoch 814/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4358 - accuracy: 0.7847 - val_loss: 0.5430 - val_accuracy: 0.7292\n",
      "Epoch 815/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4358 - accuracy: 0.7847 - val_loss: 0.5430 - val_accuracy: 0.7292\n",
      "Epoch 816/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4358 - accuracy: 0.7847 - val_loss: 0.5430 - val_accuracy: 0.7292\n",
      "Epoch 817/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4358 - accuracy: 0.7847 - val_loss: 0.5430 - val_accuracy: 0.7292\n",
      "Epoch 818/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4358 - accuracy: 0.7847 - val_loss: 0.5430 - val_accuracy: 0.7292\n",
      "Epoch 819/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4357 - accuracy: 0.7847 - val_loss: 0.5430 - val_accuracy: 0.7292\n",
      "Epoch 820/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4357 - accuracy: 0.7847 - val_loss: 0.5430 - val_accuracy: 0.7292\n",
      "Epoch 821/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4357 - accuracy: 0.7847 - val_loss: 0.5429 - val_accuracy: 0.7292\n",
      "Epoch 822/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4357 - accuracy: 0.7847 - val_loss: 0.5429 - val_accuracy: 0.7292\n",
      "Epoch 823/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4357 - accuracy: 0.7847 - val_loss: 0.5429 - val_accuracy: 0.7292\n",
      "Epoch 824/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4357 - accuracy: 0.7847 - val_loss: 0.5429 - val_accuracy: 0.7292\n",
      "Epoch 825/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4356 - accuracy: 0.7847 - val_loss: 0.5429 - val_accuracy: 0.7292\n",
      "Epoch 826/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4356 - accuracy: 0.7847 - val_loss: 0.5429 - val_accuracy: 0.7292\n",
      "Epoch 827/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4356 - accuracy: 0.7847 - val_loss: 0.5429 - val_accuracy: 0.7292\n",
      "Epoch 828/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4356 - accuracy: 0.7830 - val_loss: 0.5429 - val_accuracy: 0.7292\n",
      "Epoch 829/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4355 - accuracy: 0.7847 - val_loss: 0.5429 - val_accuracy: 0.7292\n",
      "Epoch 830/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4355 - accuracy: 0.7847 - val_loss: 0.5429 - val_accuracy: 0.7292\n",
      "Epoch 831/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4355 - accuracy: 0.7847 - val_loss: 0.5429 - val_accuracy: 0.7292\n",
      "Epoch 832/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4355 - accuracy: 0.7830 - val_loss: 0.5429 - val_accuracy: 0.7292\n",
      "Epoch 833/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4355 - accuracy: 0.7830 - val_loss: 0.5429 - val_accuracy: 0.7292\n",
      "Epoch 834/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4355 - accuracy: 0.7847 - val_loss: 0.5429 - val_accuracy: 0.7292\n",
      "Epoch 835/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4355 - accuracy: 0.7812 - val_loss: 0.5429 - val_accuracy: 0.7292\n",
      "Epoch 836/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4354 - accuracy: 0.7830 - val_loss: 0.5429 - val_accuracy: 0.7292\n",
      "Epoch 837/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4354 - accuracy: 0.7847 - val_loss: 0.5429 - val_accuracy: 0.7292\n",
      "Epoch 838/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4353 - accuracy: 0.7812 - val_loss: 0.5429 - val_accuracy: 0.7292\n",
      "Epoch 839/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4354 - accuracy: 0.7830 - val_loss: 0.5429 - val_accuracy: 0.7292\n",
      "Epoch 840/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4353 - accuracy: 0.7830 - val_loss: 0.5429 - val_accuracy: 0.7292\n",
      "Epoch 841/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4353 - accuracy: 0.7847 - val_loss: 0.5429 - val_accuracy: 0.7292\n",
      "Epoch 842/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4354 - accuracy: 0.7830 - val_loss: 0.5429 - val_accuracy: 0.7292\n",
      "Epoch 843/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4353 - accuracy: 0.7830 - val_loss: 0.5428 - val_accuracy: 0.7292\n",
      "Epoch 844/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4353 - accuracy: 0.7830 - val_loss: 0.5428 - val_accuracy: 0.7292\n",
      "Epoch 845/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4353 - accuracy: 0.7830 - val_loss: 0.5428 - val_accuracy: 0.7292\n",
      "Epoch 846/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4352 - accuracy: 0.7830 - val_loss: 0.5428 - val_accuracy: 0.7292\n",
      "Epoch 847/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4352 - accuracy: 0.7830 - val_loss: 0.5428 - val_accuracy: 0.7292\n",
      "Epoch 848/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4352 - accuracy: 0.7830 - val_loss: 0.5428 - val_accuracy: 0.7292\n",
      "Epoch 849/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4352 - accuracy: 0.7830 - val_loss: 0.5428 - val_accuracy: 0.7292\n",
      "Epoch 850/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4352 - accuracy: 0.7830 - val_loss: 0.5428 - val_accuracy: 0.7292\n",
      "Epoch 851/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4352 - accuracy: 0.7812 - val_loss: 0.5428 - val_accuracy: 0.7292\n",
      "Epoch 852/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4352 - accuracy: 0.7830 - val_loss: 0.5428 - val_accuracy: 0.7292\n",
      "Epoch 853/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4351 - accuracy: 0.7830 - val_loss: 0.5428 - val_accuracy: 0.7292\n",
      "Epoch 854/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4351 - accuracy: 0.7830 - val_loss: 0.5428 - val_accuracy: 0.7292\n",
      "Epoch 855/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4351 - accuracy: 0.7830 - val_loss: 0.5428 - val_accuracy: 0.7292\n",
      "Epoch 856/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4350 - accuracy: 0.7830 - val_loss: 0.5428 - val_accuracy: 0.7292\n",
      "Epoch 857/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4351 - accuracy: 0.7830 - val_loss: 0.5428 - val_accuracy: 0.7292\n",
      "Epoch 858/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4350 - accuracy: 0.7830 - val_loss: 0.5428 - val_accuracy: 0.7292\n",
      "Epoch 859/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4350 - accuracy: 0.7830 - val_loss: 0.5428 - val_accuracy: 0.7292\n",
      "Epoch 860/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4351 - accuracy: 0.7830 - val_loss: 0.5428 - val_accuracy: 0.7292\n",
      "Epoch 861/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4350 - accuracy: 0.7830 - val_loss: 0.5428 - val_accuracy: 0.7292\n",
      "Epoch 862/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4350 - accuracy: 0.7812 - val_loss: 0.5428 - val_accuracy: 0.7292\n",
      "Epoch 863/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4350 - accuracy: 0.7830 - val_loss: 0.5427 - val_accuracy: 0.7292\n",
      "Epoch 864/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4350 - accuracy: 0.7830 - val_loss: 0.5427 - val_accuracy: 0.7292\n",
      "Epoch 865/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4349 - accuracy: 0.7830 - val_loss: 0.5427 - val_accuracy: 0.7292\n",
      "Epoch 866/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4349 - accuracy: 0.7830 - val_loss: 0.5427 - val_accuracy: 0.7292\n",
      "Epoch 867/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4349 - accuracy: 0.7812 - val_loss: 0.5427 - val_accuracy: 0.7292\n",
      "Epoch 868/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4349 - accuracy: 0.7812 - val_loss: 0.5427 - val_accuracy: 0.7292\n",
      "Epoch 869/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4349 - accuracy: 0.7830 - val_loss: 0.5427 - val_accuracy: 0.7292\n",
      "Epoch 870/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4348 - accuracy: 0.7830 - val_loss: 0.5427 - val_accuracy: 0.7292\n",
      "Epoch 871/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4348 - accuracy: 0.7812 - val_loss: 0.5427 - val_accuracy: 0.7292\n",
      "Epoch 872/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4349 - accuracy: 0.7830 - val_loss: 0.5427 - val_accuracy: 0.7292\n",
      "Epoch 873/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4348 - accuracy: 0.7830 - val_loss: 0.5427 - val_accuracy: 0.7292\n",
      "Epoch 874/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4348 - accuracy: 0.7812 - val_loss: 0.5426 - val_accuracy: 0.7292\n",
      "Epoch 875/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4348 - accuracy: 0.7830 - val_loss: 0.5426 - val_accuracy: 0.7292\n",
      "Epoch 876/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4348 - accuracy: 0.7830 - val_loss: 0.5426 - val_accuracy: 0.7292\n",
      "Epoch 877/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4348 - accuracy: 0.7812 - val_loss: 0.5426 - val_accuracy: 0.7292\n",
      "Epoch 878/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4347 - accuracy: 0.7830 - val_loss: 0.5426 - val_accuracy: 0.7292\n",
      "Epoch 879/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4347 - accuracy: 0.7830 - val_loss: 0.5426 - val_accuracy: 0.7292\n",
      "Epoch 880/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4347 - accuracy: 0.7830 - val_loss: 0.5426 - val_accuracy: 0.7292\n",
      "Epoch 881/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4347 - accuracy: 0.7812 - val_loss: 0.5426 - val_accuracy: 0.7292\n",
      "Epoch 882/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4347 - accuracy: 0.7830 - val_loss: 0.5426 - val_accuracy: 0.7292\n",
      "Epoch 883/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4346 - accuracy: 0.7830 - val_loss: 0.5426 - val_accuracy: 0.7292\n",
      "Epoch 884/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4346 - accuracy: 0.7830 - val_loss: 0.5426 - val_accuracy: 0.7292\n",
      "Epoch 885/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4346 - accuracy: 0.7812 - val_loss: 0.5426 - val_accuracy: 0.7292\n",
      "Epoch 886/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4346 - accuracy: 0.7830 - val_loss: 0.5426 - val_accuracy: 0.7292\n",
      "Epoch 887/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4345 - accuracy: 0.7795 - val_loss: 0.5426 - val_accuracy: 0.7292\n",
      "Epoch 888/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4345 - accuracy: 0.7795 - val_loss: 0.5426 - val_accuracy: 0.7292\n",
      "Epoch 889/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4345 - accuracy: 0.7812 - val_loss: 0.5426 - val_accuracy: 0.7292\n",
      "Epoch 890/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4345 - accuracy: 0.7830 - val_loss: 0.5426 - val_accuracy: 0.7292\n",
      "Epoch 891/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4345 - accuracy: 0.7812 - val_loss: 0.5425 - val_accuracy: 0.7292\n",
      "Epoch 892/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4345 - accuracy: 0.7812 - val_loss: 0.5425 - val_accuracy: 0.7292\n",
      "Epoch 893/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4345 - accuracy: 0.7812 - val_loss: 0.5426 - val_accuracy: 0.7292\n",
      "Epoch 894/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4344 - accuracy: 0.7812 - val_loss: 0.5425 - val_accuracy: 0.7292\n",
      "Epoch 895/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4344 - accuracy: 0.7795 - val_loss: 0.5425 - val_accuracy: 0.7292\n",
      "Epoch 896/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4344 - accuracy: 0.7778 - val_loss: 0.5425 - val_accuracy: 0.7240\n",
      "Epoch 897/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4344 - accuracy: 0.7795 - val_loss: 0.5425 - val_accuracy: 0.7188\n",
      "Epoch 898/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4344 - accuracy: 0.7812 - val_loss: 0.5425 - val_accuracy: 0.7188\n",
      "Epoch 899/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4343 - accuracy: 0.7795 - val_loss: 0.5425 - val_accuracy: 0.7188\n",
      "Epoch 900/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4343 - accuracy: 0.7778 - val_loss: 0.5425 - val_accuracy: 0.7188\n",
      "Epoch 901/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4343 - accuracy: 0.7778 - val_loss: 0.5425 - val_accuracy: 0.7188\n",
      "Epoch 902/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4343 - accuracy: 0.7830 - val_loss: 0.5425 - val_accuracy: 0.7188\n",
      "Epoch 903/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4343 - accuracy: 0.7795 - val_loss: 0.5425 - val_accuracy: 0.7188\n",
      "Epoch 904/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4342 - accuracy: 0.7795 - val_loss: 0.5425 - val_accuracy: 0.7188\n",
      "Epoch 905/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4342 - accuracy: 0.7795 - val_loss: 0.5425 - val_accuracy: 0.7188\n",
      "Epoch 906/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4342 - accuracy: 0.7778 - val_loss: 0.5425 - val_accuracy: 0.7188\n",
      "Epoch 907/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4342 - accuracy: 0.7795 - val_loss: 0.5425 - val_accuracy: 0.7188\n",
      "Epoch 908/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4341 - accuracy: 0.7795 - val_loss: 0.5424 - val_accuracy: 0.7188\n",
      "Epoch 909/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4341 - accuracy: 0.7795 - val_loss: 0.5424 - val_accuracy: 0.7188\n",
      "Epoch 910/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4341 - accuracy: 0.7795 - val_loss: 0.5424 - val_accuracy: 0.7188\n",
      "Epoch 911/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4341 - accuracy: 0.7795 - val_loss: 0.5424 - val_accuracy: 0.7188\n",
      "Epoch 912/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4341 - accuracy: 0.7795 - val_loss: 0.5424 - val_accuracy: 0.7188\n",
      "Epoch 913/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4341 - accuracy: 0.7795 - val_loss: 0.5424 - val_accuracy: 0.7188\n",
      "Epoch 914/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4341 - accuracy: 0.7795 - val_loss: 0.5423 - val_accuracy: 0.7188\n",
      "Epoch 915/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4340 - accuracy: 0.7795 - val_loss: 0.5423 - val_accuracy: 0.7188\n",
      "Epoch 916/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4340 - accuracy: 0.7795 - val_loss: 0.5423 - val_accuracy: 0.7188\n",
      "Epoch 917/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4340 - accuracy: 0.7795 - val_loss: 0.5423 - val_accuracy: 0.7188\n",
      "Epoch 918/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4340 - accuracy: 0.7795 - val_loss: 0.5423 - val_accuracy: 0.7188\n",
      "Epoch 919/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4339 - accuracy: 0.7795 - val_loss: 0.5423 - val_accuracy: 0.7188\n",
      "Epoch 920/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4339 - accuracy: 0.7778 - val_loss: 0.5423 - val_accuracy: 0.7188\n",
      "Epoch 921/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4339 - accuracy: 0.7795 - val_loss: 0.5423 - val_accuracy: 0.7188\n",
      "Epoch 922/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4339 - accuracy: 0.7812 - val_loss: 0.5423 - val_accuracy: 0.7188\n",
      "Epoch 923/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4339 - accuracy: 0.7795 - val_loss: 0.5422 - val_accuracy: 0.7188\n",
      "Epoch 924/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4339 - accuracy: 0.7795 - val_loss: 0.5422 - val_accuracy: 0.7188\n",
      "Epoch 925/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4338 - accuracy: 0.7795 - val_loss: 0.5422 - val_accuracy: 0.7188\n",
      "Epoch 926/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4339 - accuracy: 0.7795 - val_loss: 0.5422 - val_accuracy: 0.7188\n",
      "Epoch 927/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4338 - accuracy: 0.7795 - val_loss: 0.5422 - val_accuracy: 0.7188\n",
      "Epoch 928/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4337 - accuracy: 0.7795 - val_loss: 0.5422 - val_accuracy: 0.7188\n",
      "Epoch 929/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4338 - accuracy: 0.7795 - val_loss: 0.5422 - val_accuracy: 0.7188\n",
      "Epoch 930/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4337 - accuracy: 0.7795 - val_loss: 0.5422 - val_accuracy: 0.7188\n",
      "Epoch 931/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4337 - accuracy: 0.7812 - val_loss: 0.5422 - val_accuracy: 0.7188\n",
      "Epoch 932/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4337 - accuracy: 0.7795 - val_loss: 0.5422 - val_accuracy: 0.7188\n",
      "Epoch 933/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4337 - accuracy: 0.7795 - val_loss: 0.5421 - val_accuracy: 0.7188\n",
      "Epoch 934/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4337 - accuracy: 0.7795 - val_loss: 0.5421 - val_accuracy: 0.7188\n",
      "Epoch 935/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4336 - accuracy: 0.7795 - val_loss: 0.5421 - val_accuracy: 0.7188\n",
      "Epoch 936/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4336 - accuracy: 0.7795 - val_loss: 0.5421 - val_accuracy: 0.7188\n",
      "Epoch 937/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4336 - accuracy: 0.7795 - val_loss: 0.5421 - val_accuracy: 0.7240\n",
      "Epoch 938/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4336 - accuracy: 0.7795 - val_loss: 0.5421 - val_accuracy: 0.7240\n",
      "Epoch 939/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4335 - accuracy: 0.7795 - val_loss: 0.5421 - val_accuracy: 0.7240\n",
      "Epoch 940/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4336 - accuracy: 0.7795 - val_loss: 0.5421 - val_accuracy: 0.7240\n",
      "Epoch 941/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4335 - accuracy: 0.7795 - val_loss: 0.5421 - val_accuracy: 0.7240\n",
      "Epoch 942/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4335 - accuracy: 0.7795 - val_loss: 0.5420 - val_accuracy: 0.7240\n",
      "Epoch 943/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4335 - accuracy: 0.7795 - val_loss: 0.5420 - val_accuracy: 0.7240\n",
      "Epoch 944/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4335 - accuracy: 0.7812 - val_loss: 0.5420 - val_accuracy: 0.7240\n",
      "Epoch 945/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4334 - accuracy: 0.7795 - val_loss: 0.5420 - val_accuracy: 0.7240\n",
      "Epoch 946/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4335 - accuracy: 0.7812 - val_loss: 0.5420 - val_accuracy: 0.7240\n",
      "Epoch 947/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4334 - accuracy: 0.7795 - val_loss: 0.5420 - val_accuracy: 0.7240\n",
      "Epoch 948/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4334 - accuracy: 0.7812 - val_loss: 0.5420 - val_accuracy: 0.7240\n",
      "Epoch 949/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4334 - accuracy: 0.7812 - val_loss: 0.5419 - val_accuracy: 0.7240\n",
      "Epoch 950/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4334 - accuracy: 0.7812 - val_loss: 0.5419 - val_accuracy: 0.7240\n",
      "Epoch 951/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4333 - accuracy: 0.7812 - val_loss: 0.5419 - val_accuracy: 0.7240\n",
      "Epoch 952/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4333 - accuracy: 0.7812 - val_loss: 0.5419 - val_accuracy: 0.7240\n",
      "Epoch 953/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4333 - accuracy: 0.7812 - val_loss: 0.5419 - val_accuracy: 0.7240\n",
      "Epoch 954/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4333 - accuracy: 0.7812 - val_loss: 0.5419 - val_accuracy: 0.7240\n",
      "Epoch 955/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4333 - accuracy: 0.7812 - val_loss: 0.5419 - val_accuracy: 0.7240\n",
      "Epoch 956/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4332 - accuracy: 0.7812 - val_loss: 0.5419 - val_accuracy: 0.7240\n",
      "Epoch 957/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4332 - accuracy: 0.7812 - val_loss: 0.5419 - val_accuracy: 0.7240\n",
      "Epoch 958/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4332 - accuracy: 0.7812 - val_loss: 0.5419 - val_accuracy: 0.7240\n",
      "Epoch 959/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4332 - accuracy: 0.7812 - val_loss: 0.5419 - val_accuracy: 0.7240\n",
      "Epoch 960/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4332 - accuracy: 0.7812 - val_loss: 0.5419 - val_accuracy: 0.7240\n",
      "Epoch 961/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4331 - accuracy: 0.7812 - val_loss: 0.5418 - val_accuracy: 0.7240\n",
      "Epoch 962/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4331 - accuracy: 0.7812 - val_loss: 0.5418 - val_accuracy: 0.7240\n",
      "Epoch 963/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4331 - accuracy: 0.7812 - val_loss: 0.5418 - val_accuracy: 0.7240\n",
      "Epoch 964/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4331 - accuracy: 0.7812 - val_loss: 0.5418 - val_accuracy: 0.7240\n",
      "Epoch 965/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4331 - accuracy: 0.7812 - val_loss: 0.5418 - val_accuracy: 0.7240\n",
      "Epoch 966/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4330 - accuracy: 0.7812 - val_loss: 0.5418 - val_accuracy: 0.7240\n",
      "Epoch 967/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4330 - accuracy: 0.7830 - val_loss: 0.5418 - val_accuracy: 0.7240\n",
      "Epoch 968/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4330 - accuracy: 0.7812 - val_loss: 0.5418 - val_accuracy: 0.7240\n",
      "Epoch 969/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4330 - accuracy: 0.7812 - val_loss: 0.5417 - val_accuracy: 0.7240\n",
      "Epoch 970/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4330 - accuracy: 0.7812 - val_loss: 0.5417 - val_accuracy: 0.7240\n",
      "Epoch 971/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4329 - accuracy: 0.7812 - val_loss: 0.5417 - val_accuracy: 0.7240\n",
      "Epoch 972/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4330 - accuracy: 0.7812 - val_loss: 0.5417 - val_accuracy: 0.7240\n",
      "Epoch 973/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4329 - accuracy: 0.7812 - val_loss: 0.5417 - val_accuracy: 0.7240\n",
      "Epoch 974/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4329 - accuracy: 0.7812 - val_loss: 0.5417 - val_accuracy: 0.7240\n",
      "Epoch 975/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4328 - accuracy: 0.7812 - val_loss: 0.5417 - val_accuracy: 0.7240\n",
      "Epoch 976/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4329 - accuracy: 0.7812 - val_loss: 0.5417 - val_accuracy: 0.7240\n",
      "Epoch 977/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4328 - accuracy: 0.7812 - val_loss: 0.5417 - val_accuracy: 0.7240\n",
      "Epoch 978/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4328 - accuracy: 0.7812 - val_loss: 0.5417 - val_accuracy: 0.7240\n",
      "Epoch 979/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4328 - accuracy: 0.7830 - val_loss: 0.5417 - val_accuracy: 0.7240\n",
      "Epoch 980/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4328 - accuracy: 0.7830 - val_loss: 0.5417 - val_accuracy: 0.7240\n",
      "Epoch 981/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4328 - accuracy: 0.7795 - val_loss: 0.5417 - val_accuracy: 0.7240\n",
      "Epoch 982/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.7830 - val_loss: 0.5417 - val_accuracy: 0.7240\n",
      "Epoch 983/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.7795 - val_loss: 0.5416 - val_accuracy: 0.7240\n",
      "Epoch 984/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.7830 - val_loss: 0.5417 - val_accuracy: 0.7240\n",
      "Epoch 985/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.7812 - val_loss: 0.5416 - val_accuracy: 0.7240\n",
      "Epoch 986/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.7847 - val_loss: 0.5417 - val_accuracy: 0.7240\n",
      "Epoch 987/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.7812 - val_loss: 0.5417 - val_accuracy: 0.7240\n",
      "Epoch 988/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4326 - accuracy: 0.7812 - val_loss: 0.5417 - val_accuracy: 0.7240\n",
      "Epoch 989/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4326 - accuracy: 0.7795 - val_loss: 0.5416 - val_accuracy: 0.7240\n",
      "Epoch 990/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4326 - accuracy: 0.7795 - val_loss: 0.5416 - val_accuracy: 0.7240\n",
      "Epoch 991/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4325 - accuracy: 0.7795 - val_loss: 0.5416 - val_accuracy: 0.7240\n",
      "Epoch 992/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4325 - accuracy: 0.7795 - val_loss: 0.5416 - val_accuracy: 0.7240\n",
      "Epoch 993/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4325 - accuracy: 0.7795 - val_loss: 0.5416 - val_accuracy: 0.7240\n",
      "Epoch 994/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4325 - accuracy: 0.7812 - val_loss: 0.5416 - val_accuracy: 0.7240\n",
      "Epoch 995/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4325 - accuracy: 0.7795 - val_loss: 0.5416 - val_accuracy: 0.7240\n",
      "Epoch 996/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4325 - accuracy: 0.7795 - val_loss: 0.5416 - val_accuracy: 0.7240\n",
      "Epoch 997/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4324 - accuracy: 0.7812 - val_loss: 0.5416 - val_accuracy: 0.7240\n",
      "Epoch 998/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4324 - accuracy: 0.7795 - val_loss: 0.5416 - val_accuracy: 0.7240\n",
      "Epoch 999/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4324 - accuracy: 0.7795 - val_loss: 0.5416 - val_accuracy: 0.7240\n",
      "Epoch 1000/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4324 - accuracy: 0.7795 - val_loss: 0.5415 - val_accuracy: 0.7240\n",
      "Epoch 1001/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4324 - accuracy: 0.7812 - val_loss: 0.5415 - val_accuracy: 0.7240\n",
      "Epoch 1002/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4323 - accuracy: 0.7795 - val_loss: 0.5415 - val_accuracy: 0.7240\n",
      "Epoch 1003/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4323 - accuracy: 0.7795 - val_loss: 0.5415 - val_accuracy: 0.7240\n",
      "Epoch 1004/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4323 - accuracy: 0.7795 - val_loss: 0.5415 - val_accuracy: 0.7240\n",
      "Epoch 1005/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4323 - accuracy: 0.7795 - val_loss: 0.5415 - val_accuracy: 0.7240\n",
      "Epoch 1006/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4323 - accuracy: 0.7795 - val_loss: 0.5415 - val_accuracy: 0.7240\n",
      "Epoch 1007/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4322 - accuracy: 0.7795 - val_loss: 0.5414 - val_accuracy: 0.7240\n",
      "Epoch 1008/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4323 - accuracy: 0.7812 - val_loss: 0.5414 - val_accuracy: 0.7240\n",
      "Epoch 1009/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4322 - accuracy: 0.7795 - val_loss: 0.5414 - val_accuracy: 0.7240\n",
      "Epoch 1010/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4322 - accuracy: 0.7812 - val_loss: 0.5414 - val_accuracy: 0.7240\n",
      "Epoch 1011/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4321 - accuracy: 0.7812 - val_loss: 0.5414 - val_accuracy: 0.7240\n",
      "Epoch 1012/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4322 - accuracy: 0.7795 - val_loss: 0.5414 - val_accuracy: 0.7240\n",
      "Epoch 1013/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4321 - accuracy: 0.7812 - val_loss: 0.5414 - val_accuracy: 0.7240\n",
      "Epoch 1014/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4321 - accuracy: 0.7812 - val_loss: 0.5414 - val_accuracy: 0.7240\n",
      "Epoch 1015/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4321 - accuracy: 0.7812 - val_loss: 0.5414 - val_accuracy: 0.7240\n",
      "Epoch 1016/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4321 - accuracy: 0.7812 - val_loss: 0.5414 - val_accuracy: 0.7240\n",
      "Epoch 1017/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4320 - accuracy: 0.7812 - val_loss: 0.5413 - val_accuracy: 0.7240\n",
      "Epoch 1018/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4320 - accuracy: 0.7812 - val_loss: 0.5413 - val_accuracy: 0.7240\n",
      "Epoch 1019/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4320 - accuracy: 0.7812 - val_loss: 0.5413 - val_accuracy: 0.7240\n",
      "Epoch 1020/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4320 - accuracy: 0.7812 - val_loss: 0.5413 - val_accuracy: 0.7240\n",
      "Epoch 1021/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4320 - accuracy: 0.7812 - val_loss: 0.5413 - val_accuracy: 0.7240\n",
      "Epoch 1022/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4319 - accuracy: 0.7812 - val_loss: 0.5413 - val_accuracy: 0.7292\n",
      "Epoch 1023/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4319 - accuracy: 0.7812 - val_loss: 0.5413 - val_accuracy: 0.7292\n",
      "Epoch 1024/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4319 - accuracy: 0.7812 - val_loss: 0.5413 - val_accuracy: 0.7292\n",
      "Epoch 1025/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4319 - accuracy: 0.7812 - val_loss: 0.5413 - val_accuracy: 0.7344\n",
      "Epoch 1026/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4318 - accuracy: 0.7795 - val_loss: 0.5413 - val_accuracy: 0.7344\n",
      "Epoch 1027/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4319 - accuracy: 0.7795 - val_loss: 0.5412 - val_accuracy: 0.7344\n",
      "Epoch 1028/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4318 - accuracy: 0.7812 - val_loss: 0.5412 - val_accuracy: 0.7344\n",
      "Epoch 1029/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4318 - accuracy: 0.7812 - val_loss: 0.5412 - val_accuracy: 0.7344\n",
      "Epoch 1030/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4318 - accuracy: 0.7812 - val_loss: 0.5412 - val_accuracy: 0.7344\n",
      "Epoch 1031/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4318 - accuracy: 0.7812 - val_loss: 0.5412 - val_accuracy: 0.7344\n",
      "Epoch 1032/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4317 - accuracy: 0.7812 - val_loss: 0.5412 - val_accuracy: 0.7344\n",
      "Epoch 1033/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4317 - accuracy: 0.7812 - val_loss: 0.5412 - val_accuracy: 0.7344\n",
      "Epoch 1034/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4317 - accuracy: 0.7812 - val_loss: 0.5412 - val_accuracy: 0.7344\n",
      "Epoch 1035/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4317 - accuracy: 0.7812 - val_loss: 0.5412 - val_accuracy: 0.7344\n",
      "Epoch 1036/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4317 - accuracy: 0.7812 - val_loss: 0.5412 - val_accuracy: 0.7344\n",
      "Epoch 1037/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4316 - accuracy: 0.7795 - val_loss: 0.5412 - val_accuracy: 0.7344\n",
      "Epoch 1038/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4317 - accuracy: 0.7795 - val_loss: 0.5412 - val_accuracy: 0.7344\n",
      "Epoch 1039/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4316 - accuracy: 0.7812 - val_loss: 0.5412 - val_accuracy: 0.7344\n",
      "Epoch 1040/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4316 - accuracy: 0.7812 - val_loss: 0.5412 - val_accuracy: 0.7344\n",
      "Epoch 1041/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4316 - accuracy: 0.7812 - val_loss: 0.5412 - val_accuracy: 0.7344\n",
      "Epoch 1042/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4315 - accuracy: 0.7795 - val_loss: 0.5411 - val_accuracy: 0.7344\n",
      "Epoch 1043/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4315 - accuracy: 0.7812 - val_loss: 0.5411 - val_accuracy: 0.7344\n",
      "Epoch 1044/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4315 - accuracy: 0.7812 - val_loss: 0.5411 - val_accuracy: 0.7344\n",
      "Epoch 1045/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4315 - accuracy: 0.7812 - val_loss: 0.5411 - val_accuracy: 0.7344\n",
      "Epoch 1046/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4315 - accuracy: 0.7812 - val_loss: 0.5411 - val_accuracy: 0.7344\n",
      "Epoch 1047/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4315 - accuracy: 0.7795 - val_loss: 0.5411 - val_accuracy: 0.7344\n",
      "Epoch 1048/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4314 - accuracy: 0.7812 - val_loss: 0.5411 - val_accuracy: 0.7344\n",
      "Epoch 1049/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4314 - accuracy: 0.7812 - val_loss: 0.5411 - val_accuracy: 0.7344\n",
      "Epoch 1050/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4314 - accuracy: 0.7812 - val_loss: 0.5411 - val_accuracy: 0.7344\n",
      "Epoch 1051/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4313 - accuracy: 0.7812 - val_loss: 0.5411 - val_accuracy: 0.7344\n",
      "Epoch 1052/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4313 - accuracy: 0.7812 - val_loss: 0.5411 - val_accuracy: 0.7344\n",
      "Epoch 1053/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4313 - accuracy: 0.7812 - val_loss: 0.5411 - val_accuracy: 0.7344\n",
      "Epoch 1054/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4313 - accuracy: 0.7795 - val_loss: 0.5411 - val_accuracy: 0.7344\n",
      "Epoch 1055/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4313 - accuracy: 0.7812 - val_loss: 0.5411 - val_accuracy: 0.7344\n",
      "Epoch 1056/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4312 - accuracy: 0.7812 - val_loss: 0.5411 - val_accuracy: 0.7344\n",
      "Epoch 1057/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4312 - accuracy: 0.7812 - val_loss: 0.5411 - val_accuracy: 0.7344\n",
      "Epoch 1058/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4312 - accuracy: 0.7812 - val_loss: 0.5410 - val_accuracy: 0.7344\n",
      "Epoch 1059/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4312 - accuracy: 0.7812 - val_loss: 0.5410 - val_accuracy: 0.7344\n",
      "Epoch 1060/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4311 - accuracy: 0.7812 - val_loss: 0.5410 - val_accuracy: 0.7344\n",
      "Epoch 1061/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4311 - accuracy: 0.7812 - val_loss: 0.5410 - val_accuracy: 0.7344\n",
      "Epoch 1062/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4311 - accuracy: 0.7812 - val_loss: 0.5410 - val_accuracy: 0.7344\n",
      "Epoch 1063/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4311 - accuracy: 0.7812 - val_loss: 0.5410 - val_accuracy: 0.7344\n",
      "Epoch 1064/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4310 - accuracy: 0.7812 - val_loss: 0.5410 - val_accuracy: 0.7344\n",
      "Epoch 1065/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4310 - accuracy: 0.7812 - val_loss: 0.5410 - val_accuracy: 0.7344\n",
      "Epoch 1066/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4311 - accuracy: 0.7795 - val_loss: 0.5410 - val_accuracy: 0.7344\n",
      "Epoch 1067/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4310 - accuracy: 0.7795 - val_loss: 0.5410 - val_accuracy: 0.7344\n",
      "Epoch 1068/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4310 - accuracy: 0.7812 - val_loss: 0.5410 - val_accuracy: 0.7344\n",
      "Epoch 1069/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4309 - accuracy: 0.7830 - val_loss: 0.5410 - val_accuracy: 0.7344\n",
      "Epoch 1070/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4309 - accuracy: 0.7812 - val_loss: 0.5410 - val_accuracy: 0.7344\n",
      "Epoch 1071/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4310 - accuracy: 0.7812 - val_loss: 0.5410 - val_accuracy: 0.7344\n",
      "Epoch 1072/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4308 - accuracy: 0.7812 - val_loss: 0.5409 - val_accuracy: 0.7344\n",
      "Epoch 1073/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4308 - accuracy: 0.7795 - val_loss: 0.5409 - val_accuracy: 0.7344\n",
      "Epoch 1074/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4308 - accuracy: 0.7795 - val_loss: 0.5409 - val_accuracy: 0.7344\n",
      "Epoch 1075/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4308 - accuracy: 0.7795 - val_loss: 0.5409 - val_accuracy: 0.7344\n",
      "Epoch 1076/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4308 - accuracy: 0.7795 - val_loss: 0.5409 - val_accuracy: 0.7344\n",
      "Epoch 1077/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4308 - accuracy: 0.7812 - val_loss: 0.5409 - val_accuracy: 0.7344\n",
      "Epoch 1078/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4307 - accuracy: 0.7812 - val_loss: 0.5409 - val_accuracy: 0.7344\n",
      "Epoch 1079/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4307 - accuracy: 0.7795 - val_loss: 0.5409 - val_accuracy: 0.7344\n",
      "Epoch 1080/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4307 - accuracy: 0.7812 - val_loss: 0.5409 - val_accuracy: 0.7344\n",
      "Epoch 1081/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4307 - accuracy: 0.7795 - val_loss: 0.5409 - val_accuracy: 0.7344\n",
      "Epoch 1082/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4307 - accuracy: 0.7795 - val_loss: 0.5409 - val_accuracy: 0.7344\n",
      "Epoch 1083/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4306 - accuracy: 0.7795 - val_loss: 0.5409 - val_accuracy: 0.7344\n",
      "Epoch 1084/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4306 - accuracy: 0.7795 - val_loss: 0.5409 - val_accuracy: 0.7344\n",
      "Epoch 1085/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4306 - accuracy: 0.7795 - val_loss: 0.5408 - val_accuracy: 0.7344\n",
      "Epoch 1086/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4306 - accuracy: 0.7795 - val_loss: 0.5409 - val_accuracy: 0.7344\n",
      "Epoch 1087/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4305 - accuracy: 0.7812 - val_loss: 0.5408 - val_accuracy: 0.7344\n",
      "Epoch 1088/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4305 - accuracy: 0.7795 - val_loss: 0.5408 - val_accuracy: 0.7344\n",
      "Epoch 1089/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4305 - accuracy: 0.7795 - val_loss: 0.5408 - val_accuracy: 0.7344\n",
      "Epoch 1090/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4305 - accuracy: 0.7795 - val_loss: 0.5408 - val_accuracy: 0.7344\n",
      "Epoch 1091/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4304 - accuracy: 0.7795 - val_loss: 0.5408 - val_accuracy: 0.7344\n",
      "Epoch 1092/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4304 - accuracy: 0.7812 - val_loss: 0.5408 - val_accuracy: 0.7344\n",
      "Epoch 1093/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4304 - accuracy: 0.7795 - val_loss: 0.5408 - val_accuracy: 0.7344\n",
      "Epoch 1094/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4304 - accuracy: 0.7812 - val_loss: 0.5408 - val_accuracy: 0.7344\n",
      "Epoch 1095/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4304 - accuracy: 0.7795 - val_loss: 0.5408 - val_accuracy: 0.7344\n",
      "Epoch 1096/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4304 - accuracy: 0.7795 - val_loss: 0.5408 - val_accuracy: 0.7344\n",
      "Epoch 1097/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4304 - accuracy: 0.7795 - val_loss: 0.5408 - val_accuracy: 0.7344\n",
      "Epoch 1098/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4304 - accuracy: 0.7795 - val_loss: 0.5407 - val_accuracy: 0.7344\n",
      "Epoch 1099/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4303 - accuracy: 0.7795 - val_loss: 0.5407 - val_accuracy: 0.7344\n",
      "Epoch 1100/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4303 - accuracy: 0.7812 - val_loss: 0.5407 - val_accuracy: 0.7344\n",
      "Epoch 1101/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4303 - accuracy: 0.7795 - val_loss: 0.5407 - val_accuracy: 0.7344\n",
      "Epoch 1102/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4302 - accuracy: 0.7812 - val_loss: 0.5407 - val_accuracy: 0.7344\n",
      "Epoch 1103/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4303 - accuracy: 0.7812 - val_loss: 0.5407 - val_accuracy: 0.7344\n",
      "Epoch 1104/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4302 - accuracy: 0.7795 - val_loss: 0.5407 - val_accuracy: 0.7344\n",
      "Epoch 1105/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4302 - accuracy: 0.7812 - val_loss: 0.5407 - val_accuracy: 0.7344\n",
      "Epoch 1106/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4302 - accuracy: 0.7795 - val_loss: 0.5407 - val_accuracy: 0.7344\n",
      "Epoch 1107/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4301 - accuracy: 0.7795 - val_loss: 0.5407 - val_accuracy: 0.7344\n",
      "Epoch 1108/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4302 - accuracy: 0.7795 - val_loss: 0.5407 - val_accuracy: 0.7344\n",
      "Epoch 1109/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4301 - accuracy: 0.7812 - val_loss: 0.5407 - val_accuracy: 0.7344\n",
      "Epoch 1110/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4301 - accuracy: 0.7795 - val_loss: 0.5406 - val_accuracy: 0.7344\n",
      "Epoch 1111/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4301 - accuracy: 0.7795 - val_loss: 0.5406 - val_accuracy: 0.7344\n",
      "Epoch 1112/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4300 - accuracy: 0.7812 - val_loss: 0.5406 - val_accuracy: 0.7344\n",
      "Epoch 1113/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4301 - accuracy: 0.7795 - val_loss: 0.5406 - val_accuracy: 0.7344\n",
      "Epoch 1114/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4300 - accuracy: 0.7795 - val_loss: 0.5406 - val_accuracy: 0.7344\n",
      "Epoch 1115/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4300 - accuracy: 0.7812 - val_loss: 0.5406 - val_accuracy: 0.7344\n",
      "Epoch 1116/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4300 - accuracy: 0.7812 - val_loss: 0.5406 - val_accuracy: 0.7344\n",
      "Epoch 1117/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4299 - accuracy: 0.7795 - val_loss: 0.5406 - val_accuracy: 0.7344\n",
      "Epoch 1118/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4300 - accuracy: 0.7795 - val_loss: 0.5405 - val_accuracy: 0.7344\n",
      "Epoch 1119/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4300 - accuracy: 0.7795 - val_loss: 0.5405 - val_accuracy: 0.7344\n",
      "Epoch 1120/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4300 - accuracy: 0.7795 - val_loss: 0.5405 - val_accuracy: 0.7344\n",
      "Epoch 1121/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4299 - accuracy: 0.7812 - val_loss: 0.5405 - val_accuracy: 0.7344\n",
      "Epoch 1122/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4299 - accuracy: 0.7812 - val_loss: 0.5405 - val_accuracy: 0.7344\n",
      "Epoch 1123/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4299 - accuracy: 0.7795 - val_loss: 0.5405 - val_accuracy: 0.7344\n",
      "Epoch 1124/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4299 - accuracy: 0.7795 - val_loss: 0.5405 - val_accuracy: 0.7344\n",
      "Epoch 1125/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4299 - accuracy: 0.7795 - val_loss: 0.5405 - val_accuracy: 0.7344\n",
      "Epoch 1126/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.7812 - val_loss: 0.5405 - val_accuracy: 0.7344\n",
      "Epoch 1127/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.7812 - val_loss: 0.5405 - val_accuracy: 0.7344\n",
      "Epoch 1128/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.7812 - val_loss: 0.5405 - val_accuracy: 0.7344\n",
      "Epoch 1129/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.7795 - val_loss: 0.5405 - val_accuracy: 0.7344\n",
      "Epoch 1130/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.7812 - val_loss: 0.5404 - val_accuracy: 0.7344\n",
      "Epoch 1131/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.7795 - val_loss: 0.5404 - val_accuracy: 0.7344\n",
      "Epoch 1132/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.7812 - val_loss: 0.5404 - val_accuracy: 0.7344\n",
      "Epoch 1133/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.7795 - val_loss: 0.5404 - val_accuracy: 0.7344\n",
      "Epoch 1134/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4297 - accuracy: 0.7795 - val_loss: 0.5404 - val_accuracy: 0.7344\n",
      "Epoch 1135/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4297 - accuracy: 0.7812 - val_loss: 0.5404 - val_accuracy: 0.7344\n",
      "Epoch 1136/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4297 - accuracy: 0.7795 - val_loss: 0.5404 - val_accuracy: 0.7344\n",
      "Epoch 1137/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4297 - accuracy: 0.7795 - val_loss: 0.5404 - val_accuracy: 0.7344\n",
      "Epoch 1138/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4296 - accuracy: 0.7812 - val_loss: 0.5404 - val_accuracy: 0.7344\n",
      "Epoch 1139/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4296 - accuracy: 0.7795 - val_loss: 0.5403 - val_accuracy: 0.7344\n",
      "Epoch 1140/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4296 - accuracy: 0.7812 - val_loss: 0.5403 - val_accuracy: 0.7344\n",
      "Epoch 1141/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4297 - accuracy: 0.7812 - val_loss: 0.5403 - val_accuracy: 0.7344\n",
      "Epoch 1142/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4297 - accuracy: 0.7812 - val_loss: 0.5403 - val_accuracy: 0.7344\n",
      "Epoch 1143/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4296 - accuracy: 0.7812 - val_loss: 0.5403 - val_accuracy: 0.7344\n",
      "Epoch 1144/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4296 - accuracy: 0.7795 - val_loss: 0.5403 - val_accuracy: 0.7344\n",
      "Epoch 1145/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4296 - accuracy: 0.7812 - val_loss: 0.5403 - val_accuracy: 0.7344\n",
      "Epoch 1146/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4296 - accuracy: 0.7812 - val_loss: 0.5403 - val_accuracy: 0.7344\n",
      "Epoch 1147/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4296 - accuracy: 0.7812 - val_loss: 0.5403 - val_accuracy: 0.7344\n",
      "Epoch 1148/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4295 - accuracy: 0.7812 - val_loss: 0.5403 - val_accuracy: 0.7344\n",
      "Epoch 1149/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4295 - accuracy: 0.7812 - val_loss: 0.5403 - val_accuracy: 0.7344\n",
      "Epoch 1150/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4295 - accuracy: 0.7795 - val_loss: 0.5403 - val_accuracy: 0.7344\n",
      "Epoch 1151/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4295 - accuracy: 0.7812 - val_loss: 0.5403 - val_accuracy: 0.7344\n",
      "Epoch 1152/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4295 - accuracy: 0.7812 - val_loss: 0.5403 - val_accuracy: 0.7344\n",
      "Epoch 1153/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4294 - accuracy: 0.7812 - val_loss: 0.5402 - val_accuracy: 0.7344\n",
      "Epoch 1154/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4295 - accuracy: 0.7812 - val_loss: 0.5402 - val_accuracy: 0.7344\n",
      "Epoch 1155/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4295 - accuracy: 0.7795 - val_loss: 0.5402 - val_accuracy: 0.7344\n",
      "Epoch 1156/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4294 - accuracy: 0.7812 - val_loss: 0.5402 - val_accuracy: 0.7344\n",
      "Epoch 1157/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4294 - accuracy: 0.7795 - val_loss: 0.5402 - val_accuracy: 0.7344\n",
      "Epoch 1158/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4294 - accuracy: 0.7795 - val_loss: 0.5402 - val_accuracy: 0.7344\n",
      "Epoch 1159/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4294 - accuracy: 0.7812 - val_loss: 0.5402 - val_accuracy: 0.7344\n",
      "Epoch 1160/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4293 - accuracy: 0.7812 - val_loss: 0.5402 - val_accuracy: 0.7344\n",
      "Epoch 1161/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4294 - accuracy: 0.7812 - val_loss: 0.5402 - val_accuracy: 0.7344\n",
      "Epoch 1162/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4294 - accuracy: 0.7812 - val_loss: 0.5402 - val_accuracy: 0.7344\n",
      "Epoch 1163/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4293 - accuracy: 0.7812 - val_loss: 0.5402 - val_accuracy: 0.7344\n",
      "Epoch 1164/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4294 - accuracy: 0.7812 - val_loss: 0.5402 - val_accuracy: 0.7344\n",
      "Epoch 1165/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4293 - accuracy: 0.7812 - val_loss: 0.5402 - val_accuracy: 0.7344\n",
      "Epoch 1166/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4293 - accuracy: 0.7812 - val_loss: 0.5402 - val_accuracy: 0.7344\n",
      "Epoch 1167/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4292 - accuracy: 0.7812 - val_loss: 0.5402 - val_accuracy: 0.7344\n",
      "Epoch 1168/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4293 - accuracy: 0.7812 - val_loss: 0.5402 - val_accuracy: 0.7344\n",
      "Epoch 1169/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4292 - accuracy: 0.7812 - val_loss: 0.5401 - val_accuracy: 0.7344\n",
      "Epoch 1170/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4292 - accuracy: 0.7812 - val_loss: 0.5401 - val_accuracy: 0.7344\n",
      "Epoch 1171/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4292 - accuracy: 0.7812 - val_loss: 0.5401 - val_accuracy: 0.7344\n",
      "Epoch 1172/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4292 - accuracy: 0.7812 - val_loss: 0.5401 - val_accuracy: 0.7344\n",
      "Epoch 1173/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4292 - accuracy: 0.7812 - val_loss: 0.5401 - val_accuracy: 0.7344\n",
      "Epoch 1174/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4292 - accuracy: 0.7812 - val_loss: 0.5401 - val_accuracy: 0.7344\n",
      "Epoch 1175/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4291 - accuracy: 0.7812 - val_loss: 0.5401 - val_accuracy: 0.7344\n",
      "Epoch 1176/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4291 - accuracy: 0.7812 - val_loss: 0.5401 - val_accuracy: 0.7344\n",
      "Epoch 1177/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4291 - accuracy: 0.7812 - val_loss: 0.5401 - val_accuracy: 0.7344\n",
      "Epoch 1178/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4291 - accuracy: 0.7812 - val_loss: 0.5401 - val_accuracy: 0.7344\n",
      "Epoch 1179/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4291 - accuracy: 0.7812 - val_loss: 0.5401 - val_accuracy: 0.7344\n",
      "Epoch 1180/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.7812 - val_loss: 0.5401 - val_accuracy: 0.7344\n",
      "Epoch 1181/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4291 - accuracy: 0.7812 - val_loss: 0.5401 - val_accuracy: 0.7344\n",
      "Epoch 1182/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4291 - accuracy: 0.7812 - val_loss: 0.5401 - val_accuracy: 0.7344\n",
      "Epoch 1183/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.7812 - val_loss: 0.5401 - val_accuracy: 0.7344\n",
      "Epoch 1184/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4291 - accuracy: 0.7812 - val_loss: 0.5401 - val_accuracy: 0.7344\n",
      "Epoch 1185/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.7812 - val_loss: 0.5401 - val_accuracy: 0.7344\n",
      "Epoch 1186/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.7812 - val_loss: 0.5401 - val_accuracy: 0.7344\n",
      "Epoch 1187/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.7812 - val_loss: 0.5402 - val_accuracy: 0.7344\n",
      "Epoch 1188/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.7812 - val_loss: 0.5402 - val_accuracy: 0.7344\n",
      "Epoch 1189/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4289 - accuracy: 0.7812 - val_loss: 0.5402 - val_accuracy: 0.7344\n",
      "Epoch 1190/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.7812 - val_loss: 0.5402 - val_accuracy: 0.7344\n",
      "Epoch 1191/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4289 - accuracy: 0.7812 - val_loss: 0.5402 - val_accuracy: 0.7344\n",
      "Epoch 1192/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4289 - accuracy: 0.7812 - val_loss: 0.5402 - val_accuracy: 0.7344\n",
      "Epoch 1193/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4289 - accuracy: 0.7812 - val_loss: 0.5402 - val_accuracy: 0.7344\n",
      "Epoch 1194/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4289 - accuracy: 0.7812 - val_loss: 0.5402 - val_accuracy: 0.7344\n",
      "Epoch 1195/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4288 - accuracy: 0.7812 - val_loss: 0.5402 - val_accuracy: 0.7344\n",
      "Epoch 1196/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4288 - accuracy: 0.7812 - val_loss: 0.5403 - val_accuracy: 0.7344\n",
      "Epoch 1197/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4288 - accuracy: 0.7812 - val_loss: 0.5403 - val_accuracy: 0.7344\n",
      "Epoch 1198/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4289 - accuracy: 0.7812 - val_loss: 0.5403 - val_accuracy: 0.7344\n",
      "Epoch 1199/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4289 - accuracy: 0.7795 - val_loss: 0.5402 - val_accuracy: 0.7344\n",
      "Epoch 1200/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4288 - accuracy: 0.7812 - val_loss: 0.5402 - val_accuracy: 0.7344\n",
      "Epoch 1201/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4288 - accuracy: 0.7812 - val_loss: 0.5402 - val_accuracy: 0.7344\n",
      "Epoch 1202/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4288 - accuracy: 0.7812 - val_loss: 0.5402 - val_accuracy: 0.7344\n",
      "Epoch 1203/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4287 - accuracy: 0.7812 - val_loss: 0.5402 - val_accuracy: 0.7344\n",
      "Epoch 1204/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4287 - accuracy: 0.7812 - val_loss: 0.5403 - val_accuracy: 0.7344\n",
      "Epoch 1205/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4287 - accuracy: 0.7812 - val_loss: 0.5402 - val_accuracy: 0.7344\n",
      "Epoch 1206/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4287 - accuracy: 0.7812 - val_loss: 0.5403 - val_accuracy: 0.7344\n",
      "Epoch 1207/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4287 - accuracy: 0.7812 - val_loss: 0.5403 - val_accuracy: 0.7344\n",
      "Epoch 1208/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4287 - accuracy: 0.7812 - val_loss: 0.5403 - val_accuracy: 0.7344\n",
      "Epoch 1209/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4287 - accuracy: 0.7812 - val_loss: 0.5403 - val_accuracy: 0.7344\n",
      "Epoch 1210/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4287 - accuracy: 0.7812 - val_loss: 0.5403 - val_accuracy: 0.7344\n",
      "Epoch 1211/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4287 - accuracy: 0.7812 - val_loss: 0.5403 - val_accuracy: 0.7344\n",
      "Epoch 1212/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4287 - accuracy: 0.7795 - val_loss: 0.5402 - val_accuracy: 0.7344\n",
      "Epoch 1213/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4286 - accuracy: 0.7812 - val_loss: 0.5402 - val_accuracy: 0.7344\n",
      "Epoch 1214/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4286 - accuracy: 0.7812 - val_loss: 0.5402 - val_accuracy: 0.7344\n",
      "Epoch 1215/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4287 - accuracy: 0.7812 - val_loss: 0.5402 - val_accuracy: 0.7344\n",
      "Epoch 1216/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4286 - accuracy: 0.7812 - val_loss: 0.5402 - val_accuracy: 0.7344\n",
      "Epoch 1217/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4286 - accuracy: 0.7812 - val_loss: 0.5402 - val_accuracy: 0.7344\n",
      "Epoch 1218/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4285 - accuracy: 0.7812 - val_loss: 0.5402 - val_accuracy: 0.7344\n",
      "Epoch 1219/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4285 - accuracy: 0.7812 - val_loss: 0.5402 - val_accuracy: 0.7344\n",
      "Epoch 1220/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4285 - accuracy: 0.7812 - val_loss: 0.5402 - val_accuracy: 0.7344\n",
      "Epoch 1221/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4285 - accuracy: 0.7812 - val_loss: 0.5402 - val_accuracy: 0.7344\n",
      "Epoch 1222/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4285 - accuracy: 0.7812 - val_loss: 0.5402 - val_accuracy: 0.7344\n",
      "Epoch 1223/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4284 - accuracy: 0.7812 - val_loss: 0.5402 - val_accuracy: 0.7344\n",
      "Epoch 1224/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4285 - accuracy: 0.7812 - val_loss: 0.5402 - val_accuracy: 0.7344\n",
      "Epoch 1225/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4285 - accuracy: 0.7812 - val_loss: 0.5402 - val_accuracy: 0.7344\n",
      "Epoch 1226/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4285 - accuracy: 0.7812 - val_loss: 0.5402 - val_accuracy: 0.7344\n",
      "Epoch 1227/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4284 - accuracy: 0.7812 - val_loss: 0.5402 - val_accuracy: 0.7344\n",
      "Epoch 1228/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4284 - accuracy: 0.7812 - val_loss: 0.5402 - val_accuracy: 0.7344\n",
      "Epoch 1229/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4284 - accuracy: 0.7812 - val_loss: 0.5402 - val_accuracy: 0.7396\n",
      "Epoch 1230/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4284 - accuracy: 0.7812 - val_loss: 0.5402 - val_accuracy: 0.7396\n",
      "Epoch 1231/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4284 - accuracy: 0.7812 - val_loss: 0.5402 - val_accuracy: 0.7396\n",
      "Epoch 1232/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.7812 - val_loss: 0.5402 - val_accuracy: 0.7396\n",
      "Epoch 1233/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4284 - accuracy: 0.7812 - val_loss: 0.5402 - val_accuracy: 0.7396\n",
      "Epoch 1234/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.7812 - val_loss: 0.5402 - val_accuracy: 0.7396\n",
      "Epoch 1235/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.7812 - val_loss: 0.5402 - val_accuracy: 0.7396\n",
      "Epoch 1236/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4282 - accuracy: 0.7812 - val_loss: 0.5402 - val_accuracy: 0.7396\n",
      "Epoch 1237/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.7812 - val_loss: 0.5402 - val_accuracy: 0.7396\n",
      "Epoch 1238/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.7812 - val_loss: 0.5402 - val_accuracy: 0.7396\n",
      "Epoch 1239/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4282 - accuracy: 0.7812 - val_loss: 0.5402 - val_accuracy: 0.7396\n",
      "Epoch 1240/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.7812 - val_loss: 0.5402 - val_accuracy: 0.7396\n",
      "Epoch 1241/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4282 - accuracy: 0.7812 - val_loss: 0.5402 - val_accuracy: 0.7396\n",
      "Epoch 1242/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4282 - accuracy: 0.7812 - val_loss: 0.5402 - val_accuracy: 0.7396\n",
      "Epoch 1243/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4282 - accuracy: 0.7812 - val_loss: 0.5402 - val_accuracy: 0.7396\n",
      "Epoch 1244/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4282 - accuracy: 0.7812 - val_loss: 0.5402 - val_accuracy: 0.7396\n",
      "Epoch 1245/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4282 - accuracy: 0.7812 - val_loss: 0.5402 - val_accuracy: 0.7396\n",
      "Epoch 1246/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4282 - accuracy: 0.7812 - val_loss: 0.5402 - val_accuracy: 0.7396\n",
      "Epoch 1247/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4282 - accuracy: 0.7812 - val_loss: 0.5402 - val_accuracy: 0.7396\n",
      "Epoch 1248/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4281 - accuracy: 0.7812 - val_loss: 0.5402 - val_accuracy: 0.7396\n",
      "Epoch 1249/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4281 - accuracy: 0.7812 - val_loss: 0.5402 - val_accuracy: 0.7396\n",
      "Epoch 1250/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4281 - accuracy: 0.7812 - val_loss: 0.5402 - val_accuracy: 0.7396\n",
      "Epoch 1251/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.7812 - val_loss: 0.5402 - val_accuracy: 0.7396\n",
      "Epoch 1252/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.7812 - val_loss: 0.5402 - val_accuracy: 0.7396\n",
      "Epoch 1253/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.7812 - val_loss: 0.5402 - val_accuracy: 0.7396\n",
      "Epoch 1254/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4281 - accuracy: 0.7812 - val_loss: 0.5402 - val_accuracy: 0.7396\n",
      "Epoch 1255/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.7812 - val_loss: 0.5402 - val_accuracy: 0.7396\n",
      "Epoch 1256/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.7812 - val_loss: 0.5402 - val_accuracy: 0.7396\n",
      "Epoch 1257/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.7812 - val_loss: 0.5402 - val_accuracy: 0.7396\n",
      "Epoch 1258/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.7812 - val_loss: 0.5402 - val_accuracy: 0.7396\n",
      "Epoch 1259/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.7812 - val_loss: 0.5402 - val_accuracy: 0.7396\n",
      "Epoch 1260/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.7812 - val_loss: 0.5402 - val_accuracy: 0.7396\n",
      "Epoch 1261/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.7812 - val_loss: 0.5402 - val_accuracy: 0.7396\n",
      "Epoch 1262/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.7812 - val_loss: 0.5402 - val_accuracy: 0.7396\n",
      "Epoch 1263/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.7812 - val_loss: 0.5402 - val_accuracy: 0.7396\n",
      "Epoch 1264/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.7812 - val_loss: 0.5402 - val_accuracy: 0.7396\n",
      "Epoch 1265/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.7812 - val_loss: 0.5402 - val_accuracy: 0.7396\n",
      "Epoch 1266/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4279 - accuracy: 0.7812 - val_loss: 0.5402 - val_accuracy: 0.7396\n",
      "Epoch 1267/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4278 - accuracy: 0.7812 - val_loss: 0.5402 - val_accuracy: 0.7396\n",
      "Epoch 1268/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.7812 - val_loss: 0.5402 - val_accuracy: 0.7396\n",
      "Epoch 1269/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4279 - accuracy: 0.7812 - val_loss: 0.5402 - val_accuracy: 0.7396\n",
      "Epoch 1270/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.7812 - val_loss: 0.5402 - val_accuracy: 0.7396\n",
      "Epoch 1271/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.7812 - val_loss: 0.5402 - val_accuracy: 0.7396\n",
      "Epoch 1272/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.7812 - val_loss: 0.5401 - val_accuracy: 0.7396\n",
      "Epoch 1273/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.7812 - val_loss: 0.5401 - val_accuracy: 0.7396\n",
      "Epoch 1274/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.7812 - val_loss: 0.5401 - val_accuracy: 0.7396\n",
      "Epoch 1275/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.7812 - val_loss: 0.5401 - val_accuracy: 0.7396\n",
      "Epoch 1276/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4277 - accuracy: 0.7812 - val_loss: 0.5401 - val_accuracy: 0.7396\n",
      "Epoch 1277/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.7812 - val_loss: 0.5401 - val_accuracy: 0.7396\n",
      "Epoch 1278/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4277 - accuracy: 0.7812 - val_loss: 0.5401 - val_accuracy: 0.7396\n",
      "Epoch 1279/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.7812 - val_loss: 0.5401 - val_accuracy: 0.7396\n",
      "Epoch 1280/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.7812 - val_loss: 0.5401 - val_accuracy: 0.7396\n",
      "Epoch 1281/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.7812 - val_loss: 0.5401 - val_accuracy: 0.7396\n",
      "Epoch 1282/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4276 - accuracy: 0.7812 - val_loss: 0.5401 - val_accuracy: 0.7396\n",
      "Epoch 1283/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4276 - accuracy: 0.7812 - val_loss: 0.5401 - val_accuracy: 0.7396\n",
      "Epoch 1284/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.7812 - val_loss: 0.5401 - val_accuracy: 0.7396\n",
      "Epoch 1285/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4276 - accuracy: 0.7812 - val_loss: 0.5401 - val_accuracy: 0.7396\n",
      "Epoch 1286/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4276 - accuracy: 0.7812 - val_loss: 0.5401 - val_accuracy: 0.7396\n",
      "Epoch 1287/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4276 - accuracy: 0.7812 - val_loss: 0.5401 - val_accuracy: 0.7396\n",
      "Epoch 1288/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4276 - accuracy: 0.7812 - val_loss: 0.5401 - val_accuracy: 0.7396\n",
      "Epoch 1289/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4275 - accuracy: 0.7812 - val_loss: 0.5401 - val_accuracy: 0.7396\n",
      "Epoch 1290/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4275 - accuracy: 0.7812 - val_loss: 0.5401 - val_accuracy: 0.7396\n",
      "Epoch 1291/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4275 - accuracy: 0.7812 - val_loss: 0.5400 - val_accuracy: 0.7396\n",
      "Epoch 1292/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4276 - accuracy: 0.7812 - val_loss: 0.5401 - val_accuracy: 0.7396\n",
      "Epoch 1293/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4275 - accuracy: 0.7812 - val_loss: 0.5400 - val_accuracy: 0.7396\n",
      "Epoch 1294/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4275 - accuracy: 0.7812 - val_loss: 0.5400 - val_accuracy: 0.7396\n",
      "Epoch 1295/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4275 - accuracy: 0.7812 - val_loss: 0.5400 - val_accuracy: 0.7396\n",
      "Epoch 1296/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4275 - accuracy: 0.7812 - val_loss: 0.5400 - val_accuracy: 0.7396\n",
      "Epoch 1297/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4274 - accuracy: 0.7812 - val_loss: 0.5400 - val_accuracy: 0.7396\n",
      "Epoch 1298/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4274 - accuracy: 0.7812 - val_loss: 0.5400 - val_accuracy: 0.7396\n",
      "Epoch 1299/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4275 - accuracy: 0.7812 - val_loss: 0.5400 - val_accuracy: 0.7396\n",
      "Epoch 1300/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4274 - accuracy: 0.7812 - val_loss: 0.5400 - val_accuracy: 0.7396\n",
      "Epoch 1301/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4274 - accuracy: 0.7812 - val_loss: 0.5400 - val_accuracy: 0.7396\n",
      "Epoch 1302/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4274 - accuracy: 0.7812 - val_loss: 0.5400 - val_accuracy: 0.7396\n",
      "Epoch 1303/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4273 - accuracy: 0.7812 - val_loss: 0.5400 - val_accuracy: 0.7396\n",
      "Epoch 1304/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4274 - accuracy: 0.7812 - val_loss: 0.5400 - val_accuracy: 0.7396\n",
      "Epoch 1305/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4273 - accuracy: 0.7812 - val_loss: 0.5400 - val_accuracy: 0.7396\n",
      "Epoch 1306/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4273 - accuracy: 0.7812 - val_loss: 0.5399 - val_accuracy: 0.7396\n",
      "Epoch 1307/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4273 - accuracy: 0.7812 - val_loss: 0.5399 - val_accuracy: 0.7396\n",
      "Epoch 1308/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4273 - accuracy: 0.7812 - val_loss: 0.5399 - val_accuracy: 0.7396\n",
      "Epoch 1309/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4273 - accuracy: 0.7812 - val_loss: 0.5399 - val_accuracy: 0.7396\n",
      "Epoch 1310/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4273 - accuracy: 0.7812 - val_loss: 0.5399 - val_accuracy: 0.7396\n",
      "Epoch 1311/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4273 - accuracy: 0.7812 - val_loss: 0.5399 - val_accuracy: 0.7396\n",
      "Epoch 1312/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4272 - accuracy: 0.7812 - val_loss: 0.5399 - val_accuracy: 0.7396\n",
      "Epoch 1313/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4272 - accuracy: 0.7812 - val_loss: 0.5399 - val_accuracy: 0.7396\n",
      "Epoch 1314/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4272 - accuracy: 0.7812 - val_loss: 0.5399 - val_accuracy: 0.7396\n",
      "Epoch 1315/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4271 - accuracy: 0.7812 - val_loss: 0.5399 - val_accuracy: 0.7396\n",
      "Epoch 1316/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4272 - accuracy: 0.7812 - val_loss: 0.5400 - val_accuracy: 0.7396\n",
      "Epoch 1317/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4272 - accuracy: 0.7812 - val_loss: 0.5400 - val_accuracy: 0.7396\n",
      "Epoch 1318/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4272 - accuracy: 0.7812 - val_loss: 0.5400 - val_accuracy: 0.7396\n",
      "Epoch 1319/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4272 - accuracy: 0.7812 - val_loss: 0.5400 - val_accuracy: 0.7396\n",
      "Epoch 1320/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4271 - accuracy: 0.7812 - val_loss: 0.5399 - val_accuracy: 0.7396\n",
      "Epoch 1321/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4271 - accuracy: 0.7812 - val_loss: 0.5399 - val_accuracy: 0.7396\n",
      "Epoch 1322/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4271 - accuracy: 0.7812 - val_loss: 0.5399 - val_accuracy: 0.7396\n",
      "Epoch 1323/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4271 - accuracy: 0.7812 - val_loss: 0.5399 - val_accuracy: 0.7396\n",
      "Epoch 1324/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4271 - accuracy: 0.7812 - val_loss: 0.5399 - val_accuracy: 0.7396\n",
      "Epoch 1325/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4271 - accuracy: 0.7812 - val_loss: 0.5399 - val_accuracy: 0.7396\n",
      "Epoch 1326/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.7812 - val_loss: 0.5399 - val_accuracy: 0.7396\n",
      "Epoch 1327/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4271 - accuracy: 0.7812 - val_loss: 0.5399 - val_accuracy: 0.7396\n",
      "Epoch 1328/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.7812 - val_loss: 0.5399 - val_accuracy: 0.7396\n",
      "Epoch 1329/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.7812 - val_loss: 0.5399 - val_accuracy: 0.7396\n",
      "Epoch 1330/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.7812 - val_loss: 0.5399 - val_accuracy: 0.7396\n",
      "Epoch 1331/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.7812 - val_loss: 0.5399 - val_accuracy: 0.7396\n",
      "Epoch 1332/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4270 - accuracy: 0.7812 - val_loss: 0.5398 - val_accuracy: 0.7396\n",
      "Epoch 1333/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4269 - accuracy: 0.7812 - val_loss: 0.5398 - val_accuracy: 0.7396\n",
      "Epoch 1334/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.7812 - val_loss: 0.5398 - val_accuracy: 0.7396\n",
      "Epoch 1335/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.7812 - val_loss: 0.5398 - val_accuracy: 0.7396\n",
      "Epoch 1336/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4269 - accuracy: 0.7812 - val_loss: 0.5398 - val_accuracy: 0.7396\n",
      "Epoch 1337/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4269 - accuracy: 0.7812 - val_loss: 0.5398 - val_accuracy: 0.7396\n",
      "Epoch 1338/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4269 - accuracy: 0.7812 - val_loss: 0.5398 - val_accuracy: 0.7396\n",
      "Epoch 1339/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4269 - accuracy: 0.7812 - val_loss: 0.5397 - val_accuracy: 0.7396\n",
      "Epoch 1340/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4269 - accuracy: 0.7812 - val_loss: 0.5398 - val_accuracy: 0.7396\n",
      "Epoch 1341/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.7812 - val_loss: 0.5397 - val_accuracy: 0.7396\n",
      "Epoch 1342/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.7812 - val_loss: 0.5397 - val_accuracy: 0.7396\n",
      "Epoch 1343/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4268 - accuracy: 0.7830 - val_loss: 0.5397 - val_accuracy: 0.7396\n",
      "Epoch 1344/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.7812 - val_loss: 0.5397 - val_accuracy: 0.7396\n",
      "Epoch 1345/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4267 - accuracy: 0.7812 - val_loss: 0.5396 - val_accuracy: 0.7396\n",
      "Epoch 1346/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4267 - accuracy: 0.7812 - val_loss: 0.5396 - val_accuracy: 0.7396\n",
      "Epoch 1347/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4267 - accuracy: 0.7812 - val_loss: 0.5396 - val_accuracy: 0.7396\n",
      "Epoch 1348/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4267 - accuracy: 0.7812 - val_loss: 0.5396 - val_accuracy: 0.7396\n",
      "Epoch 1349/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4267 - accuracy: 0.7812 - val_loss: 0.5396 - val_accuracy: 0.7396\n",
      "Epoch 1350/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4266 - accuracy: 0.7812 - val_loss: 0.5396 - val_accuracy: 0.7396\n",
      "Epoch 1351/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.7812 - val_loss: 0.5395 - val_accuracy: 0.7396\n",
      "Epoch 1352/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4266 - accuracy: 0.7812 - val_loss: 0.5395 - val_accuracy: 0.7396\n",
      "Epoch 1353/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4266 - accuracy: 0.7812 - val_loss: 0.5395 - val_accuracy: 0.7396\n",
      "Epoch 1354/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4266 - accuracy: 0.7812 - val_loss: 0.5395 - val_accuracy: 0.7396\n",
      "Epoch 1355/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.7812 - val_loss: 0.5395 - val_accuracy: 0.7396\n",
      "Epoch 1356/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.7812 - val_loss: 0.5395 - val_accuracy: 0.7396\n",
      "Epoch 1357/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.7830 - val_loss: 0.5394 - val_accuracy: 0.7396\n",
      "Epoch 1358/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.7812 - val_loss: 0.5394 - val_accuracy: 0.7396\n",
      "Epoch 1359/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.7812 - val_loss: 0.5394 - val_accuracy: 0.7396\n",
      "Epoch 1360/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.7812 - val_loss: 0.5394 - val_accuracy: 0.7396\n",
      "Epoch 1361/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4264 - accuracy: 0.7812 - val_loss: 0.5394 - val_accuracy: 0.7396\n",
      "Epoch 1362/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4264 - accuracy: 0.7812 - val_loss: 0.5394 - val_accuracy: 0.7396\n",
      "Epoch 1363/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4264 - accuracy: 0.7812 - val_loss: 0.5394 - val_accuracy: 0.7396\n",
      "Epoch 1364/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4264 - accuracy: 0.7795 - val_loss: 0.5393 - val_accuracy: 0.7396\n",
      "Epoch 1365/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4264 - accuracy: 0.7812 - val_loss: 0.5393 - val_accuracy: 0.7396\n",
      "Epoch 1366/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4264 - accuracy: 0.7812 - val_loss: 0.5393 - val_accuracy: 0.7396\n",
      "Epoch 1367/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4263 - accuracy: 0.7830 - val_loss: 0.5393 - val_accuracy: 0.7396\n",
      "Epoch 1368/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4263 - accuracy: 0.7812 - val_loss: 0.5393 - val_accuracy: 0.7396\n",
      "Epoch 1369/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4263 - accuracy: 0.7795 - val_loss: 0.5393 - val_accuracy: 0.7396\n",
      "Epoch 1370/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4263 - accuracy: 0.7812 - val_loss: 0.5393 - val_accuracy: 0.7396\n",
      "Epoch 1371/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4263 - accuracy: 0.7830 - val_loss: 0.5393 - val_accuracy: 0.7396\n",
      "Epoch 1372/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4263 - accuracy: 0.7830 - val_loss: 0.5393 - val_accuracy: 0.7396\n",
      "Epoch 1373/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4262 - accuracy: 0.7830 - val_loss: 0.5393 - val_accuracy: 0.7396\n",
      "Epoch 1374/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4262 - accuracy: 0.7830 - val_loss: 0.5392 - val_accuracy: 0.7396\n",
      "Epoch 1375/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4262 - accuracy: 0.7830 - val_loss: 0.5392 - val_accuracy: 0.7396\n",
      "Epoch 1376/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4261 - accuracy: 0.7830 - val_loss: 0.5392 - val_accuracy: 0.7396\n",
      "Epoch 1377/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4261 - accuracy: 0.7830 - val_loss: 0.5392 - val_accuracy: 0.7396\n",
      "Epoch 1378/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4262 - accuracy: 0.7830 - val_loss: 0.5392 - val_accuracy: 0.7396\n",
      "Epoch 1379/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4261 - accuracy: 0.7830 - val_loss: 0.5392 - val_accuracy: 0.7396\n",
      "Epoch 1380/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4261 - accuracy: 0.7830 - val_loss: 0.5392 - val_accuracy: 0.7396\n",
      "Epoch 1381/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4261 - accuracy: 0.7830 - val_loss: 0.5392 - val_accuracy: 0.7396\n",
      "Epoch 1382/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4261 - accuracy: 0.7830 - val_loss: 0.5391 - val_accuracy: 0.7396\n",
      "Epoch 1383/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4260 - accuracy: 0.7830 - val_loss: 0.5391 - val_accuracy: 0.7396\n",
      "Epoch 1384/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4260 - accuracy: 0.7830 - val_loss: 0.5391 - val_accuracy: 0.7396\n",
      "Epoch 1385/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4260 - accuracy: 0.7830 - val_loss: 0.5391 - val_accuracy: 0.7396\n",
      "Epoch 1386/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4260 - accuracy: 0.7847 - val_loss: 0.5391 - val_accuracy: 0.7396\n",
      "Epoch 1387/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4260 - accuracy: 0.7830 - val_loss: 0.5390 - val_accuracy: 0.7396\n",
      "Epoch 1388/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4259 - accuracy: 0.7830 - val_loss: 0.5390 - val_accuracy: 0.7396\n",
      "Epoch 1389/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4259 - accuracy: 0.7830 - val_loss: 0.5390 - val_accuracy: 0.7396\n",
      "Epoch 1390/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4259 - accuracy: 0.7847 - val_loss: 0.5390 - val_accuracy: 0.7396\n",
      "Epoch 1391/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4259 - accuracy: 0.7830 - val_loss: 0.5390 - val_accuracy: 0.7396\n",
      "Epoch 1392/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4258 - accuracy: 0.7847 - val_loss: 0.5389 - val_accuracy: 0.7396\n",
      "Epoch 1393/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4259 - accuracy: 0.7847 - val_loss: 0.5389 - val_accuracy: 0.7396\n",
      "Epoch 1394/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4259 - accuracy: 0.7847 - val_loss: 0.5389 - val_accuracy: 0.7396\n",
      "Epoch 1395/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4258 - accuracy: 0.7847 - val_loss: 0.5389 - val_accuracy: 0.7396\n",
      "Epoch 1396/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4258 - accuracy: 0.7847 - val_loss: 0.5389 - val_accuracy: 0.7396\n",
      "Epoch 1397/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4258 - accuracy: 0.7847 - val_loss: 0.5388 - val_accuracy: 0.7396\n",
      "Epoch 1398/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4258 - accuracy: 0.7847 - val_loss: 0.5388 - val_accuracy: 0.7396\n",
      "Epoch 1399/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4257 - accuracy: 0.7847 - val_loss: 0.5388 - val_accuracy: 0.7396\n",
      "Epoch 1400/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4257 - accuracy: 0.7847 - val_loss: 0.5388 - val_accuracy: 0.7396\n",
      "Epoch 1401/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4257 - accuracy: 0.7847 - val_loss: 0.5388 - val_accuracy: 0.7396\n",
      "Epoch 1402/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4257 - accuracy: 0.7847 - val_loss: 0.5388 - val_accuracy: 0.7396\n",
      "Epoch 1403/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4256 - accuracy: 0.7847 - val_loss: 0.5387 - val_accuracy: 0.7396\n",
      "Epoch 1404/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4256 - accuracy: 0.7847 - val_loss: 0.5387 - val_accuracy: 0.7396\n",
      "Epoch 1405/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4256 - accuracy: 0.7847 - val_loss: 0.5387 - val_accuracy: 0.7396\n",
      "Epoch 1406/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4256 - accuracy: 0.7847 - val_loss: 0.5387 - val_accuracy: 0.7396\n",
      "Epoch 1407/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4256 - accuracy: 0.7847 - val_loss: 0.5387 - val_accuracy: 0.7396\n",
      "Epoch 1408/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4256 - accuracy: 0.7847 - val_loss: 0.5387 - val_accuracy: 0.7396\n",
      "Epoch 1409/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4256 - accuracy: 0.7847 - val_loss: 0.5387 - val_accuracy: 0.7396\n",
      "Epoch 1410/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4255 - accuracy: 0.7830 - val_loss: 0.5387 - val_accuracy: 0.7396\n",
      "Epoch 1411/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4255 - accuracy: 0.7830 - val_loss: 0.5387 - val_accuracy: 0.7396\n",
      "Epoch 1412/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4255 - accuracy: 0.7847 - val_loss: 0.5386 - val_accuracy: 0.7396\n",
      "Epoch 1413/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4255 - accuracy: 0.7847 - val_loss: 0.5386 - val_accuracy: 0.7396\n",
      "Epoch 1414/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4255 - accuracy: 0.7847 - val_loss: 0.5386 - val_accuracy: 0.7396\n",
      "Epoch 1415/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4255 - accuracy: 0.7847 - val_loss: 0.5386 - val_accuracy: 0.7396\n",
      "Epoch 1416/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4255 - accuracy: 0.7847 - val_loss: 0.5386 - val_accuracy: 0.7396\n",
      "Epoch 1417/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4254 - accuracy: 0.7847 - val_loss: 0.5386 - val_accuracy: 0.7396\n",
      "Epoch 1418/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4254 - accuracy: 0.7847 - val_loss: 0.5386 - val_accuracy: 0.7396\n",
      "Epoch 1419/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4254 - accuracy: 0.7847 - val_loss: 0.5386 - val_accuracy: 0.7396\n",
      "Epoch 1420/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4254 - accuracy: 0.7847 - val_loss: 0.5386 - val_accuracy: 0.7396\n",
      "Epoch 1421/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4254 - accuracy: 0.7847 - val_loss: 0.5386 - val_accuracy: 0.7396\n",
      "Epoch 1422/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4254 - accuracy: 0.7847 - val_loss: 0.5386 - val_accuracy: 0.7396\n",
      "Epoch 1423/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4253 - accuracy: 0.7847 - val_loss: 0.5385 - val_accuracy: 0.7396\n",
      "Epoch 1424/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4253 - accuracy: 0.7847 - val_loss: 0.5385 - val_accuracy: 0.7396\n",
      "Epoch 1425/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4253 - accuracy: 0.7847 - val_loss: 0.5385 - val_accuracy: 0.7396\n",
      "Epoch 1426/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4253 - accuracy: 0.7847 - val_loss: 0.5385 - val_accuracy: 0.7396\n",
      "Epoch 1427/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4253 - accuracy: 0.7847 - val_loss: 0.5385 - val_accuracy: 0.7396\n",
      "Epoch 1428/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4252 - accuracy: 0.7830 - val_loss: 0.5385 - val_accuracy: 0.7396\n",
      "Epoch 1429/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4252 - accuracy: 0.7847 - val_loss: 0.5385 - val_accuracy: 0.7396\n",
      "Epoch 1430/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4252 - accuracy: 0.7830 - val_loss: 0.5384 - val_accuracy: 0.7396\n",
      "Epoch 1431/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4252 - accuracy: 0.7847 - val_loss: 0.5384 - val_accuracy: 0.7396\n",
      "Epoch 1432/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4252 - accuracy: 0.7847 - val_loss: 0.5384 - val_accuracy: 0.7396\n",
      "Epoch 1433/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4252 - accuracy: 0.7830 - val_loss: 0.5384 - val_accuracy: 0.7396\n",
      "Epoch 1434/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4251 - accuracy: 0.7830 - val_loss: 0.5384 - val_accuracy: 0.7396\n",
      "Epoch 1435/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4251 - accuracy: 0.7830 - val_loss: 0.5384 - val_accuracy: 0.7396\n",
      "Epoch 1436/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4251 - accuracy: 0.7830 - val_loss: 0.5384 - val_accuracy: 0.7396\n",
      "Epoch 1437/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4251 - accuracy: 0.7847 - val_loss: 0.5384 - val_accuracy: 0.7396\n",
      "Epoch 1438/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4251 - accuracy: 0.7830 - val_loss: 0.5384 - val_accuracy: 0.7396\n",
      "Epoch 1439/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4251 - accuracy: 0.7830 - val_loss: 0.5384 - val_accuracy: 0.7396\n",
      "Epoch 1440/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4250 - accuracy: 0.7830 - val_loss: 0.5384 - val_accuracy: 0.7396\n",
      "Epoch 1441/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4250 - accuracy: 0.7830 - val_loss: 0.5383 - val_accuracy: 0.7396\n",
      "Epoch 1442/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4250 - accuracy: 0.7830 - val_loss: 0.5383 - val_accuracy: 0.7396\n",
      "Epoch 1443/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4250 - accuracy: 0.7830 - val_loss: 0.5383 - val_accuracy: 0.7396\n",
      "Epoch 1444/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4250 - accuracy: 0.7830 - val_loss: 0.5383 - val_accuracy: 0.7396\n",
      "Epoch 1445/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4250 - accuracy: 0.7830 - val_loss: 0.5383 - val_accuracy: 0.7396\n",
      "Epoch 1446/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4250 - accuracy: 0.7830 - val_loss: 0.5383 - val_accuracy: 0.7344\n",
      "Epoch 1447/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4249 - accuracy: 0.7830 - val_loss: 0.5383 - val_accuracy: 0.7344\n",
      "Epoch 1448/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4249 - accuracy: 0.7830 - val_loss: 0.5383 - val_accuracy: 0.7344\n",
      "Epoch 1449/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4249 - accuracy: 0.7830 - val_loss: 0.5383 - val_accuracy: 0.7344\n",
      "Epoch 1450/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4249 - accuracy: 0.7830 - val_loss: 0.5383 - val_accuracy: 0.7344\n",
      "Epoch 1451/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4249 - accuracy: 0.7847 - val_loss: 0.5383 - val_accuracy: 0.7344\n",
      "Epoch 1452/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4249 - accuracy: 0.7830 - val_loss: 0.5382 - val_accuracy: 0.7344\n",
      "Epoch 1453/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4249 - accuracy: 0.7830 - val_loss: 0.5383 - val_accuracy: 0.7344\n",
      "Epoch 1454/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4249 - accuracy: 0.7830 - val_loss: 0.5382 - val_accuracy: 0.7344\n",
      "Epoch 1455/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4249 - accuracy: 0.7830 - val_loss: 0.5382 - val_accuracy: 0.7344\n",
      "Epoch 1456/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4248 - accuracy: 0.7830 - val_loss: 0.5382 - val_accuracy: 0.7344\n",
      "Epoch 1457/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4248 - accuracy: 0.7830 - val_loss: 0.5382 - val_accuracy: 0.7344\n",
      "Epoch 1458/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4248 - accuracy: 0.7830 - val_loss: 0.5382 - val_accuracy: 0.7344\n",
      "Epoch 1459/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4247 - accuracy: 0.7830 - val_loss: 0.5382 - val_accuracy: 0.7344\n",
      "Epoch 1460/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4247 - accuracy: 0.7812 - val_loss: 0.5381 - val_accuracy: 0.7344\n",
      "Epoch 1461/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4248 - accuracy: 0.7830 - val_loss: 0.5381 - val_accuracy: 0.7344\n",
      "Epoch 1462/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4247 - accuracy: 0.7847 - val_loss: 0.5381 - val_accuracy: 0.7344\n",
      "Epoch 1463/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4247 - accuracy: 0.7830 - val_loss: 0.5381 - val_accuracy: 0.7344\n",
      "Epoch 1464/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4247 - accuracy: 0.7830 - val_loss: 0.5381 - val_accuracy: 0.7344\n",
      "Epoch 1465/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4246 - accuracy: 0.7830 - val_loss: 0.5381 - val_accuracy: 0.7344\n",
      "Epoch 1466/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4246 - accuracy: 0.7830 - val_loss: 0.5381 - val_accuracy: 0.7344\n",
      "Epoch 1467/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4247 - accuracy: 0.7812 - val_loss: 0.5381 - val_accuracy: 0.7344\n",
      "Epoch 1468/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4246 - accuracy: 0.7847 - val_loss: 0.5381 - val_accuracy: 0.7344\n",
      "Epoch 1469/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4246 - accuracy: 0.7847 - val_loss: 0.5381 - val_accuracy: 0.7344\n",
      "Epoch 1470/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4247 - accuracy: 0.7830 - val_loss: 0.5380 - val_accuracy: 0.7344\n",
      "Epoch 1471/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4246 - accuracy: 0.7830 - val_loss: 0.5380 - val_accuracy: 0.7344\n",
      "Epoch 1472/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4245 - accuracy: 0.7830 - val_loss: 0.5380 - val_accuracy: 0.7344\n",
      "Epoch 1473/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4246 - accuracy: 0.7830 - val_loss: 0.5380 - val_accuracy: 0.7344\n",
      "Epoch 1474/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4245 - accuracy: 0.7830 - val_loss: 0.5380 - val_accuracy: 0.7344\n",
      "Epoch 1475/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4245 - accuracy: 0.7830 - val_loss: 0.5380 - val_accuracy: 0.7344\n",
      "Epoch 1476/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4245 - accuracy: 0.7830 - val_loss: 0.5380 - val_accuracy: 0.7344\n",
      "Epoch 1477/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4245 - accuracy: 0.7812 - val_loss: 0.5380 - val_accuracy: 0.7344\n",
      "Epoch 1478/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4245 - accuracy: 0.7830 - val_loss: 0.5380 - val_accuracy: 0.7344\n",
      "Epoch 1479/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4244 - accuracy: 0.7830 - val_loss: 0.5380 - val_accuracy: 0.7344\n",
      "Epoch 1480/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4244 - accuracy: 0.7812 - val_loss: 0.5380 - val_accuracy: 0.7344\n",
      "Epoch 1481/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4244 - accuracy: 0.7830 - val_loss: 0.5380 - val_accuracy: 0.7344\n",
      "Epoch 1482/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4243 - accuracy: 0.7830 - val_loss: 0.5379 - val_accuracy: 0.7344\n",
      "Epoch 1483/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4244 - accuracy: 0.7830 - val_loss: 0.5379 - val_accuracy: 0.7344\n",
      "Epoch 1484/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4243 - accuracy: 0.7830 - val_loss: 0.5379 - val_accuracy: 0.7344\n",
      "Epoch 1485/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4243 - accuracy: 0.7830 - val_loss: 0.5379 - val_accuracy: 0.7344\n",
      "Epoch 1486/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4243 - accuracy: 0.7830 - val_loss: 0.5379 - val_accuracy: 0.7344\n",
      "Epoch 1487/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4243 - accuracy: 0.7830 - val_loss: 0.5379 - val_accuracy: 0.7344\n",
      "Epoch 1488/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4242 - accuracy: 0.7830 - val_loss: 0.5379 - val_accuracy: 0.7344\n",
      "Epoch 1489/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4242 - accuracy: 0.7830 - val_loss: 0.5378 - val_accuracy: 0.7344\n",
      "Epoch 1490/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4243 - accuracy: 0.7830 - val_loss: 0.5378 - val_accuracy: 0.7344\n",
      "Epoch 1491/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4243 - accuracy: 0.7830 - val_loss: 0.5378 - val_accuracy: 0.7344\n",
      "Epoch 1492/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4242 - accuracy: 0.7830 - val_loss: 0.5378 - val_accuracy: 0.7344\n",
      "Epoch 1493/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4242 - accuracy: 0.7830 - val_loss: 0.5378 - val_accuracy: 0.7344\n",
      "Epoch 1494/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4242 - accuracy: 0.7830 - val_loss: 0.5378 - val_accuracy: 0.7344\n",
      "Epoch 1495/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4242 - accuracy: 0.7830 - val_loss: 0.5378 - val_accuracy: 0.7344\n",
      "Epoch 1496/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4241 - accuracy: 0.7830 - val_loss: 0.5378 - val_accuracy: 0.7344\n",
      "Epoch 1497/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4241 - accuracy: 0.7830 - val_loss: 0.5377 - val_accuracy: 0.7344\n",
      "Epoch 1498/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4241 - accuracy: 0.7830 - val_loss: 0.5377 - val_accuracy: 0.7344\n",
      "Epoch 1499/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4241 - accuracy: 0.7830 - val_loss: 0.5377 - val_accuracy: 0.7344\n",
      "Epoch 1500/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4240 - accuracy: 0.7830 - val_loss: 0.5377 - val_accuracy: 0.7344\n"
     ]
    }
   ],
   "source": [
    "### BEGIN SOLUTION\n",
    "model_2 = Sequential([\n",
    "    layers.Dense(6, input_shape=(8,), activation='relu', name='hidden-layer1-relu'),\n",
    "    layers.Dense(6, activation='relu', name='hidden-layer2-sigmoid'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_2.compile(SGD(lr=.003), \"binary_crossentropy\", metrics=['accuracy'])\n",
    "run_hist_2 = model_2.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1500)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6861 - accuracy: 0.5503 - val_loss: 0.6920 - val_accuracy: 0.5052\n",
      "Epoch 2/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6833 - accuracy: 0.5660 - val_loss: 0.6896 - val_accuracy: 0.5260\n",
      "Epoch 3/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6806 - accuracy: 0.5816 - val_loss: 0.6873 - val_accuracy: 0.5260\n",
      "Epoch 4/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6781 - accuracy: 0.5833 - val_loss: 0.6851 - val_accuracy: 0.5469\n",
      "Epoch 5/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6756 - accuracy: 0.5885 - val_loss: 0.6831 - val_accuracy: 0.5729\n",
      "Epoch 6/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6733 - accuracy: 0.5920 - val_loss: 0.6812 - val_accuracy: 0.5938\n",
      "Epoch 7/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6711 - accuracy: 0.6007 - val_loss: 0.6794 - val_accuracy: 0.5938\n",
      "Epoch 8/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6690 - accuracy: 0.6198 - val_loss: 0.6776 - val_accuracy: 0.6042\n",
      "Epoch 9/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6670 - accuracy: 0.6233 - val_loss: 0.6758 - val_accuracy: 0.5990\n",
      "Epoch 10/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6649 - accuracy: 0.6267 - val_loss: 0.6742 - val_accuracy: 0.6042\n",
      "Epoch 11/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6630 - accuracy: 0.6424 - val_loss: 0.6726 - val_accuracy: 0.6146\n",
      "Epoch 12/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6610 - accuracy: 0.6493 - val_loss: 0.6710 - val_accuracy: 0.6406\n",
      "Epoch 13/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6591 - accuracy: 0.6528 - val_loss: 0.6695 - val_accuracy: 0.6510\n",
      "Epoch 14/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6573 - accuracy: 0.6632 - val_loss: 0.6680 - val_accuracy: 0.6458\n",
      "Epoch 15/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6555 - accuracy: 0.6667 - val_loss: 0.6666 - val_accuracy: 0.6458\n",
      "Epoch 16/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6538 - accuracy: 0.6684 - val_loss: 0.6653 - val_accuracy: 0.6458\n",
      "Epoch 17/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6522 - accuracy: 0.6753 - val_loss: 0.6639 - val_accuracy: 0.6562\n",
      "Epoch 18/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6505 - accuracy: 0.6806 - val_loss: 0.6626 - val_accuracy: 0.6615\n",
      "Epoch 19/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6489 - accuracy: 0.6806 - val_loss: 0.6613 - val_accuracy: 0.6562\n",
      "Epoch 20/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6473 - accuracy: 0.6840 - val_loss: 0.6601 - val_accuracy: 0.6562\n",
      "Epoch 21/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6458 - accuracy: 0.6875 - val_loss: 0.6588 - val_accuracy: 0.6562\n",
      "Epoch 22/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6442 - accuracy: 0.6806 - val_loss: 0.6576 - val_accuracy: 0.6562\n",
      "Epoch 23/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6427 - accuracy: 0.6771 - val_loss: 0.6565 - val_accuracy: 0.6510\n",
      "Epoch 24/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6411 - accuracy: 0.6788 - val_loss: 0.6553 - val_accuracy: 0.6458\n",
      "Epoch 25/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6397 - accuracy: 0.6753 - val_loss: 0.6541 - val_accuracy: 0.6458\n",
      "Epoch 26/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6382 - accuracy: 0.6736 - val_loss: 0.6529 - val_accuracy: 0.6510\n",
      "Epoch 27/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6367 - accuracy: 0.6736 - val_loss: 0.6517 - val_accuracy: 0.6510\n",
      "Epoch 28/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6353 - accuracy: 0.6736 - val_loss: 0.6506 - val_accuracy: 0.6510\n",
      "Epoch 29/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6340 - accuracy: 0.6771 - val_loss: 0.6495 - val_accuracy: 0.6510\n",
      "Epoch 30/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6326 - accuracy: 0.6771 - val_loss: 0.6484 - val_accuracy: 0.6510\n",
      "Epoch 31/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6312 - accuracy: 0.6771 - val_loss: 0.6474 - val_accuracy: 0.6510\n",
      "Epoch 32/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6298 - accuracy: 0.6788 - val_loss: 0.6463 - val_accuracy: 0.6510\n",
      "Epoch 33/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6285 - accuracy: 0.6788 - val_loss: 0.6453 - val_accuracy: 0.6510\n",
      "Epoch 34/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6272 - accuracy: 0.6736 - val_loss: 0.6443 - val_accuracy: 0.6510\n",
      "Epoch 35/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6259 - accuracy: 0.6736 - val_loss: 0.6433 - val_accuracy: 0.6667\n",
      "Epoch 36/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6246 - accuracy: 0.6701 - val_loss: 0.6423 - val_accuracy: 0.6667\n",
      "Epoch 37/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6233 - accuracy: 0.6719 - val_loss: 0.6414 - val_accuracy: 0.6667\n",
      "Epoch 38/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6220 - accuracy: 0.6719 - val_loss: 0.6404 - val_accuracy: 0.6667\n",
      "Epoch 39/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6207 - accuracy: 0.6736 - val_loss: 0.6395 - val_accuracy: 0.6667\n",
      "Epoch 40/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6194 - accuracy: 0.6771 - val_loss: 0.6386 - val_accuracy: 0.6667\n",
      "Epoch 41/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6181 - accuracy: 0.6753 - val_loss: 0.6376 - val_accuracy: 0.6667\n",
      "Epoch 42/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6169 - accuracy: 0.6753 - val_loss: 0.6367 - val_accuracy: 0.6719\n",
      "Epoch 43/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6156 - accuracy: 0.6753 - val_loss: 0.6359 - val_accuracy: 0.6719\n",
      "Epoch 44/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6143 - accuracy: 0.6753 - val_loss: 0.6350 - val_accuracy: 0.6771\n",
      "Epoch 45/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6130 - accuracy: 0.6771 - val_loss: 0.6341 - val_accuracy: 0.6823\n",
      "Epoch 46/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6117 - accuracy: 0.6788 - val_loss: 0.6332 - val_accuracy: 0.6823\n",
      "Epoch 47/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6105 - accuracy: 0.6806 - val_loss: 0.6323 - val_accuracy: 0.6823\n",
      "Epoch 48/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6092 - accuracy: 0.6823 - val_loss: 0.6315 - val_accuracy: 0.6823\n",
      "Epoch 49/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6080 - accuracy: 0.6806 - val_loss: 0.6306 - val_accuracy: 0.6771\n",
      "Epoch 50/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6067 - accuracy: 0.6823 - val_loss: 0.6298 - val_accuracy: 0.6719\n",
      "Epoch 51/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6055 - accuracy: 0.6806 - val_loss: 0.6290 - val_accuracy: 0.6719\n",
      "Epoch 52/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6043 - accuracy: 0.6823 - val_loss: 0.6281 - val_accuracy: 0.6719\n",
      "Epoch 53/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6031 - accuracy: 0.6840 - val_loss: 0.6273 - val_accuracy: 0.6719\n",
      "Epoch 54/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6020 - accuracy: 0.6858 - val_loss: 0.6266 - val_accuracy: 0.6719\n",
      "Epoch 55/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6008 - accuracy: 0.6840 - val_loss: 0.6258 - val_accuracy: 0.6719\n",
      "Epoch 56/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5996 - accuracy: 0.6840 - val_loss: 0.6250 - val_accuracy: 0.6667\n",
      "Epoch 57/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5984 - accuracy: 0.6840 - val_loss: 0.6243 - val_accuracy: 0.6615\n",
      "Epoch 58/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5973 - accuracy: 0.6858 - val_loss: 0.6235 - val_accuracy: 0.6667\n",
      "Epoch 59/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5961 - accuracy: 0.6875 - val_loss: 0.6228 - val_accuracy: 0.6615\n",
      "Epoch 60/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5950 - accuracy: 0.6927 - val_loss: 0.6221 - val_accuracy: 0.6615\n",
      "Epoch 61/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5938 - accuracy: 0.6910 - val_loss: 0.6214 - val_accuracy: 0.6615\n",
      "Epoch 62/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5927 - accuracy: 0.6927 - val_loss: 0.6207 - val_accuracy: 0.6562\n",
      "Epoch 63/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5915 - accuracy: 0.6927 - val_loss: 0.6200 - val_accuracy: 0.6562\n",
      "Epoch 64/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5904 - accuracy: 0.6927 - val_loss: 0.6193 - val_accuracy: 0.6562\n",
      "Epoch 65/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5893 - accuracy: 0.6979 - val_loss: 0.6186 - val_accuracy: 0.6562\n",
      "Epoch 66/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5882 - accuracy: 0.6979 - val_loss: 0.6179 - val_accuracy: 0.6562\n",
      "Epoch 67/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5871 - accuracy: 0.6997 - val_loss: 0.6173 - val_accuracy: 0.6562\n",
      "Epoch 68/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5860 - accuracy: 0.6997 - val_loss: 0.6166 - val_accuracy: 0.6562\n",
      "Epoch 69/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5849 - accuracy: 0.7014 - val_loss: 0.6160 - val_accuracy: 0.6562\n",
      "Epoch 70/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5838 - accuracy: 0.6997 - val_loss: 0.6154 - val_accuracy: 0.6562\n",
      "Epoch 71/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5827 - accuracy: 0.7049 - val_loss: 0.6147 - val_accuracy: 0.6562\n",
      "Epoch 72/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5816 - accuracy: 0.7066 - val_loss: 0.6141 - val_accuracy: 0.6562\n",
      "Epoch 73/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5804 - accuracy: 0.7083 - val_loss: 0.6135 - val_accuracy: 0.6562\n",
      "Epoch 74/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5794 - accuracy: 0.7118 - val_loss: 0.6129 - val_accuracy: 0.6562\n",
      "Epoch 75/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5783 - accuracy: 0.7153 - val_loss: 0.6122 - val_accuracy: 0.6562\n",
      "Epoch 76/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5772 - accuracy: 0.7188 - val_loss: 0.6116 - val_accuracy: 0.6667\n",
      "Epoch 77/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5761 - accuracy: 0.7188 - val_loss: 0.6110 - val_accuracy: 0.6667\n",
      "Epoch 78/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5751 - accuracy: 0.7188 - val_loss: 0.6105 - val_accuracy: 0.6719\n",
      "Epoch 79/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5740 - accuracy: 0.7170 - val_loss: 0.6099 - val_accuracy: 0.6771\n",
      "Epoch 80/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5729 - accuracy: 0.7188 - val_loss: 0.6093 - val_accuracy: 0.6823\n",
      "Epoch 81/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5719 - accuracy: 0.7170 - val_loss: 0.6087 - val_accuracy: 0.6823\n",
      "Epoch 82/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5708 - accuracy: 0.7170 - val_loss: 0.6082 - val_accuracy: 0.6823\n",
      "Epoch 83/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5697 - accuracy: 0.7153 - val_loss: 0.6076 - val_accuracy: 0.6823\n",
      "Epoch 84/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5686 - accuracy: 0.7170 - val_loss: 0.6071 - val_accuracy: 0.6823\n",
      "Epoch 85/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5676 - accuracy: 0.7153 - val_loss: 0.6065 - val_accuracy: 0.6875\n",
      "Epoch 86/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5665 - accuracy: 0.7135 - val_loss: 0.6060 - val_accuracy: 0.6875\n",
      "Epoch 87/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5654 - accuracy: 0.7135 - val_loss: 0.6054 - val_accuracy: 0.6875\n",
      "Epoch 88/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5643 - accuracy: 0.7118 - val_loss: 0.6049 - val_accuracy: 0.6875\n",
      "Epoch 89/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5633 - accuracy: 0.7135 - val_loss: 0.6044 - val_accuracy: 0.6875\n",
      "Epoch 90/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5623 - accuracy: 0.7135 - val_loss: 0.6039 - val_accuracy: 0.6875\n",
      "Epoch 91/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5612 - accuracy: 0.7118 - val_loss: 0.6034 - val_accuracy: 0.6823\n",
      "Epoch 92/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5602 - accuracy: 0.7101 - val_loss: 0.6029 - val_accuracy: 0.6823\n",
      "Epoch 93/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5592 - accuracy: 0.7135 - val_loss: 0.6024 - val_accuracy: 0.6823\n",
      "Epoch 94/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5582 - accuracy: 0.7170 - val_loss: 0.6019 - val_accuracy: 0.6771\n",
      "Epoch 95/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5571 - accuracy: 0.7170 - val_loss: 0.6014 - val_accuracy: 0.6771\n",
      "Epoch 96/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5561 - accuracy: 0.7170 - val_loss: 0.6009 - val_accuracy: 0.6771\n",
      "Epoch 97/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5552 - accuracy: 0.7170 - val_loss: 0.6004 - val_accuracy: 0.6771\n",
      "Epoch 98/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5541 - accuracy: 0.7170 - val_loss: 0.5999 - val_accuracy: 0.6771\n",
      "Epoch 99/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5531 - accuracy: 0.7170 - val_loss: 0.5994 - val_accuracy: 0.6771\n",
      "Epoch 100/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5522 - accuracy: 0.7188 - val_loss: 0.5989 - val_accuracy: 0.6771\n",
      "Epoch 101/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5512 - accuracy: 0.7188 - val_loss: 0.5984 - val_accuracy: 0.6771\n",
      "Epoch 102/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5502 - accuracy: 0.7205 - val_loss: 0.5979 - val_accuracy: 0.6771\n",
      "Epoch 103/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5492 - accuracy: 0.7188 - val_loss: 0.5975 - val_accuracy: 0.6771\n",
      "Epoch 104/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5483 - accuracy: 0.7170 - val_loss: 0.5970 - val_accuracy: 0.6771\n",
      "Epoch 105/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5473 - accuracy: 0.7153 - val_loss: 0.5965 - val_accuracy: 0.6771\n",
      "Epoch 106/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5464 - accuracy: 0.7153 - val_loss: 0.5960 - val_accuracy: 0.6771\n",
      "Epoch 107/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5455 - accuracy: 0.7170 - val_loss: 0.5955 - val_accuracy: 0.6771\n",
      "Epoch 108/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5445 - accuracy: 0.7170 - val_loss: 0.5951 - val_accuracy: 0.6771\n",
      "Epoch 109/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5436 - accuracy: 0.7170 - val_loss: 0.5946 - val_accuracy: 0.6771\n",
      "Epoch 110/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5427 - accuracy: 0.7222 - val_loss: 0.5941 - val_accuracy: 0.6771\n",
      "Epoch 111/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5418 - accuracy: 0.7222 - val_loss: 0.5937 - val_accuracy: 0.6771\n",
      "Epoch 112/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5409 - accuracy: 0.7240 - val_loss: 0.5933 - val_accuracy: 0.6771\n",
      "Epoch 113/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5400 - accuracy: 0.7240 - val_loss: 0.5928 - val_accuracy: 0.6771\n",
      "Epoch 114/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5392 - accuracy: 0.7274 - val_loss: 0.5924 - val_accuracy: 0.6771\n",
      "Epoch 115/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5383 - accuracy: 0.7326 - val_loss: 0.5920 - val_accuracy: 0.6771\n",
      "Epoch 116/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5375 - accuracy: 0.7326 - val_loss: 0.5915 - val_accuracy: 0.6771\n",
      "Epoch 117/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5367 - accuracy: 0.7344 - val_loss: 0.5911 - val_accuracy: 0.6771\n",
      "Epoch 118/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5358 - accuracy: 0.7344 - val_loss: 0.5907 - val_accuracy: 0.6771\n",
      "Epoch 119/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5351 - accuracy: 0.7344 - val_loss: 0.5904 - val_accuracy: 0.6771\n",
      "Epoch 120/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5343 - accuracy: 0.7361 - val_loss: 0.5900 - val_accuracy: 0.6771\n",
      "Epoch 121/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5335 - accuracy: 0.7361 - val_loss: 0.5896 - val_accuracy: 0.6719\n",
      "Epoch 122/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5327 - accuracy: 0.7344 - val_loss: 0.5892 - val_accuracy: 0.6771\n",
      "Epoch 123/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5320 - accuracy: 0.7344 - val_loss: 0.5888 - val_accuracy: 0.6771\n",
      "Epoch 124/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5312 - accuracy: 0.7344 - val_loss: 0.5885 - val_accuracy: 0.6771\n",
      "Epoch 125/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5305 - accuracy: 0.7344 - val_loss: 0.5881 - val_accuracy: 0.6771\n",
      "Epoch 126/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5297 - accuracy: 0.7326 - val_loss: 0.5878 - val_accuracy: 0.6771\n",
      "Epoch 127/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5290 - accuracy: 0.7326 - val_loss: 0.5874 - val_accuracy: 0.6823\n",
      "Epoch 128/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5283 - accuracy: 0.7378 - val_loss: 0.5870 - val_accuracy: 0.6719\n",
      "Epoch 129/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5276 - accuracy: 0.7378 - val_loss: 0.5867 - val_accuracy: 0.6719\n",
      "Epoch 130/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5269 - accuracy: 0.7378 - val_loss: 0.5863 - val_accuracy: 0.6667\n",
      "Epoch 131/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5262 - accuracy: 0.7396 - val_loss: 0.5860 - val_accuracy: 0.6667\n",
      "Epoch 132/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5255 - accuracy: 0.7378 - val_loss: 0.5857 - val_accuracy: 0.6667\n",
      "Epoch 133/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5249 - accuracy: 0.7378 - val_loss: 0.5853 - val_accuracy: 0.6667\n",
      "Epoch 134/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5242 - accuracy: 0.7396 - val_loss: 0.5850 - val_accuracy: 0.6667\n",
      "Epoch 135/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5236 - accuracy: 0.7396 - val_loss: 0.5847 - val_accuracy: 0.6719\n",
      "Epoch 136/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5229 - accuracy: 0.7396 - val_loss: 0.5844 - val_accuracy: 0.6667\n",
      "Epoch 137/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5223 - accuracy: 0.7378 - val_loss: 0.5840 - val_accuracy: 0.6667\n",
      "Epoch 138/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5216 - accuracy: 0.7378 - val_loss: 0.5837 - val_accuracy: 0.6667\n",
      "Epoch 139/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5210 - accuracy: 0.7378 - val_loss: 0.5834 - val_accuracy: 0.6667\n",
      "Epoch 140/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5204 - accuracy: 0.7396 - val_loss: 0.5831 - val_accuracy: 0.6719\n",
      "Epoch 141/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5198 - accuracy: 0.7378 - val_loss: 0.5828 - val_accuracy: 0.6667\n",
      "Epoch 142/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5192 - accuracy: 0.7396 - val_loss: 0.5826 - val_accuracy: 0.6667\n",
      "Epoch 143/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5185 - accuracy: 0.7396 - val_loss: 0.5823 - val_accuracy: 0.6667\n",
      "Epoch 144/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5179 - accuracy: 0.7378 - val_loss: 0.5820 - val_accuracy: 0.6667\n",
      "Epoch 145/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5173 - accuracy: 0.7361 - val_loss: 0.5817 - val_accuracy: 0.6615\n",
      "Epoch 146/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5168 - accuracy: 0.7396 - val_loss: 0.5814 - val_accuracy: 0.6667\n",
      "Epoch 147/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5162 - accuracy: 0.7396 - val_loss: 0.5811 - val_accuracy: 0.6615\n",
      "Epoch 148/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5156 - accuracy: 0.7378 - val_loss: 0.5809 - val_accuracy: 0.6615\n",
      "Epoch 149/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5150 - accuracy: 0.7378 - val_loss: 0.5806 - val_accuracy: 0.6615\n",
      "Epoch 150/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5144 - accuracy: 0.7361 - val_loss: 0.5803 - val_accuracy: 0.6615\n",
      "Epoch 151/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5138 - accuracy: 0.7361 - val_loss: 0.5801 - val_accuracy: 0.6615\n",
      "Epoch 152/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5133 - accuracy: 0.7378 - val_loss: 0.5798 - val_accuracy: 0.6562\n",
      "Epoch 153/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5127 - accuracy: 0.7396 - val_loss: 0.5796 - val_accuracy: 0.6562\n",
      "Epoch 154/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5122 - accuracy: 0.7396 - val_loss: 0.5793 - val_accuracy: 0.6562\n",
      "Epoch 155/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5116 - accuracy: 0.7413 - val_loss: 0.5791 - val_accuracy: 0.6615\n",
      "Epoch 156/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5111 - accuracy: 0.7448 - val_loss: 0.5788 - val_accuracy: 0.6615\n",
      "Epoch 157/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5106 - accuracy: 0.7448 - val_loss: 0.5786 - val_accuracy: 0.6615\n",
      "Epoch 158/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5100 - accuracy: 0.7465 - val_loss: 0.5783 - val_accuracy: 0.6615\n",
      "Epoch 159/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5096 - accuracy: 0.7465 - val_loss: 0.5781 - val_accuracy: 0.6667\n",
      "Epoch 160/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.7465 - val_loss: 0.5778 - val_accuracy: 0.6719\n",
      "Epoch 161/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5085 - accuracy: 0.7448 - val_loss: 0.5776 - val_accuracy: 0.6719\n",
      "Epoch 162/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5080 - accuracy: 0.7448 - val_loss: 0.5773 - val_accuracy: 0.6771\n",
      "Epoch 163/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5075 - accuracy: 0.7465 - val_loss: 0.5771 - val_accuracy: 0.6771\n",
      "Epoch 164/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5070 - accuracy: 0.7465 - val_loss: 0.5769 - val_accuracy: 0.6771\n",
      "Epoch 165/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.7465 - val_loss: 0.5767 - val_accuracy: 0.6771\n",
      "Epoch 166/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7448 - val_loss: 0.5764 - val_accuracy: 0.6771\n",
      "Epoch 167/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7448 - val_loss: 0.5762 - val_accuracy: 0.6771\n",
      "Epoch 168/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7448 - val_loss: 0.5760 - val_accuracy: 0.6823\n",
      "Epoch 169/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7448 - val_loss: 0.5758 - val_accuracy: 0.6823\n",
      "Epoch 170/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7448 - val_loss: 0.5756 - val_accuracy: 0.6823\n",
      "Epoch 171/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7448 - val_loss: 0.5754 - val_accuracy: 0.6823\n",
      "Epoch 172/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7483 - val_loss: 0.5751 - val_accuracy: 0.6823\n",
      "Epoch 173/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7500 - val_loss: 0.5749 - val_accuracy: 0.6823\n",
      "Epoch 174/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5023 - accuracy: 0.7500 - val_loss: 0.5747 - val_accuracy: 0.6823\n",
      "Epoch 175/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5018 - accuracy: 0.7500 - val_loss: 0.5745 - val_accuracy: 0.6719\n",
      "Epoch 176/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5013 - accuracy: 0.7517 - val_loss: 0.5743 - val_accuracy: 0.6719\n",
      "Epoch 177/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5009 - accuracy: 0.7535 - val_loss: 0.5741 - val_accuracy: 0.6667\n",
      "Epoch 178/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5003 - accuracy: 0.7500 - val_loss: 0.5739 - val_accuracy: 0.6667\n",
      "Epoch 179/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4999 - accuracy: 0.7500 - val_loss: 0.5737 - val_accuracy: 0.6667\n",
      "Epoch 180/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4994 - accuracy: 0.7535 - val_loss: 0.5735 - val_accuracy: 0.6615\n",
      "Epoch 181/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4990 - accuracy: 0.7552 - val_loss: 0.5732 - val_accuracy: 0.6615\n",
      "Epoch 182/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4985 - accuracy: 0.7517 - val_loss: 0.5730 - val_accuracy: 0.6615\n",
      "Epoch 183/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4981 - accuracy: 0.7552 - val_loss: 0.5728 - val_accuracy: 0.6615\n",
      "Epoch 184/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4977 - accuracy: 0.7569 - val_loss: 0.5727 - val_accuracy: 0.6615\n",
      "Epoch 185/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4972 - accuracy: 0.7535 - val_loss: 0.5725 - val_accuracy: 0.6667\n",
      "Epoch 186/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4969 - accuracy: 0.7552 - val_loss: 0.5723 - val_accuracy: 0.6667\n",
      "Epoch 187/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4964 - accuracy: 0.7517 - val_loss: 0.5721 - val_accuracy: 0.6667\n",
      "Epoch 188/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4960 - accuracy: 0.7535 - val_loss: 0.5719 - val_accuracy: 0.6667\n",
      "Epoch 189/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4955 - accuracy: 0.7535 - val_loss: 0.5718 - val_accuracy: 0.6667\n",
      "Epoch 190/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4951 - accuracy: 0.7535 - val_loss: 0.5716 - val_accuracy: 0.6667\n",
      "Epoch 191/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4947 - accuracy: 0.7552 - val_loss: 0.5714 - val_accuracy: 0.6667\n",
      "Epoch 192/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4943 - accuracy: 0.7569 - val_loss: 0.5713 - val_accuracy: 0.6667\n",
      "Epoch 193/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4939 - accuracy: 0.7587 - val_loss: 0.5711 - val_accuracy: 0.6667\n",
      "Epoch 194/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4935 - accuracy: 0.7587 - val_loss: 0.5709 - val_accuracy: 0.6667\n",
      "Epoch 195/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4931 - accuracy: 0.7569 - val_loss: 0.5707 - val_accuracy: 0.6667\n",
      "Epoch 196/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4927 - accuracy: 0.7569 - val_loss: 0.5705 - val_accuracy: 0.6667\n",
      "Epoch 197/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4923 - accuracy: 0.7569 - val_loss: 0.5704 - val_accuracy: 0.6667\n",
      "Epoch 198/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4919 - accuracy: 0.7587 - val_loss: 0.5702 - val_accuracy: 0.6667\n",
      "Epoch 199/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4915 - accuracy: 0.7604 - val_loss: 0.5700 - val_accuracy: 0.6667\n",
      "Epoch 200/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4911 - accuracy: 0.7587 - val_loss: 0.5698 - val_accuracy: 0.6667\n",
      "Epoch 201/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4907 - accuracy: 0.7622 - val_loss: 0.5696 - val_accuracy: 0.6667\n",
      "Epoch 202/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4904 - accuracy: 0.7587 - val_loss: 0.5694 - val_accuracy: 0.6667\n",
      "Epoch 203/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4900 - accuracy: 0.7639 - val_loss: 0.5693 - val_accuracy: 0.6667\n",
      "Epoch 204/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4896 - accuracy: 0.7622 - val_loss: 0.5691 - val_accuracy: 0.6667\n",
      "Epoch 205/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4892 - accuracy: 0.7639 - val_loss: 0.5689 - val_accuracy: 0.6667\n",
      "Epoch 206/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4888 - accuracy: 0.7656 - val_loss: 0.5688 - val_accuracy: 0.6667\n",
      "Epoch 207/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4885 - accuracy: 0.7674 - val_loss: 0.5686 - val_accuracy: 0.6667\n",
      "Epoch 208/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4881 - accuracy: 0.7674 - val_loss: 0.5684 - val_accuracy: 0.6667\n",
      "Epoch 209/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4877 - accuracy: 0.7674 - val_loss: 0.5683 - val_accuracy: 0.6667\n",
      "Epoch 210/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4874 - accuracy: 0.7674 - val_loss: 0.5681 - val_accuracy: 0.6667\n",
      "Epoch 211/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4870 - accuracy: 0.7691 - val_loss: 0.5680 - val_accuracy: 0.6667\n",
      "Epoch 212/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4868 - accuracy: 0.7691 - val_loss: 0.5678 - val_accuracy: 0.6667\n",
      "Epoch 213/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4865 - accuracy: 0.7691 - val_loss: 0.5676 - val_accuracy: 0.6667\n",
      "Epoch 214/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4860 - accuracy: 0.7691 - val_loss: 0.5675 - val_accuracy: 0.6667\n",
      "Epoch 215/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4857 - accuracy: 0.7691 - val_loss: 0.5673 - val_accuracy: 0.6667\n",
      "Epoch 216/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4854 - accuracy: 0.7691 - val_loss: 0.5672 - val_accuracy: 0.6667\n",
      "Epoch 217/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4850 - accuracy: 0.7691 - val_loss: 0.5670 - val_accuracy: 0.6667\n",
      "Epoch 218/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4847 - accuracy: 0.7691 - val_loss: 0.5669 - val_accuracy: 0.6667\n",
      "Epoch 219/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4843 - accuracy: 0.7691 - val_loss: 0.5667 - val_accuracy: 0.6667\n",
      "Epoch 220/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4839 - accuracy: 0.7691 - val_loss: 0.5666 - val_accuracy: 0.6667\n",
      "Epoch 221/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4836 - accuracy: 0.7691 - val_loss: 0.5664 - val_accuracy: 0.6667\n",
      "Epoch 222/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4832 - accuracy: 0.7691 - val_loss: 0.5663 - val_accuracy: 0.6667\n",
      "Epoch 223/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4829 - accuracy: 0.7691 - val_loss: 0.5661 - val_accuracy: 0.6667\n",
      "Epoch 224/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4826 - accuracy: 0.7691 - val_loss: 0.5660 - val_accuracy: 0.6667\n",
      "Epoch 225/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4822 - accuracy: 0.7708 - val_loss: 0.5659 - val_accuracy: 0.6615\n",
      "Epoch 226/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4819 - accuracy: 0.7726 - val_loss: 0.5658 - val_accuracy: 0.6615\n",
      "Epoch 227/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4816 - accuracy: 0.7726 - val_loss: 0.5656 - val_accuracy: 0.6667\n",
      "Epoch 228/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4812 - accuracy: 0.7708 - val_loss: 0.5655 - val_accuracy: 0.6667\n",
      "Epoch 229/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4809 - accuracy: 0.7726 - val_loss: 0.5654 - val_accuracy: 0.6667\n",
      "Epoch 230/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4806 - accuracy: 0.7708 - val_loss: 0.5653 - val_accuracy: 0.6667\n",
      "Epoch 231/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4802 - accuracy: 0.7726 - val_loss: 0.5651 - val_accuracy: 0.6615\n",
      "Epoch 232/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4799 - accuracy: 0.7708 - val_loss: 0.5650 - val_accuracy: 0.6615\n",
      "Epoch 233/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4796 - accuracy: 0.7726 - val_loss: 0.5649 - val_accuracy: 0.6615\n",
      "Epoch 234/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4793 - accuracy: 0.7726 - val_loss: 0.5647 - val_accuracy: 0.6615\n",
      "Epoch 235/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4789 - accuracy: 0.7726 - val_loss: 0.5646 - val_accuracy: 0.6615\n",
      "Epoch 236/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4787 - accuracy: 0.7726 - val_loss: 0.5645 - val_accuracy: 0.6615\n",
      "Epoch 237/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4783 - accuracy: 0.7708 - val_loss: 0.5643 - val_accuracy: 0.6615\n",
      "Epoch 238/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4780 - accuracy: 0.7708 - val_loss: 0.5642 - val_accuracy: 0.6615\n",
      "Epoch 239/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4777 - accuracy: 0.7708 - val_loss: 0.5641 - val_accuracy: 0.6615\n",
      "Epoch 240/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4774 - accuracy: 0.7708 - val_loss: 0.5639 - val_accuracy: 0.6562\n",
      "Epoch 241/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4771 - accuracy: 0.7708 - val_loss: 0.5638 - val_accuracy: 0.6562\n",
      "Epoch 242/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4768 - accuracy: 0.7708 - val_loss: 0.5637 - val_accuracy: 0.6562\n",
      "Epoch 243/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4765 - accuracy: 0.7691 - val_loss: 0.5636 - val_accuracy: 0.6562\n",
      "Epoch 244/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4762 - accuracy: 0.7691 - val_loss: 0.5635 - val_accuracy: 0.6562\n",
      "Epoch 245/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4758 - accuracy: 0.7691 - val_loss: 0.5634 - val_accuracy: 0.6562\n",
      "Epoch 246/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4755 - accuracy: 0.7691 - val_loss: 0.5633 - val_accuracy: 0.6562\n",
      "Epoch 247/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4752 - accuracy: 0.7691 - val_loss: 0.5632 - val_accuracy: 0.6562\n",
      "Epoch 248/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4749 - accuracy: 0.7691 - val_loss: 0.5630 - val_accuracy: 0.6562\n",
      "Epoch 249/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4747 - accuracy: 0.7691 - val_loss: 0.5629 - val_accuracy: 0.6562\n",
      "Epoch 250/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4744 - accuracy: 0.7691 - val_loss: 0.5628 - val_accuracy: 0.6562\n",
      "Epoch 251/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4741 - accuracy: 0.7708 - val_loss: 0.5627 - val_accuracy: 0.6562\n",
      "Epoch 252/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4738 - accuracy: 0.7708 - val_loss: 0.5626 - val_accuracy: 0.6562\n",
      "Epoch 253/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4735 - accuracy: 0.7708 - val_loss: 0.5625 - val_accuracy: 0.6562\n",
      "Epoch 254/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4733 - accuracy: 0.7708 - val_loss: 0.5623 - val_accuracy: 0.6562\n",
      "Epoch 255/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4730 - accuracy: 0.7726 - val_loss: 0.5622 - val_accuracy: 0.6562\n",
      "Epoch 256/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4727 - accuracy: 0.7726 - val_loss: 0.5621 - val_accuracy: 0.6562\n",
      "Epoch 257/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4725 - accuracy: 0.7726 - val_loss: 0.5620 - val_accuracy: 0.6562\n",
      "Epoch 258/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4721 - accuracy: 0.7726 - val_loss: 0.5618 - val_accuracy: 0.6562\n",
      "Epoch 259/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4719 - accuracy: 0.7726 - val_loss: 0.5617 - val_accuracy: 0.6562\n",
      "Epoch 260/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4716 - accuracy: 0.7726 - val_loss: 0.5615 - val_accuracy: 0.6562\n",
      "Epoch 261/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4713 - accuracy: 0.7726 - val_loss: 0.5614 - val_accuracy: 0.6562\n",
      "Epoch 262/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4711 - accuracy: 0.7726 - val_loss: 0.5613 - val_accuracy: 0.6562\n",
      "Epoch 263/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4708 - accuracy: 0.7726 - val_loss: 0.5611 - val_accuracy: 0.6562\n",
      "Epoch 264/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4705 - accuracy: 0.7726 - val_loss: 0.5610 - val_accuracy: 0.6562\n",
      "Epoch 265/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4703 - accuracy: 0.7726 - val_loss: 0.5608 - val_accuracy: 0.6562\n",
      "Epoch 266/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4701 - accuracy: 0.7708 - val_loss: 0.5607 - val_accuracy: 0.6562\n",
      "Epoch 267/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4698 - accuracy: 0.7708 - val_loss: 0.5605 - val_accuracy: 0.6562\n",
      "Epoch 268/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4695 - accuracy: 0.7708 - val_loss: 0.5604 - val_accuracy: 0.6562\n",
      "Epoch 269/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4692 - accuracy: 0.7708 - val_loss: 0.5603 - val_accuracy: 0.6562\n",
      "Epoch 270/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4690 - accuracy: 0.7726 - val_loss: 0.5601 - val_accuracy: 0.6562\n",
      "Epoch 271/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4687 - accuracy: 0.7726 - val_loss: 0.5600 - val_accuracy: 0.6615\n",
      "Epoch 272/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4685 - accuracy: 0.7726 - val_loss: 0.5599 - val_accuracy: 0.6615\n",
      "Epoch 273/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4682 - accuracy: 0.7708 - val_loss: 0.5598 - val_accuracy: 0.6615\n",
      "Epoch 274/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4680 - accuracy: 0.7691 - val_loss: 0.5597 - val_accuracy: 0.6615\n",
      "Epoch 275/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4677 - accuracy: 0.7691 - val_loss: 0.5595 - val_accuracy: 0.6615\n",
      "Epoch 276/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4675 - accuracy: 0.7691 - val_loss: 0.5595 - val_accuracy: 0.6615\n",
      "Epoch 277/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4673 - accuracy: 0.7691 - val_loss: 0.5594 - val_accuracy: 0.6615\n",
      "Epoch 278/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4670 - accuracy: 0.7691 - val_loss: 0.5593 - val_accuracy: 0.6615\n",
      "Epoch 279/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4668 - accuracy: 0.7708 - val_loss: 0.5592 - val_accuracy: 0.6667\n",
      "Epoch 280/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4665 - accuracy: 0.7708 - val_loss: 0.5591 - val_accuracy: 0.6667\n",
      "Epoch 281/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4663 - accuracy: 0.7708 - val_loss: 0.5590 - val_accuracy: 0.6667\n",
      "Epoch 282/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4661 - accuracy: 0.7708 - val_loss: 0.5589 - val_accuracy: 0.6615\n",
      "Epoch 283/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4658 - accuracy: 0.7708 - val_loss: 0.5588 - val_accuracy: 0.6615\n",
      "Epoch 284/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4656 - accuracy: 0.7708 - val_loss: 0.5587 - val_accuracy: 0.6615\n",
      "Epoch 285/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4654 - accuracy: 0.7691 - val_loss: 0.5586 - val_accuracy: 0.6615\n",
      "Epoch 286/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4652 - accuracy: 0.7708 - val_loss: 0.5585 - val_accuracy: 0.6615\n",
      "Epoch 287/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4649 - accuracy: 0.7708 - val_loss: 0.5584 - val_accuracy: 0.6615\n",
      "Epoch 288/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4647 - accuracy: 0.7691 - val_loss: 0.5584 - val_accuracy: 0.6667\n",
      "Epoch 289/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7708 - val_loss: 0.5583 - val_accuracy: 0.6667\n",
      "Epoch 290/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4643 - accuracy: 0.7708 - val_loss: 0.5582 - val_accuracy: 0.6667\n",
      "Epoch 291/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4641 - accuracy: 0.7708 - val_loss: 0.5582 - val_accuracy: 0.6667\n",
      "Epoch 292/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.7708 - val_loss: 0.5581 - val_accuracy: 0.6667\n",
      "Epoch 293/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4637 - accuracy: 0.7708 - val_loss: 0.5580 - val_accuracy: 0.6667\n",
      "Epoch 294/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4635 - accuracy: 0.7708 - val_loss: 0.5580 - val_accuracy: 0.6667\n",
      "Epoch 295/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4633 - accuracy: 0.7708 - val_loss: 0.5579 - val_accuracy: 0.6667\n",
      "Epoch 296/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.7691 - val_loss: 0.5579 - val_accuracy: 0.6667\n",
      "Epoch 297/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4628 - accuracy: 0.7691 - val_loss: 0.5578 - val_accuracy: 0.6667\n",
      "Epoch 298/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4627 - accuracy: 0.7691 - val_loss: 0.5577 - val_accuracy: 0.6667\n",
      "Epoch 299/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 0.7674 - val_loss: 0.5577 - val_accuracy: 0.6667\n",
      "Epoch 300/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4622 - accuracy: 0.7708 - val_loss: 0.5576 - val_accuracy: 0.6667\n",
      "Epoch 301/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.7708 - val_loss: 0.5575 - val_accuracy: 0.6667\n",
      "Epoch 302/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4619 - accuracy: 0.7726 - val_loss: 0.5574 - val_accuracy: 0.6667\n",
      "Epoch 303/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4617 - accuracy: 0.7708 - val_loss: 0.5574 - val_accuracy: 0.6667\n",
      "Epoch 304/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4615 - accuracy: 0.7708 - val_loss: 0.5573 - val_accuracy: 0.6667\n",
      "Epoch 305/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4613 - accuracy: 0.7708 - val_loss: 0.5572 - val_accuracy: 0.6667\n",
      "Epoch 306/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.7708 - val_loss: 0.5572 - val_accuracy: 0.6667\n",
      "Epoch 307/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.7726 - val_loss: 0.5571 - val_accuracy: 0.6719\n",
      "Epoch 308/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.7708 - val_loss: 0.5570 - val_accuracy: 0.6719\n",
      "Epoch 309/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.7708 - val_loss: 0.5570 - val_accuracy: 0.6719\n",
      "Epoch 310/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.7726 - val_loss: 0.5569 - val_accuracy: 0.6719\n",
      "Epoch 311/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4602 - accuracy: 0.7726 - val_loss: 0.5569 - val_accuracy: 0.6719\n",
      "Epoch 312/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4600 - accuracy: 0.7726 - val_loss: 0.5568 - val_accuracy: 0.6771\n",
      "Epoch 313/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4599 - accuracy: 0.7726 - val_loss: 0.5567 - val_accuracy: 0.6771\n",
      "Epoch 314/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4596 - accuracy: 0.7726 - val_loss: 0.5567 - val_accuracy: 0.6771\n",
      "Epoch 315/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4595 - accuracy: 0.7726 - val_loss: 0.5566 - val_accuracy: 0.6771\n",
      "Epoch 316/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4593 - accuracy: 0.7726 - val_loss: 0.5565 - val_accuracy: 0.6771\n",
      "Epoch 317/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4591 - accuracy: 0.7726 - val_loss: 0.5565 - val_accuracy: 0.6771\n",
      "Epoch 318/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4589 - accuracy: 0.7726 - val_loss: 0.5564 - val_accuracy: 0.6771\n",
      "Epoch 319/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.7726 - val_loss: 0.5564 - val_accuracy: 0.6823\n",
      "Epoch 320/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4586 - accuracy: 0.7726 - val_loss: 0.5563 - val_accuracy: 0.6823\n",
      "Epoch 321/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4584 - accuracy: 0.7726 - val_loss: 0.5563 - val_accuracy: 0.6823\n",
      "Epoch 322/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4583 - accuracy: 0.7708 - val_loss: 0.5562 - val_accuracy: 0.6823\n",
      "Epoch 323/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4581 - accuracy: 0.7708 - val_loss: 0.5562 - val_accuracy: 0.6823\n",
      "Epoch 324/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4580 - accuracy: 0.7708 - val_loss: 0.5562 - val_accuracy: 0.6823\n",
      "Epoch 325/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4578 - accuracy: 0.7708 - val_loss: 0.5561 - val_accuracy: 0.6823\n",
      "Epoch 326/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4577 - accuracy: 0.7708 - val_loss: 0.5561 - val_accuracy: 0.6823\n",
      "Epoch 327/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4575 - accuracy: 0.7708 - val_loss: 0.5561 - val_accuracy: 0.6823\n",
      "Epoch 328/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4573 - accuracy: 0.7708 - val_loss: 0.5560 - val_accuracy: 0.6823\n",
      "Epoch 329/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4572 - accuracy: 0.7708 - val_loss: 0.5560 - val_accuracy: 0.6823\n",
      "Epoch 330/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4570 - accuracy: 0.7708 - val_loss: 0.5559 - val_accuracy: 0.6823\n",
      "Epoch 331/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4568 - accuracy: 0.7708 - val_loss: 0.5559 - val_accuracy: 0.6823\n",
      "Epoch 332/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4567 - accuracy: 0.7726 - val_loss: 0.5559 - val_accuracy: 0.6823\n",
      "Epoch 333/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4565 - accuracy: 0.7708 - val_loss: 0.5558 - val_accuracy: 0.6823\n",
      "Epoch 334/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4564 - accuracy: 0.7726 - val_loss: 0.5558 - val_accuracy: 0.6823\n",
      "Epoch 335/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4562 - accuracy: 0.7726 - val_loss: 0.5558 - val_accuracy: 0.6823\n",
      "Epoch 336/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4561 - accuracy: 0.7726 - val_loss: 0.5557 - val_accuracy: 0.6823\n",
      "Epoch 337/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4560 - accuracy: 0.7726 - val_loss: 0.5557 - val_accuracy: 0.6823\n",
      "Epoch 338/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4558 - accuracy: 0.7726 - val_loss: 0.5557 - val_accuracy: 0.6823\n",
      "Epoch 339/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4556 - accuracy: 0.7726 - val_loss: 0.5557 - val_accuracy: 0.6875\n",
      "Epoch 340/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4555 - accuracy: 0.7726 - val_loss: 0.5557 - val_accuracy: 0.6875\n",
      "Epoch 341/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4554 - accuracy: 0.7726 - val_loss: 0.5556 - val_accuracy: 0.6875\n",
      "Epoch 342/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4552 - accuracy: 0.7726 - val_loss: 0.5556 - val_accuracy: 0.6875\n",
      "Epoch 343/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4551 - accuracy: 0.7726 - val_loss: 0.5556 - val_accuracy: 0.6875\n",
      "Epoch 344/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4549 - accuracy: 0.7743 - val_loss: 0.5556 - val_accuracy: 0.6875\n",
      "Epoch 345/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4548 - accuracy: 0.7743 - val_loss: 0.5556 - val_accuracy: 0.6875\n",
      "Epoch 346/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4547 - accuracy: 0.7743 - val_loss: 0.5555 - val_accuracy: 0.6875\n",
      "Epoch 347/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4545 - accuracy: 0.7743 - val_loss: 0.5556 - val_accuracy: 0.6875\n",
      "Epoch 348/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4544 - accuracy: 0.7743 - val_loss: 0.5555 - val_accuracy: 0.6875\n",
      "Epoch 349/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4544 - accuracy: 0.7743 - val_loss: 0.5555 - val_accuracy: 0.6875\n",
      "Epoch 350/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4542 - accuracy: 0.7743 - val_loss: 0.5555 - val_accuracy: 0.6875\n",
      "Epoch 351/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4540 - accuracy: 0.7743 - val_loss: 0.5555 - val_accuracy: 0.6875\n",
      "Epoch 352/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4539 - accuracy: 0.7743 - val_loss: 0.5555 - val_accuracy: 0.6875\n",
      "Epoch 353/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4538 - accuracy: 0.7743 - val_loss: 0.5555 - val_accuracy: 0.6875\n",
      "Epoch 354/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4537 - accuracy: 0.7743 - val_loss: 0.5555 - val_accuracy: 0.6875\n",
      "Epoch 355/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4536 - accuracy: 0.7743 - val_loss: 0.5555 - val_accuracy: 0.6875\n",
      "Epoch 356/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4534 - accuracy: 0.7743 - val_loss: 0.5555 - val_accuracy: 0.6875\n",
      "Epoch 357/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4533 - accuracy: 0.7760 - val_loss: 0.5555 - val_accuracy: 0.6927\n",
      "Epoch 358/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4532 - accuracy: 0.7760 - val_loss: 0.5555 - val_accuracy: 0.6927\n",
      "Epoch 359/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4531 - accuracy: 0.7760 - val_loss: 0.5555 - val_accuracy: 0.6927\n",
      "Epoch 360/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4530 - accuracy: 0.7760 - val_loss: 0.5555 - val_accuracy: 0.6927\n",
      "Epoch 361/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4528 - accuracy: 0.7760 - val_loss: 0.5555 - val_accuracy: 0.6927\n",
      "Epoch 362/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4527 - accuracy: 0.7778 - val_loss: 0.5555 - val_accuracy: 0.6927\n",
      "Epoch 363/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4526 - accuracy: 0.7760 - val_loss: 0.5554 - val_accuracy: 0.6927\n",
      "Epoch 364/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4525 - accuracy: 0.7760 - val_loss: 0.5554 - val_accuracy: 0.6927\n",
      "Epoch 365/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4524 - accuracy: 0.7760 - val_loss: 0.5555 - val_accuracy: 0.6927\n",
      "Epoch 366/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4523 - accuracy: 0.7778 - val_loss: 0.5554 - val_accuracy: 0.6927\n",
      "Epoch 367/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4522 - accuracy: 0.7760 - val_loss: 0.5554 - val_accuracy: 0.6875\n",
      "Epoch 368/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4520 - accuracy: 0.7778 - val_loss: 0.5554 - val_accuracy: 0.6875\n",
      "Epoch 369/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4520 - accuracy: 0.7795 - val_loss: 0.5554 - val_accuracy: 0.6875\n",
      "Epoch 370/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4518 - accuracy: 0.7778 - val_loss: 0.5554 - val_accuracy: 0.6875\n",
      "Epoch 371/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4517 - accuracy: 0.7778 - val_loss: 0.5554 - val_accuracy: 0.6823\n",
      "Epoch 372/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4516 - accuracy: 0.7778 - val_loss: 0.5554 - val_accuracy: 0.6823\n",
      "Epoch 373/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4515 - accuracy: 0.7795 - val_loss: 0.5554 - val_accuracy: 0.6823\n",
      "Epoch 374/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4514 - accuracy: 0.7795 - val_loss: 0.5554 - val_accuracy: 0.6823\n",
      "Epoch 375/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4513 - accuracy: 0.7795 - val_loss: 0.5554 - val_accuracy: 0.6823\n",
      "Epoch 376/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4512 - accuracy: 0.7795 - val_loss: 0.5554 - val_accuracy: 0.6823\n",
      "Epoch 377/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4511 - accuracy: 0.7795 - val_loss: 0.5554 - val_accuracy: 0.6823\n",
      "Epoch 378/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4510 - accuracy: 0.7812 - val_loss: 0.5554 - val_accuracy: 0.6823\n",
      "Epoch 379/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4509 - accuracy: 0.7830 - val_loss: 0.5554 - val_accuracy: 0.6823\n",
      "Epoch 380/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4507 - accuracy: 0.7812 - val_loss: 0.5554 - val_accuracy: 0.6823\n",
      "Epoch 381/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4506 - accuracy: 0.7830 - val_loss: 0.5554 - val_accuracy: 0.6823\n",
      "Epoch 382/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4506 - accuracy: 0.7830 - val_loss: 0.5554 - val_accuracy: 0.6823\n",
      "Epoch 383/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4504 - accuracy: 0.7830 - val_loss: 0.5554 - val_accuracy: 0.6823\n",
      "Epoch 384/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4504 - accuracy: 0.7830 - val_loss: 0.5554 - val_accuracy: 0.6823\n",
      "Epoch 385/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4503 - accuracy: 0.7830 - val_loss: 0.5554 - val_accuracy: 0.6823\n",
      "Epoch 386/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4502 - accuracy: 0.7847 - val_loss: 0.5554 - val_accuracy: 0.6823\n",
      "Epoch 387/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4500 - accuracy: 0.7830 - val_loss: 0.5554 - val_accuracy: 0.6823\n",
      "Epoch 388/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4500 - accuracy: 0.7830 - val_loss: 0.5554 - val_accuracy: 0.6823\n",
      "Epoch 389/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4499 - accuracy: 0.7830 - val_loss: 0.5554 - val_accuracy: 0.6823\n",
      "Epoch 390/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4498 - accuracy: 0.7847 - val_loss: 0.5554 - val_accuracy: 0.6823\n",
      "Epoch 391/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4497 - accuracy: 0.7847 - val_loss: 0.5554 - val_accuracy: 0.6823\n",
      "Epoch 392/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4496 - accuracy: 0.7830 - val_loss: 0.5554 - val_accuracy: 0.6823\n",
      "Epoch 393/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4495 - accuracy: 0.7830 - val_loss: 0.5554 - val_accuracy: 0.6823\n",
      "Epoch 394/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4494 - accuracy: 0.7847 - val_loss: 0.5554 - val_accuracy: 0.6823\n",
      "Epoch 395/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4493 - accuracy: 0.7830 - val_loss: 0.5554 - val_accuracy: 0.6823\n",
      "Epoch 396/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4493 - accuracy: 0.7830 - val_loss: 0.5554 - val_accuracy: 0.6823\n",
      "Epoch 397/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4492 - accuracy: 0.7847 - val_loss: 0.5554 - val_accuracy: 0.6823\n",
      "Epoch 398/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4490 - accuracy: 0.7865 - val_loss: 0.5554 - val_accuracy: 0.6823\n",
      "Epoch 399/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4490 - accuracy: 0.7847 - val_loss: 0.5554 - val_accuracy: 0.6771\n",
      "Epoch 400/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4489 - accuracy: 0.7847 - val_loss: 0.5554 - val_accuracy: 0.6771\n",
      "Epoch 401/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4488 - accuracy: 0.7865 - val_loss: 0.5553 - val_accuracy: 0.6771\n",
      "Epoch 402/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4487 - accuracy: 0.7847 - val_loss: 0.5554 - val_accuracy: 0.6719\n",
      "Epoch 403/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4486 - accuracy: 0.7847 - val_loss: 0.5554 - val_accuracy: 0.6719\n",
      "Epoch 404/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4485 - accuracy: 0.7865 - val_loss: 0.5554 - val_accuracy: 0.6719\n",
      "Epoch 405/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4484 - accuracy: 0.7847 - val_loss: 0.5553 - val_accuracy: 0.6719\n",
      "Epoch 406/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4483 - accuracy: 0.7847 - val_loss: 0.5553 - val_accuracy: 0.6719\n",
      "Epoch 407/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4483 - accuracy: 0.7847 - val_loss: 0.5553 - val_accuracy: 0.6719\n",
      "Epoch 408/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4481 - accuracy: 0.7847 - val_loss: 0.5553 - val_accuracy: 0.6719\n",
      "Epoch 409/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4480 - accuracy: 0.7865 - val_loss: 0.5553 - val_accuracy: 0.6719\n",
      "Epoch 410/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4479 - accuracy: 0.7865 - val_loss: 0.5553 - val_accuracy: 0.6719\n",
      "Epoch 411/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4478 - accuracy: 0.7847 - val_loss: 0.5552 - val_accuracy: 0.6719\n",
      "Epoch 412/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4478 - accuracy: 0.7865 - val_loss: 0.5552 - val_accuracy: 0.6719\n",
      "Epoch 413/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4476 - accuracy: 0.7865 - val_loss: 0.5552 - val_accuracy: 0.6719\n",
      "Epoch 414/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4476 - accuracy: 0.7865 - val_loss: 0.5552 - val_accuracy: 0.6719\n",
      "Epoch 415/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4475 - accuracy: 0.7847 - val_loss: 0.5552 - val_accuracy: 0.6719\n",
      "Epoch 416/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4474 - accuracy: 0.7847 - val_loss: 0.5552 - val_accuracy: 0.6719\n",
      "Epoch 417/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4473 - accuracy: 0.7847 - val_loss: 0.5552 - val_accuracy: 0.6719\n",
      "Epoch 418/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4472 - accuracy: 0.7847 - val_loss: 0.5552 - val_accuracy: 0.6719\n",
      "Epoch 419/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4471 - accuracy: 0.7847 - val_loss: 0.5553 - val_accuracy: 0.6719\n",
      "Epoch 420/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4470 - accuracy: 0.7847 - val_loss: 0.5552 - val_accuracy: 0.6771\n",
      "Epoch 421/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4469 - accuracy: 0.7830 - val_loss: 0.5552 - val_accuracy: 0.6771\n",
      "Epoch 422/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4469 - accuracy: 0.7847 - val_loss: 0.5553 - val_accuracy: 0.6771\n",
      "Epoch 423/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4468 - accuracy: 0.7847 - val_loss: 0.5553 - val_accuracy: 0.6771\n",
      "Epoch 424/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4466 - accuracy: 0.7847 - val_loss: 0.5553 - val_accuracy: 0.6771\n",
      "Epoch 425/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4466 - accuracy: 0.7847 - val_loss: 0.5553 - val_accuracy: 0.6771\n",
      "Epoch 426/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4465 - accuracy: 0.7847 - val_loss: 0.5553 - val_accuracy: 0.6771\n",
      "Epoch 427/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4464 - accuracy: 0.7830 - val_loss: 0.5553 - val_accuracy: 0.6771\n",
      "Epoch 428/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4463 - accuracy: 0.7830 - val_loss: 0.5553 - val_accuracy: 0.6823\n",
      "Epoch 429/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4462 - accuracy: 0.7847 - val_loss: 0.5554 - val_accuracy: 0.6823\n",
      "Epoch 430/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4461 - accuracy: 0.7830 - val_loss: 0.5554 - val_accuracy: 0.6823\n",
      "Epoch 431/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4460 - accuracy: 0.7830 - val_loss: 0.5554 - val_accuracy: 0.6823\n",
      "Epoch 432/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4460 - accuracy: 0.7830 - val_loss: 0.5554 - val_accuracy: 0.6823\n",
      "Epoch 433/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4459 - accuracy: 0.7830 - val_loss: 0.5554 - val_accuracy: 0.6823\n",
      "Epoch 434/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4458 - accuracy: 0.7830 - val_loss: 0.5555 - val_accuracy: 0.6823\n",
      "Epoch 435/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4457 - accuracy: 0.7847 - val_loss: 0.5555 - val_accuracy: 0.6823\n",
      "Epoch 436/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4456 - accuracy: 0.7830 - val_loss: 0.5555 - val_accuracy: 0.6823\n",
      "Epoch 437/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4455 - accuracy: 0.7830 - val_loss: 0.5555 - val_accuracy: 0.6823\n",
      "Epoch 438/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4454 - accuracy: 0.7830 - val_loss: 0.5555 - val_accuracy: 0.6823\n",
      "Epoch 439/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4453 - accuracy: 0.7830 - val_loss: 0.5555 - val_accuracy: 0.6823\n",
      "Epoch 440/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4453 - accuracy: 0.7830 - val_loss: 0.5555 - val_accuracy: 0.6823\n",
      "Epoch 441/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4452 - accuracy: 0.7830 - val_loss: 0.5556 - val_accuracy: 0.6823\n",
      "Epoch 442/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4452 - accuracy: 0.7830 - val_loss: 0.5556 - val_accuracy: 0.6823\n",
      "Epoch 443/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4450 - accuracy: 0.7830 - val_loss: 0.5556 - val_accuracy: 0.6823\n",
      "Epoch 444/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4450 - accuracy: 0.7830 - val_loss: 0.5556 - val_accuracy: 0.6823\n",
      "Epoch 445/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4449 - accuracy: 0.7830 - val_loss: 0.5556 - val_accuracy: 0.6823\n",
      "Epoch 446/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4448 - accuracy: 0.7830 - val_loss: 0.5556 - val_accuracy: 0.6823\n",
      "Epoch 447/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4448 - accuracy: 0.7830 - val_loss: 0.5556 - val_accuracy: 0.6823\n",
      "Epoch 448/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4446 - accuracy: 0.7830 - val_loss: 0.5556 - val_accuracy: 0.6823\n",
      "Epoch 449/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4445 - accuracy: 0.7830 - val_loss: 0.5556 - val_accuracy: 0.6823\n",
      "Epoch 450/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4444 - accuracy: 0.7830 - val_loss: 0.5556 - val_accuracy: 0.6823\n",
      "Epoch 451/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4444 - accuracy: 0.7830 - val_loss: 0.5556 - val_accuracy: 0.6823\n",
      "Epoch 452/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4443 - accuracy: 0.7830 - val_loss: 0.5556 - val_accuracy: 0.6823\n",
      "Epoch 453/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4442 - accuracy: 0.7830 - val_loss: 0.5556 - val_accuracy: 0.6823\n",
      "Epoch 454/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4441 - accuracy: 0.7830 - val_loss: 0.5556 - val_accuracy: 0.6823\n",
      "Epoch 455/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4440 - accuracy: 0.7812 - val_loss: 0.5556 - val_accuracy: 0.6823\n",
      "Epoch 456/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4440 - accuracy: 0.7812 - val_loss: 0.5556 - val_accuracy: 0.6823\n",
      "Epoch 457/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4439 - accuracy: 0.7812 - val_loss: 0.5556 - val_accuracy: 0.6823\n",
      "Epoch 458/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4438 - accuracy: 0.7812 - val_loss: 0.5556 - val_accuracy: 0.6823\n",
      "Epoch 459/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4437 - accuracy: 0.7812 - val_loss: 0.5556 - val_accuracy: 0.6823\n",
      "Epoch 460/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4436 - accuracy: 0.7812 - val_loss: 0.5556 - val_accuracy: 0.6823\n",
      "Epoch 461/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4436 - accuracy: 0.7812 - val_loss: 0.5556 - val_accuracy: 0.6823\n",
      "Epoch 462/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4434 - accuracy: 0.7812 - val_loss: 0.5556 - val_accuracy: 0.6823\n",
      "Epoch 463/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4434 - accuracy: 0.7812 - val_loss: 0.5556 - val_accuracy: 0.6823\n",
      "Epoch 464/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4433 - accuracy: 0.7812 - val_loss: 0.5556 - val_accuracy: 0.6823\n",
      "Epoch 465/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4432 - accuracy: 0.7812 - val_loss: 0.5555 - val_accuracy: 0.6823\n",
      "Epoch 466/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4431 - accuracy: 0.7812 - val_loss: 0.5556 - val_accuracy: 0.6823\n",
      "Epoch 467/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4431 - accuracy: 0.7812 - val_loss: 0.5556 - val_accuracy: 0.6823\n",
      "Epoch 468/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4430 - accuracy: 0.7812 - val_loss: 0.5556 - val_accuracy: 0.6823\n",
      "Epoch 469/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4429 - accuracy: 0.7812 - val_loss: 0.5556 - val_accuracy: 0.6823\n",
      "Epoch 470/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4428 - accuracy: 0.7812 - val_loss: 0.5556 - val_accuracy: 0.6823\n",
      "Epoch 471/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4428 - accuracy: 0.7812 - val_loss: 0.5556 - val_accuracy: 0.6823\n",
      "Epoch 472/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4427 - accuracy: 0.7795 - val_loss: 0.5556 - val_accuracy: 0.6823\n",
      "Epoch 473/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4426 - accuracy: 0.7812 - val_loss: 0.5556 - val_accuracy: 0.6823\n",
      "Epoch 474/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4425 - accuracy: 0.7812 - val_loss: 0.5556 - val_accuracy: 0.6823\n",
      "Epoch 475/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4424 - accuracy: 0.7812 - val_loss: 0.5556 - val_accuracy: 0.6823\n",
      "Epoch 476/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4424 - accuracy: 0.7795 - val_loss: 0.5556 - val_accuracy: 0.6823\n",
      "Epoch 477/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4423 - accuracy: 0.7812 - val_loss: 0.5555 - val_accuracy: 0.6823\n",
      "Epoch 478/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4422 - accuracy: 0.7812 - val_loss: 0.5556 - val_accuracy: 0.6823\n",
      "Epoch 479/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4421 - accuracy: 0.7812 - val_loss: 0.5556 - val_accuracy: 0.6823\n",
      "Epoch 480/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4420 - accuracy: 0.7812 - val_loss: 0.5556 - val_accuracy: 0.6823\n",
      "Epoch 481/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4420 - accuracy: 0.7812 - val_loss: 0.5556 - val_accuracy: 0.6823\n",
      "Epoch 482/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4419 - accuracy: 0.7812 - val_loss: 0.5556 - val_accuracy: 0.6823\n",
      "Epoch 483/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4418 - accuracy: 0.7812 - val_loss: 0.5556 - val_accuracy: 0.6823\n",
      "Epoch 484/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4418 - accuracy: 0.7830 - val_loss: 0.5556 - val_accuracy: 0.6823\n",
      "Epoch 485/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4417 - accuracy: 0.7830 - val_loss: 0.5556 - val_accuracy: 0.6823\n",
      "Epoch 486/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4416 - accuracy: 0.7830 - val_loss: 0.5556 - val_accuracy: 0.6823\n",
      "Epoch 487/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4415 - accuracy: 0.7812 - val_loss: 0.5556 - val_accuracy: 0.6823\n",
      "Epoch 488/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4415 - accuracy: 0.7830 - val_loss: 0.5556 - val_accuracy: 0.6823\n",
      "Epoch 489/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4414 - accuracy: 0.7830 - val_loss: 0.5557 - val_accuracy: 0.6823\n",
      "Epoch 490/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4413 - accuracy: 0.7812 - val_loss: 0.5557 - val_accuracy: 0.6823\n",
      "Epoch 491/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4412 - accuracy: 0.7812 - val_loss: 0.5557 - val_accuracy: 0.6823\n",
      "Epoch 492/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4412 - accuracy: 0.7830 - val_loss: 0.5557 - val_accuracy: 0.6823\n",
      "Epoch 493/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4411 - accuracy: 0.7812 - val_loss: 0.5557 - val_accuracy: 0.6823\n",
      "Epoch 494/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4410 - accuracy: 0.7812 - val_loss: 0.5557 - val_accuracy: 0.6823\n",
      "Epoch 495/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4409 - accuracy: 0.7812 - val_loss: 0.5557 - val_accuracy: 0.6823\n",
      "Epoch 496/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4408 - accuracy: 0.7812 - val_loss: 0.5557 - val_accuracy: 0.6823\n",
      "Epoch 497/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4408 - accuracy: 0.7812 - val_loss: 0.5557 - val_accuracy: 0.6823\n",
      "Epoch 498/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4407 - accuracy: 0.7812 - val_loss: 0.5557 - val_accuracy: 0.6823\n",
      "Epoch 499/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4406 - accuracy: 0.7812 - val_loss: 0.5557 - val_accuracy: 0.6823\n",
      "Epoch 500/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4405 - accuracy: 0.7812 - val_loss: 0.5557 - val_accuracy: 0.6823\n",
      "Epoch 501/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4405 - accuracy: 0.7812 - val_loss: 0.5557 - val_accuracy: 0.6823\n",
      "Epoch 502/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4404 - accuracy: 0.7812 - val_loss: 0.5557 - val_accuracy: 0.6823\n",
      "Epoch 503/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4404 - accuracy: 0.7812 - val_loss: 0.5557 - val_accuracy: 0.6823\n",
      "Epoch 504/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4403 - accuracy: 0.7812 - val_loss: 0.5557 - val_accuracy: 0.6823\n",
      "Epoch 505/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4402 - accuracy: 0.7812 - val_loss: 0.5557 - val_accuracy: 0.6823\n",
      "Epoch 506/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4402 - accuracy: 0.7812 - val_loss: 0.5557 - val_accuracy: 0.6823\n",
      "Epoch 507/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4401 - accuracy: 0.7812 - val_loss: 0.5557 - val_accuracy: 0.6823\n",
      "Epoch 508/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4400 - accuracy: 0.7812 - val_loss: 0.5557 - val_accuracy: 0.6823\n",
      "Epoch 509/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4399 - accuracy: 0.7812 - val_loss: 0.5557 - val_accuracy: 0.6823\n",
      "Epoch 510/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4399 - accuracy: 0.7812 - val_loss: 0.5556 - val_accuracy: 0.6823\n",
      "Epoch 511/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4398 - accuracy: 0.7812 - val_loss: 0.5556 - val_accuracy: 0.6823\n",
      "Epoch 512/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4397 - accuracy: 0.7812 - val_loss: 0.5556 - val_accuracy: 0.6823\n",
      "Epoch 513/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4397 - accuracy: 0.7812 - val_loss: 0.5556 - val_accuracy: 0.6823\n",
      "Epoch 514/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4396 - accuracy: 0.7812 - val_loss: 0.5557 - val_accuracy: 0.6823\n",
      "Epoch 515/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4395 - accuracy: 0.7812 - val_loss: 0.5557 - val_accuracy: 0.6823\n",
      "Epoch 516/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4394 - accuracy: 0.7812 - val_loss: 0.5557 - val_accuracy: 0.6823\n",
      "Epoch 517/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4394 - accuracy: 0.7812 - val_loss: 0.5557 - val_accuracy: 0.6823\n",
      "Epoch 518/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4393 - accuracy: 0.7830 - val_loss: 0.5557 - val_accuracy: 0.6823\n",
      "Epoch 519/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4392 - accuracy: 0.7812 - val_loss: 0.5557 - val_accuracy: 0.6823\n",
      "Epoch 520/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4392 - accuracy: 0.7812 - val_loss: 0.5557 - val_accuracy: 0.6823\n",
      "Epoch 521/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4391 - accuracy: 0.7795 - val_loss: 0.5557 - val_accuracy: 0.6823\n",
      "Epoch 522/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4390 - accuracy: 0.7812 - val_loss: 0.5558 - val_accuracy: 0.6823\n",
      "Epoch 523/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4390 - accuracy: 0.7795 - val_loss: 0.5558 - val_accuracy: 0.6823\n",
      "Epoch 524/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4389 - accuracy: 0.7795 - val_loss: 0.5558 - val_accuracy: 0.6823\n",
      "Epoch 525/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4388 - accuracy: 0.7795 - val_loss: 0.5558 - val_accuracy: 0.6823\n",
      "Epoch 526/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4388 - accuracy: 0.7830 - val_loss: 0.5558 - val_accuracy: 0.6823\n",
      "Epoch 527/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4387 - accuracy: 0.7795 - val_loss: 0.5558 - val_accuracy: 0.6823\n",
      "Epoch 528/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4386 - accuracy: 0.7830 - val_loss: 0.5559 - val_accuracy: 0.6823\n",
      "Epoch 529/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4386 - accuracy: 0.7830 - val_loss: 0.5559 - val_accuracy: 0.6823\n",
      "Epoch 530/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4385 - accuracy: 0.7830 - val_loss: 0.5559 - val_accuracy: 0.6823\n",
      "Epoch 531/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4384 - accuracy: 0.7847 - val_loss: 0.5559 - val_accuracy: 0.6823\n",
      "Epoch 532/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4384 - accuracy: 0.7830 - val_loss: 0.5560 - val_accuracy: 0.6823\n",
      "Epoch 533/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4384 - accuracy: 0.7847 - val_loss: 0.5560 - val_accuracy: 0.6823\n",
      "Epoch 534/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4382 - accuracy: 0.7847 - val_loss: 0.5560 - val_accuracy: 0.6823\n",
      "Epoch 535/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4381 - accuracy: 0.7847 - val_loss: 0.5560 - val_accuracy: 0.6823\n",
      "Epoch 536/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4381 - accuracy: 0.7847 - val_loss: 0.5561 - val_accuracy: 0.6823\n",
      "Epoch 537/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4381 - accuracy: 0.7847 - val_loss: 0.5561 - val_accuracy: 0.6823\n",
      "Epoch 538/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4380 - accuracy: 0.7847 - val_loss: 0.5561 - val_accuracy: 0.6823\n",
      "Epoch 539/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4379 - accuracy: 0.7847 - val_loss: 0.5561 - val_accuracy: 0.6823\n",
      "Epoch 540/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4379 - accuracy: 0.7847 - val_loss: 0.5562 - val_accuracy: 0.6823\n",
      "Epoch 541/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4378 - accuracy: 0.7847 - val_loss: 0.5562 - val_accuracy: 0.6823\n",
      "Epoch 542/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4377 - accuracy: 0.7830 - val_loss: 0.5561 - val_accuracy: 0.6823\n",
      "Epoch 543/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4377 - accuracy: 0.7830 - val_loss: 0.5562 - val_accuracy: 0.6823\n",
      "Epoch 544/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4377 - accuracy: 0.7830 - val_loss: 0.5562 - val_accuracy: 0.6823\n",
      "Epoch 545/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4376 - accuracy: 0.7830 - val_loss: 0.5562 - val_accuracy: 0.6823\n",
      "Epoch 546/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4375 - accuracy: 0.7830 - val_loss: 0.5562 - val_accuracy: 0.6823\n",
      "Epoch 547/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4375 - accuracy: 0.7830 - val_loss: 0.5562 - val_accuracy: 0.6823\n",
      "Epoch 548/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4374 - accuracy: 0.7830 - val_loss: 0.5562 - val_accuracy: 0.6823\n",
      "Epoch 549/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4374 - accuracy: 0.7812 - val_loss: 0.5562 - val_accuracy: 0.6823\n",
      "Epoch 550/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4373 - accuracy: 0.7812 - val_loss: 0.5562 - val_accuracy: 0.6823\n",
      "Epoch 551/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4372 - accuracy: 0.7812 - val_loss: 0.5562 - val_accuracy: 0.6823\n",
      "Epoch 552/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.7812 - val_loss: 0.5563 - val_accuracy: 0.6823\n",
      "Epoch 553/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.7795 - val_loss: 0.5562 - val_accuracy: 0.6823\n",
      "Epoch 554/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4370 - accuracy: 0.7812 - val_loss: 0.5562 - val_accuracy: 0.6823\n",
      "Epoch 555/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4370 - accuracy: 0.7812 - val_loss: 0.5562 - val_accuracy: 0.6823\n",
      "Epoch 556/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4369 - accuracy: 0.7812 - val_loss: 0.5562 - val_accuracy: 0.6823\n",
      "Epoch 557/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4369 - accuracy: 0.7812 - val_loss: 0.5563 - val_accuracy: 0.6823\n",
      "Epoch 558/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4368 - accuracy: 0.7795 - val_loss: 0.5563 - val_accuracy: 0.6823\n",
      "Epoch 559/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4368 - accuracy: 0.7795 - val_loss: 0.5563 - val_accuracy: 0.6823\n",
      "Epoch 560/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4367 - accuracy: 0.7795 - val_loss: 0.5563 - val_accuracy: 0.6823\n",
      "Epoch 561/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4367 - accuracy: 0.7795 - val_loss: 0.5563 - val_accuracy: 0.6823\n",
      "Epoch 562/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4366 - accuracy: 0.7830 - val_loss: 0.5564 - val_accuracy: 0.6823\n",
      "Epoch 563/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4365 - accuracy: 0.7795 - val_loss: 0.5564 - val_accuracy: 0.6823\n",
      "Epoch 564/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4365 - accuracy: 0.7795 - val_loss: 0.5564 - val_accuracy: 0.6823\n",
      "Epoch 565/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4364 - accuracy: 0.7795 - val_loss: 0.5564 - val_accuracy: 0.6823\n",
      "Epoch 566/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4364 - accuracy: 0.7812 - val_loss: 0.5564 - val_accuracy: 0.6823\n",
      "Epoch 567/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4363 - accuracy: 0.7795 - val_loss: 0.5565 - val_accuracy: 0.6823\n",
      "Epoch 568/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4362 - accuracy: 0.7812 - val_loss: 0.5565 - val_accuracy: 0.6823\n",
      "Epoch 569/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4362 - accuracy: 0.7812 - val_loss: 0.5565 - val_accuracy: 0.6823\n",
      "Epoch 570/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4362 - accuracy: 0.7812 - val_loss: 0.5565 - val_accuracy: 0.6823\n",
      "Epoch 571/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4361 - accuracy: 0.7812 - val_loss: 0.5566 - val_accuracy: 0.6823\n",
      "Epoch 572/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4361 - accuracy: 0.7795 - val_loss: 0.5566 - val_accuracy: 0.6823\n",
      "Epoch 573/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4360 - accuracy: 0.7795 - val_loss: 0.5566 - val_accuracy: 0.6823\n",
      "Epoch 574/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4360 - accuracy: 0.7812 - val_loss: 0.5566 - val_accuracy: 0.6823\n",
      "Epoch 575/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4359 - accuracy: 0.7812 - val_loss: 0.5566 - val_accuracy: 0.6823\n",
      "Epoch 576/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4359 - accuracy: 0.7812 - val_loss: 0.5567 - val_accuracy: 0.6823\n",
      "Epoch 577/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4358 - accuracy: 0.7812 - val_loss: 0.5567 - val_accuracy: 0.6823\n",
      "Epoch 578/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4357 - accuracy: 0.7812 - val_loss: 0.5567 - val_accuracy: 0.6823\n",
      "Epoch 579/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4357 - accuracy: 0.7812 - val_loss: 0.5567 - val_accuracy: 0.6823\n",
      "Epoch 580/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4356 - accuracy: 0.7812 - val_loss: 0.5568 - val_accuracy: 0.6823\n",
      "Epoch 581/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4356 - accuracy: 0.7812 - val_loss: 0.5568 - val_accuracy: 0.6823\n",
      "Epoch 582/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4355 - accuracy: 0.7812 - val_loss: 0.5568 - val_accuracy: 0.6823\n",
      "Epoch 583/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4355 - accuracy: 0.7812 - val_loss: 0.5568 - val_accuracy: 0.6823\n",
      "Epoch 584/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4354 - accuracy: 0.7812 - val_loss: 0.5569 - val_accuracy: 0.6823\n",
      "Epoch 585/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4354 - accuracy: 0.7812 - val_loss: 0.5569 - val_accuracy: 0.6823\n",
      "Epoch 586/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4353 - accuracy: 0.7812 - val_loss: 0.5569 - val_accuracy: 0.6823\n",
      "Epoch 587/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4352 - accuracy: 0.7812 - val_loss: 0.5569 - val_accuracy: 0.6823\n",
      "Epoch 588/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4352 - accuracy: 0.7812 - val_loss: 0.5569 - val_accuracy: 0.6823\n",
      "Epoch 589/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4351 - accuracy: 0.7812 - val_loss: 0.5570 - val_accuracy: 0.6823\n",
      "Epoch 590/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4351 - accuracy: 0.7812 - val_loss: 0.5570 - val_accuracy: 0.6823\n",
      "Epoch 591/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4351 - accuracy: 0.7812 - val_loss: 0.5570 - val_accuracy: 0.6823\n",
      "Epoch 592/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4350 - accuracy: 0.7812 - val_loss: 0.5571 - val_accuracy: 0.6823\n",
      "Epoch 593/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4350 - accuracy: 0.7812 - val_loss: 0.5571 - val_accuracy: 0.6823\n",
      "Epoch 594/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4349 - accuracy: 0.7812 - val_loss: 0.5571 - val_accuracy: 0.6823\n",
      "Epoch 595/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4349 - accuracy: 0.7812 - val_loss: 0.5571 - val_accuracy: 0.6875\n",
      "Epoch 596/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4348 - accuracy: 0.7812 - val_loss: 0.5572 - val_accuracy: 0.6875\n",
      "Epoch 597/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4348 - accuracy: 0.7812 - val_loss: 0.5572 - val_accuracy: 0.6875\n",
      "Epoch 598/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4347 - accuracy: 0.7812 - val_loss: 0.5572 - val_accuracy: 0.6875\n",
      "Epoch 599/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4347 - accuracy: 0.7812 - val_loss: 0.5572 - val_accuracy: 0.6875\n",
      "Epoch 600/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4346 - accuracy: 0.7812 - val_loss: 0.5573 - val_accuracy: 0.6875\n",
      "Epoch 601/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4346 - accuracy: 0.7830 - val_loss: 0.5573 - val_accuracy: 0.6875\n",
      "Epoch 602/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4346 - accuracy: 0.7812 - val_loss: 0.5573 - val_accuracy: 0.6875\n",
      "Epoch 603/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4345 - accuracy: 0.7830 - val_loss: 0.5574 - val_accuracy: 0.6875\n",
      "Epoch 604/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4345 - accuracy: 0.7830 - val_loss: 0.5574 - val_accuracy: 0.6875\n",
      "Epoch 605/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4344 - accuracy: 0.7830 - val_loss: 0.5575 - val_accuracy: 0.6875\n",
      "Epoch 606/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4344 - accuracy: 0.7830 - val_loss: 0.5575 - val_accuracy: 0.6875\n",
      "Epoch 607/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4343 - accuracy: 0.7830 - val_loss: 0.5575 - val_accuracy: 0.6875\n",
      "Epoch 608/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4342 - accuracy: 0.7830 - val_loss: 0.5576 - val_accuracy: 0.6875\n",
      "Epoch 609/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4342 - accuracy: 0.7830 - val_loss: 0.5576 - val_accuracy: 0.6875\n",
      "Epoch 610/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4341 - accuracy: 0.7830 - val_loss: 0.5577 - val_accuracy: 0.6875\n",
      "Epoch 611/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4341 - accuracy: 0.7830 - val_loss: 0.5577 - val_accuracy: 0.6875\n",
      "Epoch 612/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4341 - accuracy: 0.7830 - val_loss: 0.5578 - val_accuracy: 0.6875\n",
      "Epoch 613/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4340 - accuracy: 0.7847 - val_loss: 0.5578 - val_accuracy: 0.6875\n",
      "Epoch 614/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4340 - accuracy: 0.7830 - val_loss: 0.5578 - val_accuracy: 0.6875\n",
      "Epoch 615/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4339 - accuracy: 0.7830 - val_loss: 0.5579 - val_accuracy: 0.6875\n",
      "Epoch 616/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4339 - accuracy: 0.7847 - val_loss: 0.5579 - val_accuracy: 0.6875\n",
      "Epoch 617/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4339 - accuracy: 0.7830 - val_loss: 0.5580 - val_accuracy: 0.6875\n",
      "Epoch 618/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4338 - accuracy: 0.7830 - val_loss: 0.5580 - val_accuracy: 0.6875\n",
      "Epoch 619/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4337 - accuracy: 0.7830 - val_loss: 0.5581 - val_accuracy: 0.6875\n",
      "Epoch 620/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4337 - accuracy: 0.7847 - val_loss: 0.5581 - val_accuracy: 0.6927\n",
      "Epoch 621/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4336 - accuracy: 0.7830 - val_loss: 0.5582 - val_accuracy: 0.6927\n",
      "Epoch 622/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4336 - accuracy: 0.7847 - val_loss: 0.5582 - val_accuracy: 0.6927\n",
      "Epoch 623/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4335 - accuracy: 0.7847 - val_loss: 0.5582 - val_accuracy: 0.6927\n",
      "Epoch 624/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4335 - accuracy: 0.7830 - val_loss: 0.5582 - val_accuracy: 0.6927\n",
      "Epoch 625/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4335 - accuracy: 0.7847 - val_loss: 0.5583 - val_accuracy: 0.6927\n",
      "Epoch 626/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4334 - accuracy: 0.7830 - val_loss: 0.5583 - val_accuracy: 0.6927\n",
      "Epoch 627/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4334 - accuracy: 0.7830 - val_loss: 0.5583 - val_accuracy: 0.6927\n",
      "Epoch 628/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4334 - accuracy: 0.7847 - val_loss: 0.5584 - val_accuracy: 0.6927\n",
      "Epoch 629/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4333 - accuracy: 0.7830 - val_loss: 0.5584 - val_accuracy: 0.6927\n",
      "Epoch 630/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4333 - accuracy: 0.7830 - val_loss: 0.5584 - val_accuracy: 0.6927\n",
      "Epoch 631/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4333 - accuracy: 0.7830 - val_loss: 0.5584 - val_accuracy: 0.6927\n",
      "Epoch 632/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4332 - accuracy: 0.7847 - val_loss: 0.5585 - val_accuracy: 0.6927\n",
      "Epoch 633/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4332 - accuracy: 0.7830 - val_loss: 0.5585 - val_accuracy: 0.6927\n",
      "Epoch 634/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4331 - accuracy: 0.7830 - val_loss: 0.5585 - val_accuracy: 0.6927\n",
      "Epoch 635/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4331 - accuracy: 0.7830 - val_loss: 0.5586 - val_accuracy: 0.6927\n",
      "Epoch 636/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4330 - accuracy: 0.7847 - val_loss: 0.5586 - val_accuracy: 0.6927\n",
      "Epoch 637/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4330 - accuracy: 0.7847 - val_loss: 0.5586 - val_accuracy: 0.6927\n",
      "Epoch 638/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4330 - accuracy: 0.7847 - val_loss: 0.5586 - val_accuracy: 0.6927\n",
      "Epoch 639/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4330 - accuracy: 0.7830 - val_loss: 0.5587 - val_accuracy: 0.6927\n",
      "Epoch 640/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4329 - accuracy: 0.7847 - val_loss: 0.5587 - val_accuracy: 0.6927\n",
      "Epoch 641/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4328 - accuracy: 0.7830 - val_loss: 0.5587 - val_accuracy: 0.6927\n",
      "Epoch 642/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4328 - accuracy: 0.7847 - val_loss: 0.5587 - val_accuracy: 0.6927\n",
      "Epoch 643/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4328 - accuracy: 0.7847 - val_loss: 0.5587 - val_accuracy: 0.6927\n",
      "Epoch 644/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4328 - accuracy: 0.7847 - val_loss: 0.5588 - val_accuracy: 0.6927\n",
      "Epoch 645/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.7847 - val_loss: 0.5588 - val_accuracy: 0.6927\n",
      "Epoch 646/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4326 - accuracy: 0.7847 - val_loss: 0.5588 - val_accuracy: 0.6927\n",
      "Epoch 647/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.7847 - val_loss: 0.5589 - val_accuracy: 0.6927\n",
      "Epoch 648/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4326 - accuracy: 0.7847 - val_loss: 0.5589 - val_accuracy: 0.6927\n",
      "Epoch 649/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4326 - accuracy: 0.7847 - val_loss: 0.5590 - val_accuracy: 0.6927\n",
      "Epoch 650/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4325 - accuracy: 0.7847 - val_loss: 0.5590 - val_accuracy: 0.6927\n",
      "Epoch 651/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4325 - accuracy: 0.7847 - val_loss: 0.5590 - val_accuracy: 0.6927\n",
      "Epoch 652/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4324 - accuracy: 0.7847 - val_loss: 0.5590 - val_accuracy: 0.6927\n",
      "Epoch 653/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4324 - accuracy: 0.7847 - val_loss: 0.5590 - val_accuracy: 0.6927\n",
      "Epoch 654/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4324 - accuracy: 0.7847 - val_loss: 0.5591 - val_accuracy: 0.6927\n",
      "Epoch 655/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4323 - accuracy: 0.7847 - val_loss: 0.5591 - val_accuracy: 0.6927\n",
      "Epoch 656/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4323 - accuracy: 0.7847 - val_loss: 0.5591 - val_accuracy: 0.6927\n",
      "Epoch 657/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4322 - accuracy: 0.7847 - val_loss: 0.5592 - val_accuracy: 0.6927\n",
      "Epoch 658/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4322 - accuracy: 0.7847 - val_loss: 0.5592 - val_accuracy: 0.6927\n",
      "Epoch 659/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4322 - accuracy: 0.7847 - val_loss: 0.5592 - val_accuracy: 0.6927\n",
      "Epoch 660/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4321 - accuracy: 0.7847 - val_loss: 0.5592 - val_accuracy: 0.6927\n",
      "Epoch 661/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4321 - accuracy: 0.7847 - val_loss: 0.5593 - val_accuracy: 0.6927\n",
      "Epoch 662/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4321 - accuracy: 0.7847 - val_loss: 0.5593 - val_accuracy: 0.6927\n",
      "Epoch 663/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4321 - accuracy: 0.7847 - val_loss: 0.5593 - val_accuracy: 0.6927\n",
      "Epoch 664/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4320 - accuracy: 0.7847 - val_loss: 0.5593 - val_accuracy: 0.6927\n",
      "Epoch 665/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4320 - accuracy: 0.7847 - val_loss: 0.5594 - val_accuracy: 0.6927\n",
      "Epoch 666/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4319 - accuracy: 0.7847 - val_loss: 0.5594 - val_accuracy: 0.6927\n",
      "Epoch 667/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4319 - accuracy: 0.7847 - val_loss: 0.5594 - val_accuracy: 0.6927\n",
      "Epoch 668/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4319 - accuracy: 0.7847 - val_loss: 0.5595 - val_accuracy: 0.6927\n",
      "Epoch 669/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4318 - accuracy: 0.7847 - val_loss: 0.5595 - val_accuracy: 0.6927\n",
      "Epoch 670/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4318 - accuracy: 0.7847 - val_loss: 0.5596 - val_accuracy: 0.6927\n",
      "Epoch 671/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4318 - accuracy: 0.7847 - val_loss: 0.5596 - val_accuracy: 0.6927\n",
      "Epoch 672/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4317 - accuracy: 0.7847 - val_loss: 0.5597 - val_accuracy: 0.6927\n",
      "Epoch 673/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4317 - accuracy: 0.7847 - val_loss: 0.5597 - val_accuracy: 0.6927\n",
      "Epoch 674/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4317 - accuracy: 0.7847 - val_loss: 0.5597 - val_accuracy: 0.6927\n",
      "Epoch 675/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4316 - accuracy: 0.7847 - val_loss: 0.5598 - val_accuracy: 0.6927\n",
      "Epoch 676/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4315 - accuracy: 0.7847 - val_loss: 0.5598 - val_accuracy: 0.6927\n",
      "Epoch 677/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4315 - accuracy: 0.7847 - val_loss: 0.5598 - val_accuracy: 0.6927\n",
      "Epoch 678/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4315 - accuracy: 0.7847 - val_loss: 0.5599 - val_accuracy: 0.6927\n",
      "Epoch 679/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4315 - accuracy: 0.7847 - val_loss: 0.5599 - val_accuracy: 0.6927\n",
      "Epoch 680/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4314 - accuracy: 0.7847 - val_loss: 0.5599 - val_accuracy: 0.6927\n",
      "Epoch 681/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4314 - accuracy: 0.7847 - val_loss: 0.5600 - val_accuracy: 0.6927\n",
      "Epoch 682/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4313 - accuracy: 0.7847 - val_loss: 0.5601 - val_accuracy: 0.6927\n",
      "Epoch 683/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4313 - accuracy: 0.7847 - val_loss: 0.5601 - val_accuracy: 0.6927\n",
      "Epoch 684/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4312 - accuracy: 0.7847 - val_loss: 0.5602 - val_accuracy: 0.6927\n",
      "Epoch 685/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4312 - accuracy: 0.7847 - val_loss: 0.5602 - val_accuracy: 0.6927\n",
      "Epoch 686/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4312 - accuracy: 0.7847 - val_loss: 0.5603 - val_accuracy: 0.6927\n",
      "Epoch 687/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4312 - accuracy: 0.7847 - val_loss: 0.5603 - val_accuracy: 0.6927\n",
      "Epoch 688/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4311 - accuracy: 0.7847 - val_loss: 0.5603 - val_accuracy: 0.6927\n",
      "Epoch 689/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4311 - accuracy: 0.7847 - val_loss: 0.5604 - val_accuracy: 0.6927\n",
      "Epoch 690/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4310 - accuracy: 0.7847 - val_loss: 0.5605 - val_accuracy: 0.6927\n",
      "Epoch 691/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4310 - accuracy: 0.7847 - val_loss: 0.5605 - val_accuracy: 0.6927\n",
      "Epoch 692/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4310 - accuracy: 0.7847 - val_loss: 0.5606 - val_accuracy: 0.6927\n",
      "Epoch 693/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4310 - accuracy: 0.7847 - val_loss: 0.5606 - val_accuracy: 0.6927\n",
      "Epoch 694/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4309 - accuracy: 0.7847 - val_loss: 0.5606 - val_accuracy: 0.6927\n",
      "Epoch 695/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4309 - accuracy: 0.7847 - val_loss: 0.5607 - val_accuracy: 0.6927\n",
      "Epoch 696/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4308 - accuracy: 0.7847 - val_loss: 0.5607 - val_accuracy: 0.6927\n",
      "Epoch 697/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4308 - accuracy: 0.7847 - val_loss: 0.5608 - val_accuracy: 0.6927\n",
      "Epoch 698/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4308 - accuracy: 0.7847 - val_loss: 0.5608 - val_accuracy: 0.6927\n",
      "Epoch 699/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4307 - accuracy: 0.7847 - val_loss: 0.5609 - val_accuracy: 0.6927\n",
      "Epoch 700/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4307 - accuracy: 0.7847 - val_loss: 0.5609 - val_accuracy: 0.6927\n",
      "Epoch 701/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4307 - accuracy: 0.7847 - val_loss: 0.5610 - val_accuracy: 0.6927\n",
      "Epoch 702/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4306 - accuracy: 0.7847 - val_loss: 0.5610 - val_accuracy: 0.6927\n",
      "Epoch 703/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4306 - accuracy: 0.7847 - val_loss: 0.5610 - val_accuracy: 0.6927\n",
      "Epoch 704/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4306 - accuracy: 0.7847 - val_loss: 0.5611 - val_accuracy: 0.6927\n",
      "Epoch 705/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4305 - accuracy: 0.7847 - val_loss: 0.5612 - val_accuracy: 0.6927\n",
      "Epoch 706/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4305 - accuracy: 0.7847 - val_loss: 0.5612 - val_accuracy: 0.6927\n",
      "Epoch 707/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4304 - accuracy: 0.7847 - val_loss: 0.5613 - val_accuracy: 0.6927\n",
      "Epoch 708/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4304 - accuracy: 0.7865 - val_loss: 0.5613 - val_accuracy: 0.6927\n",
      "Epoch 709/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4304 - accuracy: 0.7847 - val_loss: 0.5613 - val_accuracy: 0.6927\n",
      "Epoch 710/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4303 - accuracy: 0.7847 - val_loss: 0.5614 - val_accuracy: 0.6927\n",
      "Epoch 711/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4303 - accuracy: 0.7847 - val_loss: 0.5614 - val_accuracy: 0.6927\n",
      "Epoch 712/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4303 - accuracy: 0.7847 - val_loss: 0.5614 - val_accuracy: 0.6927\n",
      "Epoch 713/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4302 - accuracy: 0.7847 - val_loss: 0.5614 - val_accuracy: 0.6927\n",
      "Epoch 714/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4302 - accuracy: 0.7847 - val_loss: 0.5615 - val_accuracy: 0.6927\n",
      "Epoch 715/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4301 - accuracy: 0.7847 - val_loss: 0.5615 - val_accuracy: 0.6927\n",
      "Epoch 716/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4301 - accuracy: 0.7847 - val_loss: 0.5616 - val_accuracy: 0.6927\n",
      "Epoch 717/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4301 - accuracy: 0.7847 - val_loss: 0.5616 - val_accuracy: 0.6927\n",
      "Epoch 718/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4300 - accuracy: 0.7847 - val_loss: 0.5616 - val_accuracy: 0.6927\n",
      "Epoch 719/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4300 - accuracy: 0.7847 - val_loss: 0.5616 - val_accuracy: 0.6927\n",
      "Epoch 720/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4300 - accuracy: 0.7847 - val_loss: 0.5616 - val_accuracy: 0.6927\n",
      "Epoch 721/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4299 - accuracy: 0.7847 - val_loss: 0.5616 - val_accuracy: 0.6927\n",
      "Epoch 722/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.7847 - val_loss: 0.5616 - val_accuracy: 0.6927\n",
      "Epoch 723/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.7847 - val_loss: 0.5616 - val_accuracy: 0.6927\n",
      "Epoch 724/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.7847 - val_loss: 0.5617 - val_accuracy: 0.6927\n",
      "Epoch 725/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.7847 - val_loss: 0.5617 - val_accuracy: 0.6927\n",
      "Epoch 726/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4297 - accuracy: 0.7847 - val_loss: 0.5617 - val_accuracy: 0.6927\n",
      "Epoch 727/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4296 - accuracy: 0.7847 - val_loss: 0.5617 - val_accuracy: 0.6927\n",
      "Epoch 728/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4296 - accuracy: 0.7847 - val_loss: 0.5618 - val_accuracy: 0.6927\n",
      "Epoch 729/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4296 - accuracy: 0.7847 - val_loss: 0.5618 - val_accuracy: 0.6927\n",
      "Epoch 730/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4295 - accuracy: 0.7847 - val_loss: 0.5618 - val_accuracy: 0.6927\n",
      "Epoch 731/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4295 - accuracy: 0.7847 - val_loss: 0.5618 - val_accuracy: 0.6927\n",
      "Epoch 732/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4294 - accuracy: 0.7847 - val_loss: 0.5618 - val_accuracy: 0.6927\n",
      "Epoch 733/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4294 - accuracy: 0.7865 - val_loss: 0.5619 - val_accuracy: 0.6927\n",
      "Epoch 734/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4294 - accuracy: 0.7847 - val_loss: 0.5619 - val_accuracy: 0.6927\n",
      "Epoch 735/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4294 - accuracy: 0.7865 - val_loss: 0.5619 - val_accuracy: 0.6927\n",
      "Epoch 736/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4293 - accuracy: 0.7865 - val_loss: 0.5619 - val_accuracy: 0.6927\n",
      "Epoch 737/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4294 - accuracy: 0.7847 - val_loss: 0.5619 - val_accuracy: 0.6927\n",
      "Epoch 738/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4292 - accuracy: 0.7865 - val_loss: 0.5619 - val_accuracy: 0.6927\n",
      "Epoch 739/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4292 - accuracy: 0.7865 - val_loss: 0.5620 - val_accuracy: 0.6927\n",
      "Epoch 740/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4292 - accuracy: 0.7865 - val_loss: 0.5620 - val_accuracy: 0.6927\n",
      "Epoch 741/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4291 - accuracy: 0.7865 - val_loss: 0.5620 - val_accuracy: 0.6927\n",
      "Epoch 742/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4291 - accuracy: 0.7865 - val_loss: 0.5620 - val_accuracy: 0.6927\n",
      "Epoch 743/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4291 - accuracy: 0.7865 - val_loss: 0.5620 - val_accuracy: 0.6927\n",
      "Epoch 744/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.7865 - val_loss: 0.5621 - val_accuracy: 0.6927\n",
      "Epoch 745/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.7865 - val_loss: 0.5621 - val_accuracy: 0.6979\n",
      "Epoch 746/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.7865 - val_loss: 0.5621 - val_accuracy: 0.6927\n",
      "Epoch 747/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4289 - accuracy: 0.7865 - val_loss: 0.5621 - val_accuracy: 0.6927\n",
      "Epoch 748/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4288 - accuracy: 0.7865 - val_loss: 0.5622 - val_accuracy: 0.6927\n",
      "Epoch 749/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4288 - accuracy: 0.7865 - val_loss: 0.5622 - val_accuracy: 0.6927\n",
      "Epoch 750/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4288 - accuracy: 0.7865 - val_loss: 0.5622 - val_accuracy: 0.6927\n",
      "Epoch 751/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4287 - accuracy: 0.7865 - val_loss: 0.5623 - val_accuracy: 0.6927\n",
      "Epoch 752/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4287 - accuracy: 0.7865 - val_loss: 0.5623 - val_accuracy: 0.6927\n",
      "Epoch 753/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4287 - accuracy: 0.7865 - val_loss: 0.5623 - val_accuracy: 0.6927\n",
      "Epoch 754/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4287 - accuracy: 0.7865 - val_loss: 0.5624 - val_accuracy: 0.6927\n",
      "Epoch 755/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4286 - accuracy: 0.7865 - val_loss: 0.5624 - val_accuracy: 0.6927\n",
      "Epoch 756/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4287 - accuracy: 0.7865 - val_loss: 0.5624 - val_accuracy: 0.6927\n",
      "Epoch 757/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4285 - accuracy: 0.7865 - val_loss: 0.5625 - val_accuracy: 0.6927\n",
      "Epoch 758/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4285 - accuracy: 0.7865 - val_loss: 0.5625 - val_accuracy: 0.6927\n",
      "Epoch 759/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4284 - accuracy: 0.7865 - val_loss: 0.5625 - val_accuracy: 0.6927\n",
      "Epoch 760/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4285 - accuracy: 0.7865 - val_loss: 0.5626 - val_accuracy: 0.6927\n",
      "Epoch 761/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4284 - accuracy: 0.7865 - val_loss: 0.5626 - val_accuracy: 0.6927\n",
      "Epoch 762/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.7865 - val_loss: 0.5626 - val_accuracy: 0.6927\n",
      "Epoch 763/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.7865 - val_loss: 0.5627 - val_accuracy: 0.6927\n",
      "Epoch 764/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.7865 - val_loss: 0.5627 - val_accuracy: 0.6927\n",
      "Epoch 765/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4282 - accuracy: 0.7865 - val_loss: 0.5628 - val_accuracy: 0.6927\n",
      "Epoch 766/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4281 - accuracy: 0.7865 - val_loss: 0.5628 - val_accuracy: 0.6927\n",
      "Epoch 767/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4282 - accuracy: 0.7865 - val_loss: 0.5629 - val_accuracy: 0.6927\n",
      "Epoch 768/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4281 - accuracy: 0.7865 - val_loss: 0.5629 - val_accuracy: 0.6927\n",
      "Epoch 769/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.7865 - val_loss: 0.5629 - val_accuracy: 0.6927\n",
      "Epoch 770/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4281 - accuracy: 0.7865 - val_loss: 0.5630 - val_accuracy: 0.6927\n",
      "Epoch 771/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.7865 - val_loss: 0.5630 - val_accuracy: 0.6927\n",
      "Epoch 772/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.7865 - val_loss: 0.5630 - val_accuracy: 0.6927\n",
      "Epoch 773/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4280 - accuracy: 0.7865 - val_loss: 0.5630 - val_accuracy: 0.6927\n",
      "Epoch 774/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.7865 - val_loss: 0.5631 - val_accuracy: 0.6927\n",
      "Epoch 775/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.7865 - val_loss: 0.5631 - val_accuracy: 0.6927\n",
      "Epoch 776/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.7882 - val_loss: 0.5632 - val_accuracy: 0.6927\n",
      "Epoch 777/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.7865 - val_loss: 0.5632 - val_accuracy: 0.6927\n",
      "Epoch 778/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.7865 - val_loss: 0.5633 - val_accuracy: 0.6927\n",
      "Epoch 779/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.7865 - val_loss: 0.5633 - val_accuracy: 0.6927\n",
      "Epoch 780/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.7865 - val_loss: 0.5633 - val_accuracy: 0.6927\n",
      "Epoch 781/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4276 - accuracy: 0.7882 - val_loss: 0.5634 - val_accuracy: 0.6927\n",
      "Epoch 782/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4276 - accuracy: 0.7865 - val_loss: 0.5634 - val_accuracy: 0.6927\n",
      "Epoch 783/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4275 - accuracy: 0.7865 - val_loss: 0.5635 - val_accuracy: 0.6927\n",
      "Epoch 784/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4276 - accuracy: 0.7882 - val_loss: 0.5635 - val_accuracy: 0.6927\n",
      "Epoch 785/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4275 - accuracy: 0.7865 - val_loss: 0.5635 - val_accuracy: 0.6927\n",
      "Epoch 786/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4275 - accuracy: 0.7882 - val_loss: 0.5636 - val_accuracy: 0.6927\n",
      "Epoch 787/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4275 - accuracy: 0.7865 - val_loss: 0.5636 - val_accuracy: 0.6927\n",
      "Epoch 788/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4274 - accuracy: 0.7882 - val_loss: 0.5636 - val_accuracy: 0.6927\n",
      "Epoch 789/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4274 - accuracy: 0.7865 - val_loss: 0.5637 - val_accuracy: 0.6927\n",
      "Epoch 790/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4274 - accuracy: 0.7882 - val_loss: 0.5637 - val_accuracy: 0.6927\n",
      "Epoch 791/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4274 - accuracy: 0.7865 - val_loss: 0.5637 - val_accuracy: 0.6927\n",
      "Epoch 792/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4273 - accuracy: 0.7865 - val_loss: 0.5638 - val_accuracy: 0.6927\n",
      "Epoch 793/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4273 - accuracy: 0.7847 - val_loss: 0.5638 - val_accuracy: 0.6927\n",
      "Epoch 794/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4272 - accuracy: 0.7882 - val_loss: 0.5638 - val_accuracy: 0.6927\n",
      "Epoch 795/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4272 - accuracy: 0.7865 - val_loss: 0.5638 - val_accuracy: 0.6927\n",
      "Epoch 796/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4271 - accuracy: 0.7882 - val_loss: 0.5639 - val_accuracy: 0.6927\n",
      "Epoch 797/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4271 - accuracy: 0.7899 - val_loss: 0.5639 - val_accuracy: 0.6927\n",
      "Epoch 798/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4271 - accuracy: 0.7865 - val_loss: 0.5639 - val_accuracy: 0.6927\n",
      "Epoch 799/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.7882 - val_loss: 0.5639 - val_accuracy: 0.6927\n",
      "Epoch 800/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.7882 - val_loss: 0.5640 - val_accuracy: 0.6927\n",
      "Epoch 801/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.7847 - val_loss: 0.5640 - val_accuracy: 0.6927\n",
      "Epoch 802/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4269 - accuracy: 0.7882 - val_loss: 0.5640 - val_accuracy: 0.6927\n",
      "Epoch 803/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4269 - accuracy: 0.7865 - val_loss: 0.5641 - val_accuracy: 0.6927\n",
      "Epoch 804/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4269 - accuracy: 0.7882 - val_loss: 0.5641 - val_accuracy: 0.6927\n",
      "Epoch 805/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4269 - accuracy: 0.7882 - val_loss: 0.5641 - val_accuracy: 0.6927\n",
      "Epoch 806/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.7882 - val_loss: 0.5641 - val_accuracy: 0.6927\n",
      "Epoch 807/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.7882 - val_loss: 0.5642 - val_accuracy: 0.6927\n",
      "Epoch 808/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.7899 - val_loss: 0.5642 - val_accuracy: 0.6927\n",
      "Epoch 809/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.7882 - val_loss: 0.5642 - val_accuracy: 0.6927\n",
      "Epoch 810/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.7899 - val_loss: 0.5642 - val_accuracy: 0.6927\n",
      "Epoch 811/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4266 - accuracy: 0.7882 - val_loss: 0.5643 - val_accuracy: 0.6927\n",
      "Epoch 812/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.7882 - val_loss: 0.5643 - val_accuracy: 0.6927\n",
      "Epoch 813/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.7882 - val_loss: 0.5644 - val_accuracy: 0.6927\n",
      "Epoch 814/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.7882 - val_loss: 0.5644 - val_accuracy: 0.6927\n",
      "Epoch 815/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4266 - accuracy: 0.7882 - val_loss: 0.5644 - val_accuracy: 0.6927\n",
      "Epoch 816/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.7882 - val_loss: 0.5644 - val_accuracy: 0.6927\n",
      "Epoch 817/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4264 - accuracy: 0.7882 - val_loss: 0.5645 - val_accuracy: 0.6927\n",
      "Epoch 818/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4264 - accuracy: 0.7882 - val_loss: 0.5645 - val_accuracy: 0.6927\n",
      "Epoch 819/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4264 - accuracy: 0.7882 - val_loss: 0.5646 - val_accuracy: 0.6927\n",
      "Epoch 820/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4263 - accuracy: 0.7882 - val_loss: 0.5646 - val_accuracy: 0.6927\n",
      "Epoch 821/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4263 - accuracy: 0.7882 - val_loss: 0.5646 - val_accuracy: 0.6927\n",
      "Epoch 822/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4263 - accuracy: 0.7882 - val_loss: 0.5646 - val_accuracy: 0.6927\n",
      "Epoch 823/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4262 - accuracy: 0.7865 - val_loss: 0.5647 - val_accuracy: 0.6927\n",
      "Epoch 824/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4262 - accuracy: 0.7865 - val_loss: 0.5647 - val_accuracy: 0.6927\n",
      "Epoch 825/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4261 - accuracy: 0.7882 - val_loss: 0.5647 - val_accuracy: 0.6927\n",
      "Epoch 826/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4261 - accuracy: 0.7882 - val_loss: 0.5647 - val_accuracy: 0.6927\n",
      "Epoch 827/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4261 - accuracy: 0.7882 - val_loss: 0.5648 - val_accuracy: 0.6927\n",
      "Epoch 828/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4260 - accuracy: 0.7882 - val_loss: 0.5648 - val_accuracy: 0.6927\n",
      "Epoch 829/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4260 - accuracy: 0.7882 - val_loss: 0.5648 - val_accuracy: 0.6927\n",
      "Epoch 830/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4260 - accuracy: 0.7882 - val_loss: 0.5649 - val_accuracy: 0.6927\n",
      "Epoch 831/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4259 - accuracy: 0.7882 - val_loss: 0.5649 - val_accuracy: 0.6927\n",
      "Epoch 832/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4258 - accuracy: 0.7882 - val_loss: 0.5649 - val_accuracy: 0.6927\n",
      "Epoch 833/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4258 - accuracy: 0.7882 - val_loss: 0.5650 - val_accuracy: 0.6927\n",
      "Epoch 834/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4258 - accuracy: 0.7882 - val_loss: 0.5650 - val_accuracy: 0.6927\n",
      "Epoch 835/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4258 - accuracy: 0.7882 - val_loss: 0.5650 - val_accuracy: 0.6927\n",
      "Epoch 836/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4257 - accuracy: 0.7899 - val_loss: 0.5650 - val_accuracy: 0.6927\n",
      "Epoch 837/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4257 - accuracy: 0.7882 - val_loss: 0.5651 - val_accuracy: 0.6927\n",
      "Epoch 838/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4256 - accuracy: 0.7882 - val_loss: 0.5651 - val_accuracy: 0.6927\n",
      "Epoch 839/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4256 - accuracy: 0.7882 - val_loss: 0.5651 - val_accuracy: 0.6927\n",
      "Epoch 840/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4255 - accuracy: 0.7882 - val_loss: 0.5652 - val_accuracy: 0.6927\n",
      "Epoch 841/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4255 - accuracy: 0.7882 - val_loss: 0.5652 - val_accuracy: 0.6927\n",
      "Epoch 842/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4254 - accuracy: 0.7899 - val_loss: 0.5652 - val_accuracy: 0.6927\n",
      "Epoch 843/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4255 - accuracy: 0.7882 - val_loss: 0.5652 - val_accuracy: 0.6927\n",
      "Epoch 844/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4254 - accuracy: 0.7899 - val_loss: 0.5653 - val_accuracy: 0.6927\n",
      "Epoch 845/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4254 - accuracy: 0.7899 - val_loss: 0.5653 - val_accuracy: 0.6927\n",
      "Epoch 846/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4253 - accuracy: 0.7899 - val_loss: 0.5654 - val_accuracy: 0.6927\n",
      "Epoch 847/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4252 - accuracy: 0.7917 - val_loss: 0.5654 - val_accuracy: 0.6927\n",
      "Epoch 848/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4252 - accuracy: 0.7917 - val_loss: 0.5654 - val_accuracy: 0.6927\n",
      "Epoch 849/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4252 - accuracy: 0.7934 - val_loss: 0.5655 - val_accuracy: 0.6927\n",
      "Epoch 850/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4251 - accuracy: 0.7917 - val_loss: 0.5655 - val_accuracy: 0.6927\n",
      "Epoch 851/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4251 - accuracy: 0.7917 - val_loss: 0.5655 - val_accuracy: 0.6927\n",
      "Epoch 852/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4251 - accuracy: 0.7934 - val_loss: 0.5656 - val_accuracy: 0.6927\n",
      "Epoch 853/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4249 - accuracy: 0.7917 - val_loss: 0.5656 - val_accuracy: 0.6927\n",
      "Epoch 854/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4249 - accuracy: 0.7917 - val_loss: 0.5656 - val_accuracy: 0.6927\n",
      "Epoch 855/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4249 - accuracy: 0.7917 - val_loss: 0.5657 - val_accuracy: 0.6927\n",
      "Epoch 856/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4249 - accuracy: 0.7917 - val_loss: 0.5657 - val_accuracy: 0.6927\n",
      "Epoch 857/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4248 - accuracy: 0.7917 - val_loss: 0.5657 - val_accuracy: 0.6927\n",
      "Epoch 858/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4248 - accuracy: 0.7917 - val_loss: 0.5658 - val_accuracy: 0.6927\n",
      "Epoch 859/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4247 - accuracy: 0.7899 - val_loss: 0.5658 - val_accuracy: 0.6927\n",
      "Epoch 860/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4246 - accuracy: 0.7917 - val_loss: 0.5658 - val_accuracy: 0.6927\n",
      "Epoch 861/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4247 - accuracy: 0.7917 - val_loss: 0.5659 - val_accuracy: 0.6927\n",
      "Epoch 862/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4246 - accuracy: 0.7917 - val_loss: 0.5659 - val_accuracy: 0.6927\n",
      "Epoch 863/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4245 - accuracy: 0.7934 - val_loss: 0.5660 - val_accuracy: 0.6927\n",
      "Epoch 864/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4246 - accuracy: 0.7917 - val_loss: 0.5660 - val_accuracy: 0.6927\n",
      "Epoch 865/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4245 - accuracy: 0.7917 - val_loss: 0.5660 - val_accuracy: 0.6927\n",
      "Epoch 866/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4244 - accuracy: 0.7917 - val_loss: 0.5661 - val_accuracy: 0.6927\n",
      "Epoch 867/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4244 - accuracy: 0.7899 - val_loss: 0.5661 - val_accuracy: 0.6927\n",
      "Epoch 868/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4243 - accuracy: 0.7899 - val_loss: 0.5661 - val_accuracy: 0.6927\n",
      "Epoch 869/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4244 - accuracy: 0.7917 - val_loss: 0.5662 - val_accuracy: 0.6927\n",
      "Epoch 870/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4243 - accuracy: 0.7899 - val_loss: 0.5662 - val_accuracy: 0.6927\n",
      "Epoch 871/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4242 - accuracy: 0.7917 - val_loss: 0.5662 - val_accuracy: 0.6927\n",
      "Epoch 872/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4242 - accuracy: 0.7917 - val_loss: 0.5663 - val_accuracy: 0.6927\n",
      "Epoch 873/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4241 - accuracy: 0.7934 - val_loss: 0.5664 - val_accuracy: 0.6927\n",
      "Epoch 874/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4241 - accuracy: 0.7934 - val_loss: 0.5664 - val_accuracy: 0.6927\n",
      "Epoch 875/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4240 - accuracy: 0.7899 - val_loss: 0.5665 - val_accuracy: 0.6927\n",
      "Epoch 876/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4240 - accuracy: 0.7917 - val_loss: 0.5665 - val_accuracy: 0.6927\n",
      "Epoch 877/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4240 - accuracy: 0.7917 - val_loss: 0.5665 - val_accuracy: 0.6927\n",
      "Epoch 878/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4239 - accuracy: 0.7934 - val_loss: 0.5666 - val_accuracy: 0.6927\n",
      "Epoch 879/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4239 - accuracy: 0.7917 - val_loss: 0.5666 - val_accuracy: 0.6927\n",
      "Epoch 880/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4239 - accuracy: 0.7934 - val_loss: 0.5667 - val_accuracy: 0.6927\n",
      "Epoch 881/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4238 - accuracy: 0.7899 - val_loss: 0.5668 - val_accuracy: 0.6927\n",
      "Epoch 882/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4238 - accuracy: 0.7917 - val_loss: 0.5668 - val_accuracy: 0.6927\n",
      "Epoch 883/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4237 - accuracy: 0.7917 - val_loss: 0.5669 - val_accuracy: 0.6927\n",
      "Epoch 884/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4238 - accuracy: 0.7934 - val_loss: 0.5670 - val_accuracy: 0.6927\n",
      "Epoch 885/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4236 - accuracy: 0.7917 - val_loss: 0.5670 - val_accuracy: 0.6927\n",
      "Epoch 886/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4236 - accuracy: 0.7899 - val_loss: 0.5671 - val_accuracy: 0.6927\n",
      "Epoch 887/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4235 - accuracy: 0.7917 - val_loss: 0.5671 - val_accuracy: 0.6927\n",
      "Epoch 888/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4235 - accuracy: 0.7917 - val_loss: 0.5672 - val_accuracy: 0.6927\n",
      "Epoch 889/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4234 - accuracy: 0.7899 - val_loss: 0.5673 - val_accuracy: 0.6927\n",
      "Epoch 890/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4234 - accuracy: 0.7917 - val_loss: 0.5673 - val_accuracy: 0.6875\n",
      "Epoch 891/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4234 - accuracy: 0.7899 - val_loss: 0.5674 - val_accuracy: 0.6875\n",
      "Epoch 892/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4233 - accuracy: 0.7899 - val_loss: 0.5674 - val_accuracy: 0.6875\n",
      "Epoch 893/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4233 - accuracy: 0.7917 - val_loss: 0.5675 - val_accuracy: 0.6875\n",
      "Epoch 894/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4233 - accuracy: 0.7917 - val_loss: 0.5675 - val_accuracy: 0.6875\n",
      "Epoch 895/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4232 - accuracy: 0.7934 - val_loss: 0.5676 - val_accuracy: 0.6875\n",
      "Epoch 896/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4232 - accuracy: 0.7917 - val_loss: 0.5676 - val_accuracy: 0.6875\n",
      "Epoch 897/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4231 - accuracy: 0.7917 - val_loss: 0.5677 - val_accuracy: 0.6875\n",
      "Epoch 898/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4231 - accuracy: 0.7899 - val_loss: 0.5677 - val_accuracy: 0.6875\n",
      "Epoch 899/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4230 - accuracy: 0.7917 - val_loss: 0.5677 - val_accuracy: 0.6875\n",
      "Epoch 900/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4230 - accuracy: 0.7917 - val_loss: 0.5678 - val_accuracy: 0.6875\n",
      "Epoch 901/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4230 - accuracy: 0.7917 - val_loss: 0.5678 - val_accuracy: 0.6875\n",
      "Epoch 902/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4229 - accuracy: 0.7899 - val_loss: 0.5679 - val_accuracy: 0.6875\n",
      "Epoch 903/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4229 - accuracy: 0.7899 - val_loss: 0.5679 - val_accuracy: 0.6875\n",
      "Epoch 904/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4229 - accuracy: 0.7899 - val_loss: 0.5680 - val_accuracy: 0.6875\n",
      "Epoch 905/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4228 - accuracy: 0.7917 - val_loss: 0.5680 - val_accuracy: 0.6875\n",
      "Epoch 906/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4228 - accuracy: 0.7917 - val_loss: 0.5681 - val_accuracy: 0.6875\n",
      "Epoch 907/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4227 - accuracy: 0.7917 - val_loss: 0.5681 - val_accuracy: 0.6875\n",
      "Epoch 908/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4227 - accuracy: 0.7899 - val_loss: 0.5682 - val_accuracy: 0.6875\n",
      "Epoch 909/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4227 - accuracy: 0.7917 - val_loss: 0.5682 - val_accuracy: 0.6875\n",
      "Epoch 910/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4226 - accuracy: 0.7917 - val_loss: 0.5683 - val_accuracy: 0.6875\n",
      "Epoch 911/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4226 - accuracy: 0.7917 - val_loss: 0.5683 - val_accuracy: 0.6875\n",
      "Epoch 912/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4226 - accuracy: 0.7934 - val_loss: 0.5683 - val_accuracy: 0.6875\n",
      "Epoch 913/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4225 - accuracy: 0.7899 - val_loss: 0.5684 - val_accuracy: 0.6875\n",
      "Epoch 914/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4224 - accuracy: 0.7917 - val_loss: 0.5685 - val_accuracy: 0.6875\n",
      "Epoch 915/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4224 - accuracy: 0.7899 - val_loss: 0.5685 - val_accuracy: 0.6875\n",
      "Epoch 916/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4224 - accuracy: 0.7917 - val_loss: 0.5685 - val_accuracy: 0.6875\n",
      "Epoch 917/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4223 - accuracy: 0.7917 - val_loss: 0.5686 - val_accuracy: 0.6875\n",
      "Epoch 918/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4223 - accuracy: 0.7899 - val_loss: 0.5686 - val_accuracy: 0.6875\n",
      "Epoch 919/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4223 - accuracy: 0.7917 - val_loss: 0.5687 - val_accuracy: 0.6875\n",
      "Epoch 920/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4222 - accuracy: 0.7917 - val_loss: 0.5687 - val_accuracy: 0.6875\n",
      "Epoch 921/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4222 - accuracy: 0.7917 - val_loss: 0.5688 - val_accuracy: 0.6875\n",
      "Epoch 922/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4222 - accuracy: 0.7917 - val_loss: 0.5689 - val_accuracy: 0.6875\n",
      "Epoch 923/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4221 - accuracy: 0.7899 - val_loss: 0.5689 - val_accuracy: 0.6875\n",
      "Epoch 924/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4221 - accuracy: 0.7917 - val_loss: 0.5690 - val_accuracy: 0.6875\n",
      "Epoch 925/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4221 - accuracy: 0.7917 - val_loss: 0.5690 - val_accuracy: 0.6875\n",
      "Epoch 926/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4220 - accuracy: 0.7917 - val_loss: 0.5691 - val_accuracy: 0.6875\n",
      "Epoch 927/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4221 - accuracy: 0.7917 - val_loss: 0.5691 - val_accuracy: 0.6875\n",
      "Epoch 928/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4219 - accuracy: 0.7917 - val_loss: 0.5692 - val_accuracy: 0.6875\n",
      "Epoch 929/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4219 - accuracy: 0.7917 - val_loss: 0.5693 - val_accuracy: 0.6875\n",
      "Epoch 930/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4220 - accuracy: 0.7899 - val_loss: 0.5693 - val_accuracy: 0.6875\n",
      "Epoch 931/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4219 - accuracy: 0.7917 - val_loss: 0.5693 - val_accuracy: 0.6875\n",
      "Epoch 932/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4218 - accuracy: 0.7917 - val_loss: 0.5694 - val_accuracy: 0.6875\n",
      "Epoch 933/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4218 - accuracy: 0.7899 - val_loss: 0.5694 - val_accuracy: 0.6875\n",
      "Epoch 934/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4218 - accuracy: 0.7917 - val_loss: 0.5695 - val_accuracy: 0.6875\n",
      "Epoch 935/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4217 - accuracy: 0.7917 - val_loss: 0.5695 - val_accuracy: 0.6875\n",
      "Epoch 936/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4217 - accuracy: 0.7917 - val_loss: 0.5696 - val_accuracy: 0.6875\n",
      "Epoch 937/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4217 - accuracy: 0.7917 - val_loss: 0.5696 - val_accuracy: 0.6875\n",
      "Epoch 938/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4216 - accuracy: 0.7899 - val_loss: 0.5696 - val_accuracy: 0.6875\n",
      "Epoch 939/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4216 - accuracy: 0.7917 - val_loss: 0.5697 - val_accuracy: 0.6875\n",
      "Epoch 940/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4216 - accuracy: 0.7917 - val_loss: 0.5698 - val_accuracy: 0.6875\n",
      "Epoch 941/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4216 - accuracy: 0.7917 - val_loss: 0.5698 - val_accuracy: 0.6875\n",
      "Epoch 942/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4216 - accuracy: 0.7917 - val_loss: 0.5699 - val_accuracy: 0.6875\n",
      "Epoch 943/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4215 - accuracy: 0.7917 - val_loss: 0.5699 - val_accuracy: 0.6875\n",
      "Epoch 944/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4215 - accuracy: 0.7917 - val_loss: 0.5699 - val_accuracy: 0.6875\n",
      "Epoch 945/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4214 - accuracy: 0.7917 - val_loss: 0.5700 - val_accuracy: 0.6875\n",
      "Epoch 946/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4214 - accuracy: 0.7917 - val_loss: 0.5700 - val_accuracy: 0.6875\n",
      "Epoch 947/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4213 - accuracy: 0.7917 - val_loss: 0.5701 - val_accuracy: 0.6875\n",
      "Epoch 948/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4213 - accuracy: 0.7899 - val_loss: 0.5701 - val_accuracy: 0.6875\n",
      "Epoch 949/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4213 - accuracy: 0.7917 - val_loss: 0.5702 - val_accuracy: 0.6875\n",
      "Epoch 950/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4212 - accuracy: 0.7917 - val_loss: 0.5702 - val_accuracy: 0.6875\n",
      "Epoch 951/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4212 - accuracy: 0.7917 - val_loss: 0.5703 - val_accuracy: 0.6875\n",
      "Epoch 952/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4212 - accuracy: 0.7917 - val_loss: 0.5703 - val_accuracy: 0.6875\n",
      "Epoch 953/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4211 - accuracy: 0.7917 - val_loss: 0.5704 - val_accuracy: 0.6875\n",
      "Epoch 954/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4211 - accuracy: 0.7951 - val_loss: 0.5704 - val_accuracy: 0.6875\n",
      "Epoch 955/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4210 - accuracy: 0.7917 - val_loss: 0.5704 - val_accuracy: 0.6875\n",
      "Epoch 956/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4211 - accuracy: 0.7899 - val_loss: 0.5705 - val_accuracy: 0.6875\n",
      "Epoch 957/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4210 - accuracy: 0.7917 - val_loss: 0.5705 - val_accuracy: 0.6875\n",
      "Epoch 958/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4210 - accuracy: 0.7917 - val_loss: 0.5705 - val_accuracy: 0.6875\n",
      "Epoch 959/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4209 - accuracy: 0.7917 - val_loss: 0.5706 - val_accuracy: 0.6875\n",
      "Epoch 960/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4209 - accuracy: 0.7917 - val_loss: 0.5706 - val_accuracy: 0.6875\n",
      "Epoch 961/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4209 - accuracy: 0.7934 - val_loss: 0.5707 - val_accuracy: 0.6875\n",
      "Epoch 962/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4208 - accuracy: 0.7917 - val_loss: 0.5707 - val_accuracy: 0.6875\n",
      "Epoch 963/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4208 - accuracy: 0.7917 - val_loss: 0.5708 - val_accuracy: 0.6875\n",
      "Epoch 964/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4208 - accuracy: 0.7917 - val_loss: 0.5708 - val_accuracy: 0.6875\n",
      "Epoch 965/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4208 - accuracy: 0.7934 - val_loss: 0.5708 - val_accuracy: 0.6875\n",
      "Epoch 966/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4208 - accuracy: 0.7899 - val_loss: 0.5708 - val_accuracy: 0.6875\n",
      "Epoch 967/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4207 - accuracy: 0.7917 - val_loss: 0.5709 - val_accuracy: 0.6875\n",
      "Epoch 968/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4207 - accuracy: 0.7899 - val_loss: 0.5709 - val_accuracy: 0.6875\n",
      "Epoch 969/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4206 - accuracy: 0.7899 - val_loss: 0.5709 - val_accuracy: 0.6875\n",
      "Epoch 970/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4206 - accuracy: 0.7899 - val_loss: 0.5710 - val_accuracy: 0.6875\n",
      "Epoch 971/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4205 - accuracy: 0.7899 - val_loss: 0.5710 - val_accuracy: 0.6875\n",
      "Epoch 972/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4205 - accuracy: 0.7899 - val_loss: 0.5711 - val_accuracy: 0.6875\n",
      "Epoch 973/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4205 - accuracy: 0.7917 - val_loss: 0.5711 - val_accuracy: 0.6875\n",
      "Epoch 974/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4205 - accuracy: 0.7899 - val_loss: 0.5711 - val_accuracy: 0.6875\n",
      "Epoch 975/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4204 - accuracy: 0.7899 - val_loss: 0.5712 - val_accuracy: 0.6875\n",
      "Epoch 976/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4204 - accuracy: 0.7899 - val_loss: 0.5712 - val_accuracy: 0.6875\n",
      "Epoch 977/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4203 - accuracy: 0.7899 - val_loss: 0.5713 - val_accuracy: 0.6875\n",
      "Epoch 978/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4204 - accuracy: 0.7899 - val_loss: 0.5713 - val_accuracy: 0.6875\n",
      "Epoch 979/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4203 - accuracy: 0.7899 - val_loss: 0.5714 - val_accuracy: 0.6875\n",
      "Epoch 980/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4203 - accuracy: 0.7899 - val_loss: 0.5714 - val_accuracy: 0.6875\n",
      "Epoch 981/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4202 - accuracy: 0.7917 - val_loss: 0.5714 - val_accuracy: 0.6875\n",
      "Epoch 982/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4202 - accuracy: 0.7917 - val_loss: 0.5715 - val_accuracy: 0.6875\n",
      "Epoch 983/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4202 - accuracy: 0.7917 - val_loss: 0.5715 - val_accuracy: 0.6875\n",
      "Epoch 984/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4201 - accuracy: 0.7899 - val_loss: 0.5716 - val_accuracy: 0.6875\n",
      "Epoch 985/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4201 - accuracy: 0.7899 - val_loss: 0.5716 - val_accuracy: 0.6875\n",
      "Epoch 986/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4201 - accuracy: 0.7917 - val_loss: 0.5716 - val_accuracy: 0.6875\n",
      "Epoch 987/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4200 - accuracy: 0.7917 - val_loss: 0.5716 - val_accuracy: 0.6875\n",
      "Epoch 988/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4200 - accuracy: 0.7917 - val_loss: 0.5717 - val_accuracy: 0.6875\n",
      "Epoch 989/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4200 - accuracy: 0.7917 - val_loss: 0.5717 - val_accuracy: 0.6875\n",
      "Epoch 990/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4199 - accuracy: 0.7899 - val_loss: 0.5718 - val_accuracy: 0.6875\n",
      "Epoch 991/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4198 - accuracy: 0.7917 - val_loss: 0.5718 - val_accuracy: 0.6875\n",
      "Epoch 992/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4198 - accuracy: 0.7917 - val_loss: 0.5719 - val_accuracy: 0.6875\n",
      "Epoch 993/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4198 - accuracy: 0.7917 - val_loss: 0.5719 - val_accuracy: 0.6875\n",
      "Epoch 994/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4197 - accuracy: 0.7917 - val_loss: 0.5720 - val_accuracy: 0.6875\n",
      "Epoch 995/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4197 - accuracy: 0.7917 - val_loss: 0.5720 - val_accuracy: 0.6875\n",
      "Epoch 996/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4196 - accuracy: 0.7917 - val_loss: 0.5721 - val_accuracy: 0.6875\n",
      "Epoch 997/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4196 - accuracy: 0.7917 - val_loss: 0.5721 - val_accuracy: 0.6875\n",
      "Epoch 998/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4196 - accuracy: 0.7917 - val_loss: 0.5722 - val_accuracy: 0.6875\n",
      "Epoch 999/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4196 - accuracy: 0.7917 - val_loss: 0.5722 - val_accuracy: 0.6823\n",
      "Epoch 1000/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4194 - accuracy: 0.7917 - val_loss: 0.5723 - val_accuracy: 0.6823\n",
      "Epoch 1001/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4195 - accuracy: 0.7917 - val_loss: 0.5723 - val_accuracy: 0.6823\n",
      "Epoch 1002/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4194 - accuracy: 0.7917 - val_loss: 0.5724 - val_accuracy: 0.6823\n",
      "Epoch 1003/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4194 - accuracy: 0.7917 - val_loss: 0.5725 - val_accuracy: 0.6823\n",
      "Epoch 1004/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4193 - accuracy: 0.7917 - val_loss: 0.5725 - val_accuracy: 0.6823\n",
      "Epoch 1005/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4193 - accuracy: 0.7917 - val_loss: 0.5726 - val_accuracy: 0.6823\n",
      "Epoch 1006/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4193 - accuracy: 0.7917 - val_loss: 0.5726 - val_accuracy: 0.6823\n",
      "Epoch 1007/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4193 - accuracy: 0.7917 - val_loss: 0.5727 - val_accuracy: 0.6823\n",
      "Epoch 1008/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4191 - accuracy: 0.7917 - val_loss: 0.5727 - val_accuracy: 0.6823\n",
      "Epoch 1009/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4192 - accuracy: 0.7917 - val_loss: 0.5728 - val_accuracy: 0.6823\n",
      "Epoch 1010/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4191 - accuracy: 0.7917 - val_loss: 0.5728 - val_accuracy: 0.6823\n",
      "Epoch 1011/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4191 - accuracy: 0.7951 - val_loss: 0.5728 - val_accuracy: 0.6823\n",
      "Epoch 1012/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4190 - accuracy: 0.7969 - val_loss: 0.5729 - val_accuracy: 0.6823\n",
      "Epoch 1013/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4190 - accuracy: 0.7934 - val_loss: 0.5730 - val_accuracy: 0.6823\n",
      "Epoch 1014/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4189 - accuracy: 0.7951 - val_loss: 0.5730 - val_accuracy: 0.6823\n",
      "Epoch 1015/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4189 - accuracy: 0.7934 - val_loss: 0.5731 - val_accuracy: 0.6823\n",
      "Epoch 1016/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4189 - accuracy: 0.7969 - val_loss: 0.5731 - val_accuracy: 0.6875\n",
      "Epoch 1017/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4188 - accuracy: 0.7917 - val_loss: 0.5731 - val_accuracy: 0.6875\n",
      "Epoch 1018/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4188 - accuracy: 0.7934 - val_loss: 0.5731 - val_accuracy: 0.6875\n",
      "Epoch 1019/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4187 - accuracy: 0.7969 - val_loss: 0.5732 - val_accuracy: 0.6875\n",
      "Epoch 1020/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4187 - accuracy: 0.7969 - val_loss: 0.5732 - val_accuracy: 0.6875\n",
      "Epoch 1021/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4187 - accuracy: 0.7969 - val_loss: 0.5733 - val_accuracy: 0.6875\n",
      "Epoch 1022/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4187 - accuracy: 0.7934 - val_loss: 0.5733 - val_accuracy: 0.6875\n",
      "Epoch 1023/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4186 - accuracy: 0.7951 - val_loss: 0.5734 - val_accuracy: 0.6875\n",
      "Epoch 1024/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4185 - accuracy: 0.7969 - val_loss: 0.5734 - val_accuracy: 0.6875\n",
      "Epoch 1025/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4185 - accuracy: 0.7969 - val_loss: 0.5735 - val_accuracy: 0.6875\n",
      "Epoch 1026/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4185 - accuracy: 0.7969 - val_loss: 0.5735 - val_accuracy: 0.6875\n",
      "Epoch 1027/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4185 - accuracy: 0.7969 - val_loss: 0.5736 - val_accuracy: 0.6875\n",
      "Epoch 1028/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4184 - accuracy: 0.7969 - val_loss: 0.5736 - val_accuracy: 0.6875\n",
      "Epoch 1029/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4184 - accuracy: 0.7969 - val_loss: 0.5736 - val_accuracy: 0.6875\n",
      "Epoch 1030/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4183 - accuracy: 0.7951 - val_loss: 0.5737 - val_accuracy: 0.6875\n",
      "Epoch 1031/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4183 - accuracy: 0.7969 - val_loss: 0.5737 - val_accuracy: 0.6875\n",
      "Epoch 1032/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4182 - accuracy: 0.7969 - val_loss: 0.5738 - val_accuracy: 0.6875\n",
      "Epoch 1033/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4182 - accuracy: 0.7969 - val_loss: 0.5739 - val_accuracy: 0.6875\n",
      "Epoch 1034/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4182 - accuracy: 0.7934 - val_loss: 0.5739 - val_accuracy: 0.6875\n",
      "Epoch 1035/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4181 - accuracy: 0.7969 - val_loss: 0.5740 - val_accuracy: 0.6875\n",
      "Epoch 1036/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4181 - accuracy: 0.7969 - val_loss: 0.5740 - val_accuracy: 0.6875\n",
      "Epoch 1037/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4180 - accuracy: 0.7986 - val_loss: 0.5741 - val_accuracy: 0.6875\n",
      "Epoch 1038/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4180 - accuracy: 0.7969 - val_loss: 0.5741 - val_accuracy: 0.6875\n",
      "Epoch 1039/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4180 - accuracy: 0.7969 - val_loss: 0.5742 - val_accuracy: 0.6875\n",
      "Epoch 1040/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4179 - accuracy: 0.7969 - val_loss: 0.5743 - val_accuracy: 0.6875\n",
      "Epoch 1041/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4179 - accuracy: 0.7969 - val_loss: 0.5743 - val_accuracy: 0.6875\n",
      "Epoch 1042/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4179 - accuracy: 0.7986 - val_loss: 0.5744 - val_accuracy: 0.6875\n",
      "Epoch 1043/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4178 - accuracy: 0.7986 - val_loss: 0.5744 - val_accuracy: 0.6875\n",
      "Epoch 1044/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4178 - accuracy: 0.7951 - val_loss: 0.5745 - val_accuracy: 0.6875\n",
      "Epoch 1045/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4178 - accuracy: 0.7986 - val_loss: 0.5745 - val_accuracy: 0.6875\n",
      "Epoch 1046/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4177 - accuracy: 0.8003 - val_loss: 0.5746 - val_accuracy: 0.6875\n",
      "Epoch 1047/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4177 - accuracy: 0.7986 - val_loss: 0.5746 - val_accuracy: 0.6875\n",
      "Epoch 1048/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4176 - accuracy: 0.7969 - val_loss: 0.5747 - val_accuracy: 0.6875\n",
      "Epoch 1049/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4176 - accuracy: 0.7986 - val_loss: 0.5747 - val_accuracy: 0.6875\n",
      "Epoch 1050/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4175 - accuracy: 0.7986 - val_loss: 0.5748 - val_accuracy: 0.6875\n",
      "Epoch 1051/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4175 - accuracy: 0.7969 - val_loss: 0.5748 - val_accuracy: 0.6875\n",
      "Epoch 1052/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4175 - accuracy: 0.7969 - val_loss: 0.5748 - val_accuracy: 0.6875\n",
      "Epoch 1053/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4175 - accuracy: 0.7986 - val_loss: 0.5749 - val_accuracy: 0.6875\n",
      "Epoch 1054/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4175 - accuracy: 0.7951 - val_loss: 0.5749 - val_accuracy: 0.6875\n",
      "Epoch 1055/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4174 - accuracy: 0.7969 - val_loss: 0.5750 - val_accuracy: 0.6875\n",
      "Epoch 1056/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4173 - accuracy: 0.7986 - val_loss: 0.5751 - val_accuracy: 0.6875\n",
      "Epoch 1057/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4174 - accuracy: 0.7986 - val_loss: 0.5751 - val_accuracy: 0.6875\n",
      "Epoch 1058/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4173 - accuracy: 0.7969 - val_loss: 0.5752 - val_accuracy: 0.6875\n",
      "Epoch 1059/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4173 - accuracy: 0.7934 - val_loss: 0.5752 - val_accuracy: 0.6875\n",
      "Epoch 1060/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4172 - accuracy: 0.7986 - val_loss: 0.5753 - val_accuracy: 0.6875\n",
      "Epoch 1061/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4172 - accuracy: 0.7934 - val_loss: 0.5754 - val_accuracy: 0.6875\n",
      "Epoch 1062/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4171 - accuracy: 0.7934 - val_loss: 0.5754 - val_accuracy: 0.6875\n",
      "Epoch 1063/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4172 - accuracy: 0.7969 - val_loss: 0.5754 - val_accuracy: 0.6875\n",
      "Epoch 1064/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4171 - accuracy: 0.7951 - val_loss: 0.5755 - val_accuracy: 0.6875\n",
      "Epoch 1065/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4171 - accuracy: 0.7969 - val_loss: 0.5756 - val_accuracy: 0.6875\n",
      "Epoch 1066/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4170 - accuracy: 0.7951 - val_loss: 0.5756 - val_accuracy: 0.6875\n",
      "Epoch 1067/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4170 - accuracy: 0.7951 - val_loss: 0.5756 - val_accuracy: 0.6875\n",
      "Epoch 1068/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4169 - accuracy: 0.7951 - val_loss: 0.5757 - val_accuracy: 0.6875\n",
      "Epoch 1069/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4169 - accuracy: 0.7951 - val_loss: 0.5758 - val_accuracy: 0.6875\n",
      "Epoch 1070/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4169 - accuracy: 0.7934 - val_loss: 0.5758 - val_accuracy: 0.6875\n",
      "Epoch 1071/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4169 - accuracy: 0.7934 - val_loss: 0.5758 - val_accuracy: 0.6875\n",
      "Epoch 1072/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4168 - accuracy: 0.7934 - val_loss: 0.5759 - val_accuracy: 0.6875\n",
      "Epoch 1073/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4168 - accuracy: 0.7951 - val_loss: 0.5759 - val_accuracy: 0.6875\n",
      "Epoch 1074/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4167 - accuracy: 0.7951 - val_loss: 0.5759 - val_accuracy: 0.6875\n",
      "Epoch 1075/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4168 - accuracy: 0.7951 - val_loss: 0.5759 - val_accuracy: 0.6875\n",
      "Epoch 1076/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4167 - accuracy: 0.7969 - val_loss: 0.5760 - val_accuracy: 0.6875\n",
      "Epoch 1077/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4166 - accuracy: 0.7934 - val_loss: 0.5760 - val_accuracy: 0.6875\n",
      "Epoch 1078/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4166 - accuracy: 0.7934 - val_loss: 0.5761 - val_accuracy: 0.6875\n",
      "Epoch 1079/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4166 - accuracy: 0.7934 - val_loss: 0.5762 - val_accuracy: 0.6875\n",
      "Epoch 1080/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4166 - accuracy: 0.7951 - val_loss: 0.5762 - val_accuracy: 0.6875\n",
      "Epoch 1081/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4165 - accuracy: 0.7934 - val_loss: 0.5762 - val_accuracy: 0.6875\n",
      "Epoch 1082/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4165 - accuracy: 0.7934 - val_loss: 0.5763 - val_accuracy: 0.6875\n",
      "Epoch 1083/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4165 - accuracy: 0.7934 - val_loss: 0.5763 - val_accuracy: 0.6875\n",
      "Epoch 1084/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4164 - accuracy: 0.7934 - val_loss: 0.5763 - val_accuracy: 0.6875\n",
      "Epoch 1085/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4164 - accuracy: 0.7934 - val_loss: 0.5764 - val_accuracy: 0.6875\n",
      "Epoch 1086/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4164 - accuracy: 0.7934 - val_loss: 0.5765 - val_accuracy: 0.6875\n",
      "Epoch 1087/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4164 - accuracy: 0.7934 - val_loss: 0.5765 - val_accuracy: 0.6875\n",
      "Epoch 1088/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4163 - accuracy: 0.7934 - val_loss: 0.5766 - val_accuracy: 0.6875\n",
      "Epoch 1089/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4163 - accuracy: 0.7934 - val_loss: 0.5766 - val_accuracy: 0.6875\n",
      "Epoch 1090/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4163 - accuracy: 0.7934 - val_loss: 0.5767 - val_accuracy: 0.6875\n",
      "Epoch 1091/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4162 - accuracy: 0.7951 - val_loss: 0.5767 - val_accuracy: 0.6875\n",
      "Epoch 1092/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4162 - accuracy: 0.7934 - val_loss: 0.5768 - val_accuracy: 0.6875\n",
      "Epoch 1093/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4161 - accuracy: 0.7951 - val_loss: 0.5768 - val_accuracy: 0.6875\n",
      "Epoch 1094/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4161 - accuracy: 0.7951 - val_loss: 0.5769 - val_accuracy: 0.6875\n",
      "Epoch 1095/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4161 - accuracy: 0.7951 - val_loss: 0.5770 - val_accuracy: 0.6875\n",
      "Epoch 1096/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4161 - accuracy: 0.7951 - val_loss: 0.5770 - val_accuracy: 0.6875\n",
      "Epoch 1097/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4161 - accuracy: 0.7969 - val_loss: 0.5770 - val_accuracy: 0.6875\n",
      "Epoch 1098/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4160 - accuracy: 0.7934 - val_loss: 0.5771 - val_accuracy: 0.6875\n",
      "Epoch 1099/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4160 - accuracy: 0.7934 - val_loss: 0.5771 - val_accuracy: 0.6875\n",
      "Epoch 1100/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4160 - accuracy: 0.7951 - val_loss: 0.5772 - val_accuracy: 0.6875\n",
      "Epoch 1101/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4159 - accuracy: 0.7951 - val_loss: 0.5772 - val_accuracy: 0.6875\n",
      "Epoch 1102/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4159 - accuracy: 0.7951 - val_loss: 0.5772 - val_accuracy: 0.6875\n",
      "Epoch 1103/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4158 - accuracy: 0.7951 - val_loss: 0.5773 - val_accuracy: 0.6875\n",
      "Epoch 1104/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4159 - accuracy: 0.7969 - val_loss: 0.5773 - val_accuracy: 0.6875\n",
      "Epoch 1105/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4158 - accuracy: 0.7951 - val_loss: 0.5773 - val_accuracy: 0.6875\n",
      "Epoch 1106/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4158 - accuracy: 0.7951 - val_loss: 0.5774 - val_accuracy: 0.6875\n",
      "Epoch 1107/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4157 - accuracy: 0.7951 - val_loss: 0.5774 - val_accuracy: 0.6875\n",
      "Epoch 1108/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4158 - accuracy: 0.7951 - val_loss: 0.5775 - val_accuracy: 0.6875\n",
      "Epoch 1109/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4157 - accuracy: 0.7951 - val_loss: 0.5775 - val_accuracy: 0.6875\n",
      "Epoch 1110/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4157 - accuracy: 0.7951 - val_loss: 0.5775 - val_accuracy: 0.6875\n",
      "Epoch 1111/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4156 - accuracy: 0.7969 - val_loss: 0.5776 - val_accuracy: 0.6875\n",
      "Epoch 1112/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4157 - accuracy: 0.7951 - val_loss: 0.5776 - val_accuracy: 0.6875\n",
      "Epoch 1113/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4155 - accuracy: 0.7951 - val_loss: 0.5777 - val_accuracy: 0.6875\n",
      "Epoch 1114/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4156 - accuracy: 0.7951 - val_loss: 0.5777 - val_accuracy: 0.6875\n",
      "Epoch 1115/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4156 - accuracy: 0.7969 - val_loss: 0.5778 - val_accuracy: 0.6875\n",
      "Epoch 1116/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4155 - accuracy: 0.7969 - val_loss: 0.5778 - val_accuracy: 0.6875\n",
      "Epoch 1117/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4155 - accuracy: 0.7986 - val_loss: 0.5778 - val_accuracy: 0.6875\n",
      "Epoch 1118/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4155 - accuracy: 0.7969 - val_loss: 0.5779 - val_accuracy: 0.6875\n",
      "Epoch 1119/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4154 - accuracy: 0.7951 - val_loss: 0.5779 - val_accuracy: 0.6875\n",
      "Epoch 1120/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4154 - accuracy: 0.7969 - val_loss: 0.5780 - val_accuracy: 0.6875\n",
      "Epoch 1121/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4154 - accuracy: 0.7969 - val_loss: 0.5780 - val_accuracy: 0.6875\n",
      "Epoch 1122/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4154 - accuracy: 0.7969 - val_loss: 0.5781 - val_accuracy: 0.6875\n",
      "Epoch 1123/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4153 - accuracy: 0.7969 - val_loss: 0.5782 - val_accuracy: 0.6875\n",
      "Epoch 1124/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4153 - accuracy: 0.7969 - val_loss: 0.5782 - val_accuracy: 0.6875\n",
      "Epoch 1125/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4153 - accuracy: 0.7969 - val_loss: 0.5783 - val_accuracy: 0.6875\n",
      "Epoch 1126/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4152 - accuracy: 0.7969 - val_loss: 0.5783 - val_accuracy: 0.6875\n",
      "Epoch 1127/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4152 - accuracy: 0.7969 - val_loss: 0.5783 - val_accuracy: 0.6875\n",
      "Epoch 1128/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4152 - accuracy: 0.7986 - val_loss: 0.5784 - val_accuracy: 0.6875\n",
      "Epoch 1129/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4151 - accuracy: 0.7969 - val_loss: 0.5784 - val_accuracy: 0.6875\n",
      "Epoch 1130/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4151 - accuracy: 0.7986 - val_loss: 0.5785 - val_accuracy: 0.6875\n",
      "Epoch 1131/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4151 - accuracy: 0.7986 - val_loss: 0.5785 - val_accuracy: 0.6875\n",
      "Epoch 1132/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4151 - accuracy: 0.7986 - val_loss: 0.5785 - val_accuracy: 0.6875\n",
      "Epoch 1133/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4150 - accuracy: 0.7986 - val_loss: 0.5786 - val_accuracy: 0.6875\n",
      "Epoch 1134/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4150 - accuracy: 0.7986 - val_loss: 0.5786 - val_accuracy: 0.6875\n",
      "Epoch 1135/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4150 - accuracy: 0.7986 - val_loss: 0.5786 - val_accuracy: 0.6875\n",
      "Epoch 1136/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4149 - accuracy: 0.7986 - val_loss: 0.5787 - val_accuracy: 0.6875\n",
      "Epoch 1137/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4149 - accuracy: 0.7986 - val_loss: 0.5788 - val_accuracy: 0.6875\n",
      "Epoch 1138/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4149 - accuracy: 0.7986 - val_loss: 0.5788 - val_accuracy: 0.6875\n",
      "Epoch 1139/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4149 - accuracy: 0.7986 - val_loss: 0.5789 - val_accuracy: 0.6875\n",
      "Epoch 1140/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4149 - accuracy: 0.7986 - val_loss: 0.5789 - val_accuracy: 0.6875\n",
      "Epoch 1141/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4148 - accuracy: 0.7986 - val_loss: 0.5790 - val_accuracy: 0.6875\n",
      "Epoch 1142/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4148 - accuracy: 0.7986 - val_loss: 0.5790 - val_accuracy: 0.6875\n",
      "Epoch 1143/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4148 - accuracy: 0.7986 - val_loss: 0.5790 - val_accuracy: 0.6875\n",
      "Epoch 1144/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4148 - accuracy: 0.7986 - val_loss: 0.5791 - val_accuracy: 0.6875\n",
      "Epoch 1145/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4147 - accuracy: 0.7986 - val_loss: 0.5791 - val_accuracy: 0.6875\n",
      "Epoch 1146/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4146 - accuracy: 0.7986 - val_loss: 0.5792 - val_accuracy: 0.6875\n",
      "Epoch 1147/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4146 - accuracy: 0.7986 - val_loss: 0.5792 - val_accuracy: 0.6875\n",
      "Epoch 1148/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4146 - accuracy: 0.7986 - val_loss: 0.5792 - val_accuracy: 0.6875\n",
      "Epoch 1149/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4146 - accuracy: 0.7986 - val_loss: 0.5793 - val_accuracy: 0.6875\n",
      "Epoch 1150/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.7986 - val_loss: 0.5793 - val_accuracy: 0.6875\n",
      "Epoch 1151/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4146 - accuracy: 0.7986 - val_loss: 0.5793 - val_accuracy: 0.6875\n",
      "Epoch 1152/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.7986 - val_loss: 0.5794 - val_accuracy: 0.6875\n",
      "Epoch 1153/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.7986 - val_loss: 0.5794 - val_accuracy: 0.6875\n",
      "Epoch 1154/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.7986 - val_loss: 0.5794 - val_accuracy: 0.6875\n",
      "Epoch 1155/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4144 - accuracy: 0.7986 - val_loss: 0.5795 - val_accuracy: 0.6875\n",
      "Epoch 1156/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4144 - accuracy: 0.7986 - val_loss: 0.5795 - val_accuracy: 0.6875\n",
      "Epoch 1157/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4144 - accuracy: 0.7986 - val_loss: 0.5796 - val_accuracy: 0.6875\n",
      "Epoch 1158/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4144 - accuracy: 0.7986 - val_loss: 0.5796 - val_accuracy: 0.6875\n",
      "Epoch 1159/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4144 - accuracy: 0.7986 - val_loss: 0.5797 - val_accuracy: 0.6875\n",
      "Epoch 1160/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4142 - accuracy: 0.7986 - val_loss: 0.5797 - val_accuracy: 0.6875\n",
      "Epoch 1161/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4143 - accuracy: 0.7986 - val_loss: 0.5798 - val_accuracy: 0.6875\n",
      "Epoch 1162/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4142 - accuracy: 0.7986 - val_loss: 0.5798 - val_accuracy: 0.6875\n",
      "Epoch 1163/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4142 - accuracy: 0.7986 - val_loss: 0.5799 - val_accuracy: 0.6875\n",
      "Epoch 1164/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4142 - accuracy: 0.7986 - val_loss: 0.5800 - val_accuracy: 0.6875\n",
      "Epoch 1165/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4141 - accuracy: 0.7986 - val_loss: 0.5800 - val_accuracy: 0.6875\n",
      "Epoch 1166/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4140 - accuracy: 0.7986 - val_loss: 0.5800 - val_accuracy: 0.6875\n",
      "Epoch 1167/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4140 - accuracy: 0.7986 - val_loss: 0.5801 - val_accuracy: 0.6875\n",
      "Epoch 1168/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4140 - accuracy: 0.7986 - val_loss: 0.5801 - val_accuracy: 0.6875\n",
      "Epoch 1169/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4140 - accuracy: 0.7986 - val_loss: 0.5802 - val_accuracy: 0.6875\n",
      "Epoch 1170/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4140 - accuracy: 0.7986 - val_loss: 0.5802 - val_accuracy: 0.6875\n",
      "Epoch 1171/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4139 - accuracy: 0.7986 - val_loss: 0.5803 - val_accuracy: 0.6875\n",
      "Epoch 1172/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4140 - accuracy: 0.7986 - val_loss: 0.5803 - val_accuracy: 0.6875\n",
      "Epoch 1173/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4139 - accuracy: 0.7986 - val_loss: 0.5804 - val_accuracy: 0.6875\n",
      "Epoch 1174/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4138 - accuracy: 0.7986 - val_loss: 0.5805 - val_accuracy: 0.6875\n",
      "Epoch 1175/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4138 - accuracy: 0.7986 - val_loss: 0.5806 - val_accuracy: 0.6875\n",
      "Epoch 1176/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4138 - accuracy: 0.7986 - val_loss: 0.5806 - val_accuracy: 0.6875\n",
      "Epoch 1177/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4138 - accuracy: 0.7986 - val_loss: 0.5807 - val_accuracy: 0.6875\n",
      "Epoch 1178/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4137 - accuracy: 0.7986 - val_loss: 0.5807 - val_accuracy: 0.6875\n",
      "Epoch 1179/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4137 - accuracy: 0.7986 - val_loss: 0.5807 - val_accuracy: 0.6875\n",
      "Epoch 1180/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4137 - accuracy: 0.7986 - val_loss: 0.5808 - val_accuracy: 0.6875\n",
      "Epoch 1181/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4137 - accuracy: 0.7986 - val_loss: 0.5809 - val_accuracy: 0.6875\n",
      "Epoch 1182/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4136 - accuracy: 0.7986 - val_loss: 0.5809 - val_accuracy: 0.6875\n",
      "Epoch 1183/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4136 - accuracy: 0.7986 - val_loss: 0.5810 - val_accuracy: 0.6875\n",
      "Epoch 1184/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4136 - accuracy: 0.7986 - val_loss: 0.5810 - val_accuracy: 0.6875\n",
      "Epoch 1185/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4136 - accuracy: 0.7986 - val_loss: 0.5811 - val_accuracy: 0.6875\n",
      "Epoch 1186/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4136 - accuracy: 0.7986 - val_loss: 0.5811 - val_accuracy: 0.6875\n",
      "Epoch 1187/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4135 - accuracy: 0.7986 - val_loss: 0.5812 - val_accuracy: 0.6875\n",
      "Epoch 1188/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4135 - accuracy: 0.7986 - val_loss: 0.5813 - val_accuracy: 0.6875\n",
      "Epoch 1189/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4135 - accuracy: 0.7986 - val_loss: 0.5813 - val_accuracy: 0.6875\n",
      "Epoch 1190/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4134 - accuracy: 0.7986 - val_loss: 0.5813 - val_accuracy: 0.6875\n",
      "Epoch 1191/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4134 - accuracy: 0.7986 - val_loss: 0.5814 - val_accuracy: 0.6823\n",
      "Epoch 1192/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4134 - accuracy: 0.7986 - val_loss: 0.5815 - val_accuracy: 0.6823\n",
      "Epoch 1193/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4133 - accuracy: 0.7986 - val_loss: 0.5815 - val_accuracy: 0.6823\n",
      "Epoch 1194/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4134 - accuracy: 0.7986 - val_loss: 0.5815 - val_accuracy: 0.6823\n",
      "Epoch 1195/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4133 - accuracy: 0.7986 - val_loss: 0.5816 - val_accuracy: 0.6823\n",
      "Epoch 1196/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4133 - accuracy: 0.7986 - val_loss: 0.5816 - val_accuracy: 0.6823\n",
      "Epoch 1197/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4132 - accuracy: 0.7986 - val_loss: 0.5817 - val_accuracy: 0.6823\n",
      "Epoch 1198/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4132 - accuracy: 0.7986 - val_loss: 0.5818 - val_accuracy: 0.6823\n",
      "Epoch 1199/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4132 - accuracy: 0.7986 - val_loss: 0.5818 - val_accuracy: 0.6823\n",
      "Epoch 1200/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4131 - accuracy: 0.7986 - val_loss: 0.5819 - val_accuracy: 0.6823\n",
      "Epoch 1201/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4132 - accuracy: 0.7986 - val_loss: 0.5819 - val_accuracy: 0.6823\n",
      "Epoch 1202/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4131 - accuracy: 0.7986 - val_loss: 0.5819 - val_accuracy: 0.6823\n",
      "Epoch 1203/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4131 - accuracy: 0.7969 - val_loss: 0.5820 - val_accuracy: 0.6823\n",
      "Epoch 1204/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4130 - accuracy: 0.7986 - val_loss: 0.5820 - val_accuracy: 0.6823\n",
      "Epoch 1205/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4131 - accuracy: 0.7969 - val_loss: 0.5820 - val_accuracy: 0.6823\n",
      "Epoch 1206/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4131 - accuracy: 0.7969 - val_loss: 0.5821 - val_accuracy: 0.6823\n",
      "Epoch 1207/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4130 - accuracy: 0.7986 - val_loss: 0.5822 - val_accuracy: 0.6823\n",
      "Epoch 1208/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4130 - accuracy: 0.7969 - val_loss: 0.5822 - val_accuracy: 0.6823\n",
      "Epoch 1209/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4130 - accuracy: 0.7969 - val_loss: 0.5822 - val_accuracy: 0.6823\n",
      "Epoch 1210/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4130 - accuracy: 0.7986 - val_loss: 0.5823 - val_accuracy: 0.6823\n",
      "Epoch 1211/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4130 - accuracy: 0.7969 - val_loss: 0.5823 - val_accuracy: 0.6823\n",
      "Epoch 1212/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4129 - accuracy: 0.7969 - val_loss: 0.5823 - val_accuracy: 0.6823\n",
      "Epoch 1213/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4129 - accuracy: 0.7969 - val_loss: 0.5823 - val_accuracy: 0.6823\n",
      "Epoch 1214/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4129 - accuracy: 0.7969 - val_loss: 0.5824 - val_accuracy: 0.6823\n",
      "Epoch 1215/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4128 - accuracy: 0.7969 - val_loss: 0.5825 - val_accuracy: 0.6823\n",
      "Epoch 1216/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4128 - accuracy: 0.7986 - val_loss: 0.5825 - val_accuracy: 0.6823\n",
      "Epoch 1217/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4127 - accuracy: 0.7969 - val_loss: 0.5825 - val_accuracy: 0.6823\n",
      "Epoch 1218/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4128 - accuracy: 0.7969 - val_loss: 0.5826 - val_accuracy: 0.6823\n",
      "Epoch 1219/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4127 - accuracy: 0.7969 - val_loss: 0.5826 - val_accuracy: 0.6823\n",
      "Epoch 1220/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4127 - accuracy: 0.7969 - val_loss: 0.5827 - val_accuracy: 0.6823\n",
      "Epoch 1221/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4127 - accuracy: 0.7986 - val_loss: 0.5827 - val_accuracy: 0.6823\n",
      "Epoch 1222/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4127 - accuracy: 0.7969 - val_loss: 0.5828 - val_accuracy: 0.6823\n",
      "Epoch 1223/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4126 - accuracy: 0.7969 - val_loss: 0.5828 - val_accuracy: 0.6823\n",
      "Epoch 1224/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4126 - accuracy: 0.7969 - val_loss: 0.5829 - val_accuracy: 0.6823\n",
      "Epoch 1225/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4126 - accuracy: 0.7969 - val_loss: 0.5829 - val_accuracy: 0.6823\n",
      "Epoch 1226/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4126 - accuracy: 0.7969 - val_loss: 0.5830 - val_accuracy: 0.6823\n",
      "Epoch 1227/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4126 - accuracy: 0.7986 - val_loss: 0.5830 - val_accuracy: 0.6823\n",
      "Epoch 1228/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4125 - accuracy: 0.7969 - val_loss: 0.5830 - val_accuracy: 0.6823\n",
      "Epoch 1229/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4125 - accuracy: 0.7969 - val_loss: 0.5831 - val_accuracy: 0.6823\n",
      "Epoch 1230/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4125 - accuracy: 0.7969 - val_loss: 0.5831 - val_accuracy: 0.6823\n",
      "Epoch 1231/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4125 - accuracy: 0.7969 - val_loss: 0.5832 - val_accuracy: 0.6823\n",
      "Epoch 1232/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4125 - accuracy: 0.7969 - val_loss: 0.5832 - val_accuracy: 0.6823\n",
      "Epoch 1233/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4124 - accuracy: 0.7969 - val_loss: 0.5833 - val_accuracy: 0.6823\n",
      "Epoch 1234/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4124 - accuracy: 0.7969 - val_loss: 0.5834 - val_accuracy: 0.6823\n",
      "Epoch 1235/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4124 - accuracy: 0.7969 - val_loss: 0.5834 - val_accuracy: 0.6823\n",
      "Epoch 1236/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4124 - accuracy: 0.7969 - val_loss: 0.5834 - val_accuracy: 0.6823\n",
      "Epoch 1237/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4124 - accuracy: 0.7969 - val_loss: 0.5835 - val_accuracy: 0.6823\n",
      "Epoch 1238/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4123 - accuracy: 0.7969 - val_loss: 0.5835 - val_accuracy: 0.6823\n",
      "Epoch 1239/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4123 - accuracy: 0.7969 - val_loss: 0.5836 - val_accuracy: 0.6823\n",
      "Epoch 1240/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4124 - accuracy: 0.7969 - val_loss: 0.5836 - val_accuracy: 0.6823\n",
      "Epoch 1241/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4123 - accuracy: 0.7986 - val_loss: 0.5837 - val_accuracy: 0.6823\n",
      "Epoch 1242/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4123 - accuracy: 0.7969 - val_loss: 0.5837 - val_accuracy: 0.6823\n",
      "Epoch 1243/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4122 - accuracy: 0.7986 - val_loss: 0.5838 - val_accuracy: 0.6823\n",
      "Epoch 1244/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4122 - accuracy: 0.7986 - val_loss: 0.5838 - val_accuracy: 0.6823\n",
      "Epoch 1245/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4122 - accuracy: 0.7986 - val_loss: 0.5839 - val_accuracy: 0.6823\n",
      "Epoch 1246/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4122 - accuracy: 0.7986 - val_loss: 0.5840 - val_accuracy: 0.6823\n",
      "Epoch 1247/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4122 - accuracy: 0.7969 - val_loss: 0.5840 - val_accuracy: 0.6823\n",
      "Epoch 1248/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4121 - accuracy: 0.8003 - val_loss: 0.5840 - val_accuracy: 0.6823\n",
      "Epoch 1249/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4122 - accuracy: 0.7986 - val_loss: 0.5841 - val_accuracy: 0.6823\n",
      "Epoch 1250/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4121 - accuracy: 0.8003 - val_loss: 0.5841 - val_accuracy: 0.6823\n",
      "Epoch 1251/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4121 - accuracy: 0.7969 - val_loss: 0.5842 - val_accuracy: 0.6823\n",
      "Epoch 1252/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4121 - accuracy: 0.8003 - val_loss: 0.5842 - val_accuracy: 0.6823\n",
      "Epoch 1253/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4120 - accuracy: 0.8003 - val_loss: 0.5843 - val_accuracy: 0.6823\n",
      "Epoch 1254/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4120 - accuracy: 0.7986 - val_loss: 0.5843 - val_accuracy: 0.6823\n",
      "Epoch 1255/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4120 - accuracy: 0.8003 - val_loss: 0.5844 - val_accuracy: 0.6823\n",
      "Epoch 1256/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4120 - accuracy: 0.8003 - val_loss: 0.5844 - val_accuracy: 0.6823\n",
      "Epoch 1257/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4120 - accuracy: 0.8003 - val_loss: 0.5844 - val_accuracy: 0.6823\n",
      "Epoch 1258/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4119 - accuracy: 0.8003 - val_loss: 0.5845 - val_accuracy: 0.6823\n",
      "Epoch 1259/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4120 - accuracy: 0.8003 - val_loss: 0.5845 - val_accuracy: 0.6823\n",
      "Epoch 1260/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4119 - accuracy: 0.8003 - val_loss: 0.5845 - val_accuracy: 0.6823\n",
      "Epoch 1261/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4119 - accuracy: 0.8003 - val_loss: 0.5846 - val_accuracy: 0.6823\n",
      "Epoch 1262/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4118 - accuracy: 0.8003 - val_loss: 0.5846 - val_accuracy: 0.6823\n",
      "Epoch 1263/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4119 - accuracy: 0.8003 - val_loss: 0.5846 - val_accuracy: 0.6823\n",
      "Epoch 1264/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4118 - accuracy: 0.8003 - val_loss: 0.5847 - val_accuracy: 0.6823\n",
      "Epoch 1265/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4118 - accuracy: 0.8003 - val_loss: 0.5847 - val_accuracy: 0.6823\n",
      "Epoch 1266/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4117 - accuracy: 0.8003 - val_loss: 0.5847 - val_accuracy: 0.6771\n",
      "Epoch 1267/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4118 - accuracy: 0.8003 - val_loss: 0.5848 - val_accuracy: 0.6771\n",
      "Epoch 1268/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4117 - accuracy: 0.8003 - val_loss: 0.5848 - val_accuracy: 0.6771\n",
      "Epoch 1269/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4117 - accuracy: 0.8003 - val_loss: 0.5849 - val_accuracy: 0.6771\n",
      "Epoch 1270/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4116 - accuracy: 0.8003 - val_loss: 0.5849 - val_accuracy: 0.6771\n",
      "Epoch 1271/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4116 - accuracy: 0.8003 - val_loss: 0.5850 - val_accuracy: 0.6771\n",
      "Epoch 1272/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4117 - accuracy: 0.8003 - val_loss: 0.5850 - val_accuracy: 0.6771\n",
      "Epoch 1273/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4116 - accuracy: 0.8003 - val_loss: 0.5851 - val_accuracy: 0.6771\n",
      "Epoch 1274/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4116 - accuracy: 0.8003 - val_loss: 0.5851 - val_accuracy: 0.6771\n",
      "Epoch 1275/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4116 - accuracy: 0.8003 - val_loss: 0.5851 - val_accuracy: 0.6771\n",
      "Epoch 1276/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4115 - accuracy: 0.8003 - val_loss: 0.5852 - val_accuracy: 0.6771\n",
      "Epoch 1277/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4116 - accuracy: 0.8003 - val_loss: 0.5852 - val_accuracy: 0.6771\n",
      "Epoch 1278/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4114 - accuracy: 0.8003 - val_loss: 0.5852 - val_accuracy: 0.6771\n",
      "Epoch 1279/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4114 - accuracy: 0.8003 - val_loss: 0.5853 - val_accuracy: 0.6771\n",
      "Epoch 1280/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4114 - accuracy: 0.8003 - val_loss: 0.5853 - val_accuracy: 0.6771\n",
      "Epoch 1281/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4114 - accuracy: 0.8003 - val_loss: 0.5854 - val_accuracy: 0.6771\n",
      "Epoch 1282/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4114 - accuracy: 0.8003 - val_loss: 0.5854 - val_accuracy: 0.6771\n",
      "Epoch 1283/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4113 - accuracy: 0.8003 - val_loss: 0.5854 - val_accuracy: 0.6771\n",
      "Epoch 1284/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4113 - accuracy: 0.8003 - val_loss: 0.5855 - val_accuracy: 0.6771\n",
      "Epoch 1285/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4113 - accuracy: 0.8003 - val_loss: 0.5855 - val_accuracy: 0.6771\n",
      "Epoch 1286/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4113 - accuracy: 0.8003 - val_loss: 0.5856 - val_accuracy: 0.6771\n",
      "Epoch 1287/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4112 - accuracy: 0.8003 - val_loss: 0.5856 - val_accuracy: 0.6771\n",
      "Epoch 1288/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4112 - accuracy: 0.8003 - val_loss: 0.5857 - val_accuracy: 0.6771\n",
      "Epoch 1289/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4111 - accuracy: 0.8003 - val_loss: 0.5857 - val_accuracy: 0.6771\n",
      "Epoch 1290/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4112 - accuracy: 0.8003 - val_loss: 0.5857 - val_accuracy: 0.6771\n",
      "Epoch 1291/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4112 - accuracy: 0.8003 - val_loss: 0.5857 - val_accuracy: 0.6771\n",
      "Epoch 1292/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4112 - accuracy: 0.8003 - val_loss: 0.5858 - val_accuracy: 0.6771\n",
      "Epoch 1293/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4111 - accuracy: 0.8003 - val_loss: 0.5858 - val_accuracy: 0.6771\n",
      "Epoch 1294/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4110 - accuracy: 0.8003 - val_loss: 0.5859 - val_accuracy: 0.6771\n",
      "Epoch 1295/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4110 - accuracy: 0.8003 - val_loss: 0.5859 - val_accuracy: 0.6823\n",
      "Epoch 1296/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4110 - accuracy: 0.8003 - val_loss: 0.5860 - val_accuracy: 0.6823\n",
      "Epoch 1297/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4110 - accuracy: 0.8003 - val_loss: 0.5860 - val_accuracy: 0.6823\n",
      "Epoch 1298/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4110 - accuracy: 0.8003 - val_loss: 0.5860 - val_accuracy: 0.6823\n",
      "Epoch 1299/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4110 - accuracy: 0.8003 - val_loss: 0.5860 - val_accuracy: 0.6823\n",
      "Epoch 1300/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4109 - accuracy: 0.8003 - val_loss: 0.5860 - val_accuracy: 0.6823\n",
      "Epoch 1301/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4109 - accuracy: 0.8003 - val_loss: 0.5861 - val_accuracy: 0.6823\n",
      "Epoch 1302/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4108 - accuracy: 0.8003 - val_loss: 0.5861 - val_accuracy: 0.6823\n",
      "Epoch 1303/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4108 - accuracy: 0.8003 - val_loss: 0.5861 - val_accuracy: 0.6823\n",
      "Epoch 1304/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4108 - accuracy: 0.8003 - val_loss: 0.5862 - val_accuracy: 0.6823\n",
      "Epoch 1305/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4108 - accuracy: 0.8003 - val_loss: 0.5862 - val_accuracy: 0.6823\n",
      "Epoch 1306/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4108 - accuracy: 0.8003 - val_loss: 0.5862 - val_accuracy: 0.6823\n",
      "Epoch 1307/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4107 - accuracy: 0.8003 - val_loss: 0.5862 - val_accuracy: 0.6823\n",
      "Epoch 1308/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4108 - accuracy: 0.8003 - val_loss: 0.5863 - val_accuracy: 0.6823\n",
      "Epoch 1309/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4108 - accuracy: 0.8003 - val_loss: 0.5863 - val_accuracy: 0.6823\n",
      "Epoch 1310/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4107 - accuracy: 0.8003 - val_loss: 0.5863 - val_accuracy: 0.6823\n",
      "Epoch 1311/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4107 - accuracy: 0.8003 - val_loss: 0.5863 - val_accuracy: 0.6823\n",
      "Epoch 1312/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4106 - accuracy: 0.8003 - val_loss: 0.5864 - val_accuracy: 0.6823\n",
      "Epoch 1313/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4106 - accuracy: 0.8003 - val_loss: 0.5864 - val_accuracy: 0.6823\n",
      "Epoch 1314/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4107 - accuracy: 0.8003 - val_loss: 0.5864 - val_accuracy: 0.6823\n",
      "Epoch 1315/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4106 - accuracy: 0.8003 - val_loss: 0.5864 - val_accuracy: 0.6823\n",
      "Epoch 1316/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4106 - accuracy: 0.8003 - val_loss: 0.5864 - val_accuracy: 0.6823\n",
      "Epoch 1317/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4106 - accuracy: 0.8003 - val_loss: 0.5865 - val_accuracy: 0.6823\n",
      "Epoch 1318/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4105 - accuracy: 0.8003 - val_loss: 0.5865 - val_accuracy: 0.6823\n",
      "Epoch 1319/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4105 - accuracy: 0.8021 - val_loss: 0.5866 - val_accuracy: 0.6823\n",
      "Epoch 1320/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4104 - accuracy: 0.8003 - val_loss: 0.5866 - val_accuracy: 0.6823\n",
      "Epoch 1321/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4104 - accuracy: 0.8003 - val_loss: 0.5866 - val_accuracy: 0.6823\n",
      "Epoch 1322/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4103 - accuracy: 0.8021 - val_loss: 0.5867 - val_accuracy: 0.6823\n",
      "Epoch 1323/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4103 - accuracy: 0.8003 - val_loss: 0.5867 - val_accuracy: 0.6823\n",
      "Epoch 1324/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4104 - accuracy: 0.8003 - val_loss: 0.5868 - val_accuracy: 0.6823\n",
      "Epoch 1325/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4104 - accuracy: 0.8003 - val_loss: 0.5868 - val_accuracy: 0.6823\n",
      "Epoch 1326/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4103 - accuracy: 0.8003 - val_loss: 0.5868 - val_accuracy: 0.6823\n",
      "Epoch 1327/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4103 - accuracy: 0.8021 - val_loss: 0.5869 - val_accuracy: 0.6823\n",
      "Epoch 1328/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4103 - accuracy: 0.8003 - val_loss: 0.5869 - val_accuracy: 0.6823\n",
      "Epoch 1329/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4102 - accuracy: 0.8021 - val_loss: 0.5869 - val_accuracy: 0.6823\n",
      "Epoch 1330/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4101 - accuracy: 0.8021 - val_loss: 0.5870 - val_accuracy: 0.6823\n",
      "Epoch 1331/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4102 - accuracy: 0.8021 - val_loss: 0.5870 - val_accuracy: 0.6823\n",
      "Epoch 1332/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4102 - accuracy: 0.8003 - val_loss: 0.5870 - val_accuracy: 0.6823\n",
      "Epoch 1333/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4101 - accuracy: 0.8021 - val_loss: 0.5870 - val_accuracy: 0.6823\n",
      "Epoch 1334/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4102 - accuracy: 0.8038 - val_loss: 0.5871 - val_accuracy: 0.6823\n",
      "Epoch 1335/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4101 - accuracy: 0.8038 - val_loss: 0.5872 - val_accuracy: 0.6823\n",
      "Epoch 1336/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4101 - accuracy: 0.8038 - val_loss: 0.5872 - val_accuracy: 0.6823\n",
      "Epoch 1337/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4100 - accuracy: 0.8021 - val_loss: 0.5872 - val_accuracy: 0.6823\n",
      "Epoch 1338/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4100 - accuracy: 0.8038 - val_loss: 0.5872 - val_accuracy: 0.6823\n",
      "Epoch 1339/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4100 - accuracy: 0.8038 - val_loss: 0.5872 - val_accuracy: 0.6823\n",
      "Epoch 1340/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4100 - accuracy: 0.8056 - val_loss: 0.5873 - val_accuracy: 0.6823\n",
      "Epoch 1341/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4100 - accuracy: 0.8021 - val_loss: 0.5873 - val_accuracy: 0.6823\n",
      "Epoch 1342/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4099 - accuracy: 0.8038 - val_loss: 0.5873 - val_accuracy: 0.6823\n",
      "Epoch 1343/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4099 - accuracy: 0.8038 - val_loss: 0.5873 - val_accuracy: 0.6823\n",
      "Epoch 1344/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4098 - accuracy: 0.8021 - val_loss: 0.5873 - val_accuracy: 0.6823\n",
      "Epoch 1345/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4098 - accuracy: 0.8021 - val_loss: 0.5873 - val_accuracy: 0.6823\n",
      "Epoch 1346/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4098 - accuracy: 0.8038 - val_loss: 0.5874 - val_accuracy: 0.6823\n",
      "Epoch 1347/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4098 - accuracy: 0.8056 - val_loss: 0.5874 - val_accuracy: 0.6823\n",
      "Epoch 1348/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4097 - accuracy: 0.8056 - val_loss: 0.5875 - val_accuracy: 0.6823\n",
      "Epoch 1349/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4097 - accuracy: 0.8056 - val_loss: 0.5875 - val_accuracy: 0.6823\n",
      "Epoch 1350/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4097 - accuracy: 0.8038 - val_loss: 0.5875 - val_accuracy: 0.6823\n",
      "Epoch 1351/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4096 - accuracy: 0.8056 - val_loss: 0.5876 - val_accuracy: 0.6823\n",
      "Epoch 1352/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4096 - accuracy: 0.8056 - val_loss: 0.5876 - val_accuracy: 0.6823\n",
      "Epoch 1353/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4096 - accuracy: 0.8056 - val_loss: 0.5876 - val_accuracy: 0.6823\n",
      "Epoch 1354/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4096 - accuracy: 0.8073 - val_loss: 0.5877 - val_accuracy: 0.6823\n",
      "Epoch 1355/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4095 - accuracy: 0.8073 - val_loss: 0.5877 - val_accuracy: 0.6823\n",
      "Epoch 1356/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4095 - accuracy: 0.8056 - val_loss: 0.5878 - val_accuracy: 0.6823\n",
      "Epoch 1357/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4095 - accuracy: 0.8073 - val_loss: 0.5878 - val_accuracy: 0.6823\n",
      "Epoch 1358/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4094 - accuracy: 0.8073 - val_loss: 0.5878 - val_accuracy: 0.6823\n",
      "Epoch 1359/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4094 - accuracy: 0.8073 - val_loss: 0.5879 - val_accuracy: 0.6823\n",
      "Epoch 1360/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4093 - accuracy: 0.8073 - val_loss: 0.5879 - val_accuracy: 0.6823\n",
      "Epoch 1361/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4093 - accuracy: 0.8073 - val_loss: 0.5879 - val_accuracy: 0.6823\n",
      "Epoch 1362/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4093 - accuracy: 0.8073 - val_loss: 0.5880 - val_accuracy: 0.6823\n",
      "Epoch 1363/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4093 - accuracy: 0.8090 - val_loss: 0.5880 - val_accuracy: 0.6823\n",
      "Epoch 1364/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4092 - accuracy: 0.8073 - val_loss: 0.5880 - val_accuracy: 0.6823\n",
      "Epoch 1365/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4092 - accuracy: 0.8073 - val_loss: 0.5881 - val_accuracy: 0.6823\n",
      "Epoch 1366/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4093 - accuracy: 0.8073 - val_loss: 0.5881 - val_accuracy: 0.6823\n",
      "Epoch 1367/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4092 - accuracy: 0.8090 - val_loss: 0.5881 - val_accuracy: 0.6823\n",
      "Epoch 1368/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4092 - accuracy: 0.8073 - val_loss: 0.5882 - val_accuracy: 0.6823\n",
      "Epoch 1369/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4091 - accuracy: 0.8073 - val_loss: 0.5882 - val_accuracy: 0.6823\n",
      "Epoch 1370/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4091 - accuracy: 0.8090 - val_loss: 0.5882 - val_accuracy: 0.6823\n",
      "Epoch 1371/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4091 - accuracy: 0.8090 - val_loss: 0.5882 - val_accuracy: 0.6823\n",
      "Epoch 1372/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4090 - accuracy: 0.8090 - val_loss: 0.5883 - val_accuracy: 0.6823\n",
      "Epoch 1373/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4091 - accuracy: 0.8090 - val_loss: 0.5883 - val_accuracy: 0.6823\n",
      "Epoch 1374/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4090 - accuracy: 0.8090 - val_loss: 0.5884 - val_accuracy: 0.6823\n",
      "Epoch 1375/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4089 - accuracy: 0.8090 - val_loss: 0.5884 - val_accuracy: 0.6823\n",
      "Epoch 1376/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4089 - accuracy: 0.8090 - val_loss: 0.5884 - val_accuracy: 0.6823\n",
      "Epoch 1377/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4089 - accuracy: 0.8090 - val_loss: 0.5885 - val_accuracy: 0.6823\n",
      "Epoch 1378/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4089 - accuracy: 0.8090 - val_loss: 0.5885 - val_accuracy: 0.6823\n",
      "Epoch 1379/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4089 - accuracy: 0.8090 - val_loss: 0.5885 - val_accuracy: 0.6823\n",
      "Epoch 1380/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4089 - accuracy: 0.8108 - val_loss: 0.5886 - val_accuracy: 0.6823\n",
      "Epoch 1381/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4088 - accuracy: 0.8090 - val_loss: 0.5886 - val_accuracy: 0.6823\n",
      "Epoch 1382/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4087 - accuracy: 0.8090 - val_loss: 0.5886 - val_accuracy: 0.6823\n",
      "Epoch 1383/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4088 - accuracy: 0.8090 - val_loss: 0.5887 - val_accuracy: 0.6823\n",
      "Epoch 1384/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4087 - accuracy: 0.8090 - val_loss: 0.5887 - val_accuracy: 0.6823\n",
      "Epoch 1385/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4087 - accuracy: 0.8090 - val_loss: 0.5888 - val_accuracy: 0.6823\n",
      "Epoch 1386/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4087 - accuracy: 0.8090 - val_loss: 0.5888 - val_accuracy: 0.6823\n",
      "Epoch 1387/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4086 - accuracy: 0.8090 - val_loss: 0.5888 - val_accuracy: 0.6823\n",
      "Epoch 1388/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4086 - accuracy: 0.8090 - val_loss: 0.5888 - val_accuracy: 0.6823\n",
      "Epoch 1389/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4086 - accuracy: 0.8090 - val_loss: 0.5889 - val_accuracy: 0.6823\n",
      "Epoch 1390/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4086 - accuracy: 0.8090 - val_loss: 0.5889 - val_accuracy: 0.6823\n",
      "Epoch 1391/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4086 - accuracy: 0.8090 - val_loss: 0.5889 - val_accuracy: 0.6823\n",
      "Epoch 1392/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4086 - accuracy: 0.8090 - val_loss: 0.5889 - val_accuracy: 0.6823\n",
      "Epoch 1393/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4086 - accuracy: 0.8090 - val_loss: 0.5890 - val_accuracy: 0.6823\n",
      "Epoch 1394/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4085 - accuracy: 0.8090 - val_loss: 0.5890 - val_accuracy: 0.6823\n",
      "Epoch 1395/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4085 - accuracy: 0.8090 - val_loss: 0.5891 - val_accuracy: 0.6823\n",
      "Epoch 1396/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4084 - accuracy: 0.8090 - val_loss: 0.5891 - val_accuracy: 0.6823\n",
      "Epoch 1397/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4085 - accuracy: 0.8090 - val_loss: 0.5891 - val_accuracy: 0.6823\n",
      "Epoch 1398/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4084 - accuracy: 0.8090 - val_loss: 0.5892 - val_accuracy: 0.6823\n",
      "Epoch 1399/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4084 - accuracy: 0.8090 - val_loss: 0.5892 - val_accuracy: 0.6823\n",
      "Epoch 1400/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4084 - accuracy: 0.8090 - val_loss: 0.5892 - val_accuracy: 0.6823\n",
      "Epoch 1401/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4083 - accuracy: 0.8090 - val_loss: 0.5892 - val_accuracy: 0.6823\n",
      "Epoch 1402/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4083 - accuracy: 0.8090 - val_loss: 0.5893 - val_accuracy: 0.6823\n",
      "Epoch 1403/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4083 - accuracy: 0.8090 - val_loss: 0.5893 - val_accuracy: 0.6823\n",
      "Epoch 1404/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4083 - accuracy: 0.8090 - val_loss: 0.5893 - val_accuracy: 0.6823\n",
      "Epoch 1405/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4084 - accuracy: 0.8090 - val_loss: 0.5893 - val_accuracy: 0.6823\n",
      "Epoch 1406/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4083 - accuracy: 0.8108 - val_loss: 0.5893 - val_accuracy: 0.6823\n",
      "Epoch 1407/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4082 - accuracy: 0.8090 - val_loss: 0.5894 - val_accuracy: 0.6823\n",
      "Epoch 1408/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4082 - accuracy: 0.8090 - val_loss: 0.5895 - val_accuracy: 0.6823\n",
      "Epoch 1409/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4082 - accuracy: 0.8090 - val_loss: 0.5895 - val_accuracy: 0.6823\n",
      "Epoch 1410/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4081 - accuracy: 0.8108 - val_loss: 0.5896 - val_accuracy: 0.6823\n",
      "Epoch 1411/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4082 - accuracy: 0.8090 - val_loss: 0.5896 - val_accuracy: 0.6823\n",
      "Epoch 1412/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4081 - accuracy: 0.8090 - val_loss: 0.5896 - val_accuracy: 0.6823\n",
      "Epoch 1413/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4081 - accuracy: 0.8090 - val_loss: 0.5896 - val_accuracy: 0.6823\n",
      "Epoch 1414/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4081 - accuracy: 0.8090 - val_loss: 0.5897 - val_accuracy: 0.6823\n",
      "Epoch 1415/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4081 - accuracy: 0.8090 - val_loss: 0.5897 - val_accuracy: 0.6823\n",
      "Epoch 1416/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4080 - accuracy: 0.8090 - val_loss: 0.5897 - val_accuracy: 0.6823\n",
      "Epoch 1417/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4080 - accuracy: 0.8090 - val_loss: 0.5897 - val_accuracy: 0.6823\n",
      "Epoch 1418/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4079 - accuracy: 0.8090 - val_loss: 0.5898 - val_accuracy: 0.6823\n",
      "Epoch 1419/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4080 - accuracy: 0.8108 - val_loss: 0.5898 - val_accuracy: 0.6823\n",
      "Epoch 1420/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4080 - accuracy: 0.8108 - val_loss: 0.5898 - val_accuracy: 0.6823\n",
      "Epoch 1421/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4079 - accuracy: 0.8090 - val_loss: 0.5899 - val_accuracy: 0.6823\n",
      "Epoch 1422/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4080 - accuracy: 0.8090 - val_loss: 0.5899 - val_accuracy: 0.6823\n",
      "Epoch 1423/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4079 - accuracy: 0.8108 - val_loss: 0.5899 - val_accuracy: 0.6823\n",
      "Epoch 1424/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4079 - accuracy: 0.8108 - val_loss: 0.5900 - val_accuracy: 0.6823\n",
      "Epoch 1425/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4078 - accuracy: 0.8090 - val_loss: 0.5899 - val_accuracy: 0.6823\n",
      "Epoch 1426/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4079 - accuracy: 0.8090 - val_loss: 0.5900 - val_accuracy: 0.6823\n",
      "Epoch 1427/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4078 - accuracy: 0.8108 - val_loss: 0.5900 - val_accuracy: 0.6823\n",
      "Epoch 1428/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4079 - accuracy: 0.8108 - val_loss: 0.5901 - val_accuracy: 0.6823\n",
      "Epoch 1429/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4078 - accuracy: 0.8108 - val_loss: 0.5901 - val_accuracy: 0.6823\n",
      "Epoch 1430/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4078 - accuracy: 0.8108 - val_loss: 0.5901 - val_accuracy: 0.6823\n",
      "Epoch 1431/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4078 - accuracy: 0.8108 - val_loss: 0.5901 - val_accuracy: 0.6823\n",
      "Epoch 1432/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4077 - accuracy: 0.8090 - val_loss: 0.5901 - val_accuracy: 0.6823\n",
      "Epoch 1433/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4077 - accuracy: 0.8108 - val_loss: 0.5902 - val_accuracy: 0.6823\n",
      "Epoch 1434/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4077 - accuracy: 0.8108 - val_loss: 0.5902 - val_accuracy: 0.6823\n",
      "Epoch 1435/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4076 - accuracy: 0.8090 - val_loss: 0.5902 - val_accuracy: 0.6823\n",
      "Epoch 1436/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4077 - accuracy: 0.8108 - val_loss: 0.5903 - val_accuracy: 0.6823\n",
      "Epoch 1437/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4076 - accuracy: 0.8108 - val_loss: 0.5904 - val_accuracy: 0.6823\n",
      "Epoch 1438/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4076 - accuracy: 0.8108 - val_loss: 0.5904 - val_accuracy: 0.6823\n",
      "Epoch 1439/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4077 - accuracy: 0.8108 - val_loss: 0.5904 - val_accuracy: 0.6823\n",
      "Epoch 1440/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4076 - accuracy: 0.8090 - val_loss: 0.5904 - val_accuracy: 0.6823\n",
      "Epoch 1441/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4076 - accuracy: 0.8108 - val_loss: 0.5905 - val_accuracy: 0.6823\n",
      "Epoch 1442/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4076 - accuracy: 0.8108 - val_loss: 0.5905 - val_accuracy: 0.6823\n",
      "Epoch 1443/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4075 - accuracy: 0.8108 - val_loss: 0.5906 - val_accuracy: 0.6823\n",
      "Epoch 1444/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4075 - accuracy: 0.8108 - val_loss: 0.5906 - val_accuracy: 0.6823\n",
      "Epoch 1445/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4075 - accuracy: 0.8108 - val_loss: 0.5906 - val_accuracy: 0.6823\n",
      "Epoch 1446/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4075 - accuracy: 0.8108 - val_loss: 0.5907 - val_accuracy: 0.6823\n",
      "Epoch 1447/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4075 - accuracy: 0.8108 - val_loss: 0.5907 - val_accuracy: 0.6823\n",
      "Epoch 1448/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4074 - accuracy: 0.8108 - val_loss: 0.5907 - val_accuracy: 0.6823\n",
      "Epoch 1449/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4074 - accuracy: 0.8090 - val_loss: 0.5907 - val_accuracy: 0.6823\n",
      "Epoch 1450/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4074 - accuracy: 0.8108 - val_loss: 0.5908 - val_accuracy: 0.6823\n",
      "Epoch 1451/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4074 - accuracy: 0.8108 - val_loss: 0.5908 - val_accuracy: 0.6823\n",
      "Epoch 1452/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4074 - accuracy: 0.8108 - val_loss: 0.5909 - val_accuracy: 0.6823\n",
      "Epoch 1453/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4074 - accuracy: 0.8108 - val_loss: 0.5909 - val_accuracy: 0.6823\n",
      "Epoch 1454/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4074 - accuracy: 0.8108 - val_loss: 0.5909 - val_accuracy: 0.6823\n",
      "Epoch 1455/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4074 - accuracy: 0.8108 - val_loss: 0.5909 - val_accuracy: 0.6823\n",
      "Epoch 1456/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4073 - accuracy: 0.8108 - val_loss: 0.5909 - val_accuracy: 0.6823\n",
      "Epoch 1457/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4074 - accuracy: 0.8090 - val_loss: 0.5909 - val_accuracy: 0.6823\n",
      "Epoch 1458/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4073 - accuracy: 0.8108 - val_loss: 0.5910 - val_accuracy: 0.6823\n",
      "Epoch 1459/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4073 - accuracy: 0.8108 - val_loss: 0.5911 - val_accuracy: 0.6823\n",
      "Epoch 1460/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4073 - accuracy: 0.8090 - val_loss: 0.5910 - val_accuracy: 0.6823\n",
      "Epoch 1461/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4072 - accuracy: 0.8108 - val_loss: 0.5911 - val_accuracy: 0.6823\n",
      "Epoch 1462/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4072 - accuracy: 0.8108 - val_loss: 0.5911 - val_accuracy: 0.6823\n",
      "Epoch 1463/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4073 - accuracy: 0.8090 - val_loss: 0.5912 - val_accuracy: 0.6823\n",
      "Epoch 1464/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4072 - accuracy: 0.8108 - val_loss: 0.5912 - val_accuracy: 0.6823\n",
      "Epoch 1465/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4072 - accuracy: 0.8108 - val_loss: 0.5912 - val_accuracy: 0.6823\n",
      "Epoch 1466/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4071 - accuracy: 0.8108 - val_loss: 0.5913 - val_accuracy: 0.6823\n",
      "Epoch 1467/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4072 - accuracy: 0.8108 - val_loss: 0.5913 - val_accuracy: 0.6823\n",
      "Epoch 1468/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4071 - accuracy: 0.8108 - val_loss: 0.5913 - val_accuracy: 0.6823\n",
      "Epoch 1469/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4071 - accuracy: 0.8108 - val_loss: 0.5913 - val_accuracy: 0.6823\n",
      "Epoch 1470/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4071 - accuracy: 0.8090 - val_loss: 0.5914 - val_accuracy: 0.6823\n",
      "Epoch 1471/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4070 - accuracy: 0.8108 - val_loss: 0.5915 - val_accuracy: 0.6823\n",
      "Epoch 1472/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4071 - accuracy: 0.8108 - val_loss: 0.5915 - val_accuracy: 0.6823\n",
      "Epoch 1473/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4070 - accuracy: 0.8108 - val_loss: 0.5915 - val_accuracy: 0.6823\n",
      "Epoch 1474/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4070 - accuracy: 0.8090 - val_loss: 0.5915 - val_accuracy: 0.6823\n",
      "Epoch 1475/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4071 - accuracy: 0.8108 - val_loss: 0.5916 - val_accuracy: 0.6823\n",
      "Epoch 1476/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4070 - accuracy: 0.8090 - val_loss: 0.5916 - val_accuracy: 0.6823\n",
      "Epoch 1477/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4070 - accuracy: 0.8108 - val_loss: 0.5916 - val_accuracy: 0.6823\n",
      "Epoch 1478/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4070 - accuracy: 0.8108 - val_loss: 0.5917 - val_accuracy: 0.6823\n",
      "Epoch 1479/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4069 - accuracy: 0.8108 - val_loss: 0.5917 - val_accuracy: 0.6823\n",
      "Epoch 1480/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4069 - accuracy: 0.8090 - val_loss: 0.5918 - val_accuracy: 0.6823\n",
      "Epoch 1481/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4069 - accuracy: 0.8090 - val_loss: 0.5918 - val_accuracy: 0.6823\n",
      "Epoch 1482/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4069 - accuracy: 0.8108 - val_loss: 0.5918 - val_accuracy: 0.6823\n",
      "Epoch 1483/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4069 - accuracy: 0.8108 - val_loss: 0.5919 - val_accuracy: 0.6823\n",
      "Epoch 1484/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4069 - accuracy: 0.8108 - val_loss: 0.5919 - val_accuracy: 0.6823\n",
      "Epoch 1485/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4068 - accuracy: 0.8108 - val_loss: 0.5919 - val_accuracy: 0.6823\n",
      "Epoch 1486/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4068 - accuracy: 0.8090 - val_loss: 0.5920 - val_accuracy: 0.6823\n",
      "Epoch 1487/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4068 - accuracy: 0.8108 - val_loss: 0.5920 - val_accuracy: 0.6823\n",
      "Epoch 1488/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4068 - accuracy: 0.8090 - val_loss: 0.5920 - val_accuracy: 0.6823\n",
      "Epoch 1489/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4068 - accuracy: 0.8090 - val_loss: 0.5920 - val_accuracy: 0.6823\n",
      "Epoch 1490/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4067 - accuracy: 0.8090 - val_loss: 0.5920 - val_accuracy: 0.6823\n",
      "Epoch 1491/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4068 - accuracy: 0.8090 - val_loss: 0.5921 - val_accuracy: 0.6823\n",
      "Epoch 1492/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4067 - accuracy: 0.8125 - val_loss: 0.5921 - val_accuracy: 0.6823\n",
      "Epoch 1493/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4067 - accuracy: 0.8090 - val_loss: 0.5921 - val_accuracy: 0.6823\n",
      "Epoch 1494/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4067 - accuracy: 0.8108 - val_loss: 0.5921 - val_accuracy: 0.6823\n",
      "Epoch 1495/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4067 - accuracy: 0.8108 - val_loss: 0.5922 - val_accuracy: 0.6823\n",
      "Epoch 1496/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4067 - accuracy: 0.8090 - val_loss: 0.5922 - val_accuracy: 0.6823\n",
      "Epoch 1497/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4067 - accuracy: 0.8073 - val_loss: 0.5922 - val_accuracy: 0.6823\n",
      "Epoch 1498/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4066 - accuracy: 0.8108 - val_loss: 0.5922 - val_accuracy: 0.6823\n",
      "Epoch 1499/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4067 - accuracy: 0.8090 - val_loss: 0.5922 - val_accuracy: 0.6823\n",
      "Epoch 1500/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4066 - accuracy: 0.8108 - val_loss: 0.5923 - val_accuracy: 0.6823\n"
     ]
    }
   ],
   "source": [
    "### BEGIN SOLUTION\n",
    "model_3 = Sequential()\n",
    "model_3.add(Dense(6, input_shape=(8,), activation=\"relu\"))\n",
    "model_3.add(Dense(6,  activation=\"relu\"))\n",
    "model_3.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model_3.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "run_hist_3 = model_3.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " hidden-layer1-relu (Dense)  (None, 6)                 54        \n",
      "                                                                 \n",
      " hidden-layer2-sigmoid (Dens  (None, 6)                42        \n",
      " e)                                                              \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1)                 7         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 103\n",
      "Trainable params: 103\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_hist_2.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Text(0.5, 1.0, 'Accuracy over iterations')"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 864x432 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = len(run_hist_2.history[\"loss\"])\n",
    "\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "ax.plot(range(n), (run_hist_2.history[\"loss\"]),'r.', label=\"Train Loss\")\n",
    "ax.plot(range(n), (run_hist_2.history[\"val_loss\"]),'b.', label=\"Validation Loss\")\n",
    "ax.legend()\n",
    "ax.set_title('Loss over iterations')\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "ax.plot(range(n), (run_hist_2.history[\"accuracy\"]),'r.', label=\"Train Acc\")\n",
    "ax.plot(range(n), (run_hist_2.history[\"val_accuracy\"]),'b.', label=\"Validation Acc\")\n",
    "ax.legend(loc='lower right')\n",
    "ax.set_title('Accuracy over iterations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "accuracy is 0.734\n",
      "roc-auc is 0.793\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 576x576 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_prob_nn_2 = model_2.predict(X_test_norm)\n",
    "y_pred_class_nn_2 = (y_pred_prob_nn_2 > 0.5).astype(\"int32\")\n",
    "\n",
    "print('')\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_2)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_2)))\n",
    "\n",
    "plot_roc(y_test, y_pred_prob_nn_2, 'NN-2')\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Machine Learning Foundation (C) 2020 IBM Corporation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}